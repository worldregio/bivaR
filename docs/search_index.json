[["index.html", "Introduction à la statistique bivariée et aux représentations graphiques avec R À propos de ce document Remerciements Licence", " Introduction à la statistique bivariée et aux représentations graphiques avec R Claude Grasland 2024-09-23 À propos de ce document Ce document n’est pas une introduction aux méthodes statistiques d’analyse de données. Il est basé sur R version 4.3.1 (2023-06-16). Ce document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse : https://github.com/ClaudeGrasland/bivaR Le code source est disponible sur GitHub. Pour toute suggestion ou correction, il est possible de me contacter par mail Remerciements Ce document est généré par l’ extension bookdown de Yihui Xie, complétée par les ajouts de Julien Barnier (css, javascript, …) dans son Introduction à R et au Tidyverse Licence Ce document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International. Licence Creative Commons "],["01-principes.html", "Partie 1 Premiers pas 1.1 Opérations arithmétiques 1.2 Les objets de base : valeur, vecteur, matrice 1.3 Ne pas confondre listes et vecteurs ! 1.4 Attention aux types de variables … 1.5 Types de tableaux et guerres de religion. 1.6 En résumé 1.7 Exercices", " Partie 1 Premiers pas Mise en place : Télécharger le dossier exo1 et décompressez le sur votre ordinateur. Placez le dossier exo1 comme sous-dossier de votre dossier de cours. Puis ouvrez le programme R exo1.R 1.1 Opérations arithmétiques Nous allons commencer par passer quelques commandes arithmétiques simples. Il suffit de les taper dans la console de R pour qu’elles s’executent automatiquement. 8+2 #&gt; [1] 10 8-2 #&gt; [1] 6 8*2 #&gt; [1] 16 8/2 #&gt; [1] 4 8**2 #&gt; [1] 64 8**(1/2) #&gt; [1] 2.828427 log(10) #&gt; [1] 2.302585 log10(10) #&gt; [1] 1 sqrt(10) #&gt; [1] 3.162278 sin(pi) #&gt; [1] 1.224647e-16 cos(pi) #&gt; [1] -1 tan(pi) #&gt; [1] -1.224647e-16 1.2 Les objets de base : valeur, vecteur, matrice Les objets élémentéires de R apparaissent dans la fenêtre environnement sous la rubrique Values 1.2.1 Eléments Un élément est unique et constitue la brique de base de tous les objets suivants. On peut aussi l’interpréter comme un vecteur de longueur 1 ou une matrice de dimension 1x1. x&lt;-8 y&lt;-2 x+y #&gt; [1] 10 x*y #&gt; [1] 16 x**y #&gt; [1] 64 Les éléments se combinent différemment selon leur type. Par exemple, des éléments de type caractère (character) peuvent être assemblés avec l’instruction paste() ou découpez avec l’instruction substr() : x&lt;-&quot;Bonjour&quot; y&lt;- &quot;tout le monde&quot; z&lt;- &quot;!&quot; paste(x,y,z) #&gt; [1] &quot;Bonjour tout le monde !&quot; substr(x,1,3) #&gt; [1] &quot;Bon&quot; Quant aux éléments logiques (logical) nous verrons qu’ils peuvent se combiner avec des opérateurs comme &amp; quii signifie ET ou bien | qui signifie OU. x&lt;-TRUE y&lt;-FALSE x &amp; y #&gt; [1] FALSE x | y #&gt; [1] TRUE 1.2.2 vecteurs (vectors) Un vecteur est un ensemble d’éléments de même type que l’on a concaténés à l’aide de l’instruction c(). On peut ensuite les aditionner, les multiplier ou les combiner avec des éléments. x &lt;- c(1,2,4,8,16) y &lt;- 4 x+y #&gt; [1] 5 6 8 12 20 x*y #&gt; [1] 4 8 16 32 64 x**y #&gt; [1] 1 16 256 4096 65536 On remarque dans l’exemple ci-dessus que R n’a pas de problème pour combiner des vecteurs de tailles différentes. 1.2.3 Matrices (matrix) Une matrice est un ensemble de vecteurs de même longueur et de même type. On peut donc construire une matrice en concaténant des vecteurs verticalement avec cbind()ou horizontalement avec rbind(). # deux vecteurs x1 &lt;- c(1,2,4,8,16) x2 &lt;- c(5,10,15,20,25) # matrice en colonnes m1 &lt;- cbind(x1,x2) m1 #&gt; x1 x2 #&gt; [1,] 1 5 #&gt; [2,] 2 10 #&gt; [3,] 4 15 #&gt; [4,] 8 20 #&gt; [5,] 16 25 # matrice en lignes m2 &lt;- rbind(x1,x2) m2 #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; x1 1 2 4 8 16 #&gt; x2 5 10 15 20 25 # piège ! m3 &lt;- c(x1,x2) m3 #&gt; [1] 1 2 4 8 16 5 10 15 20 25 is.matrix(m3) #&gt; [1] FALSE Si on assemble deux vecteurs à l’aide de la commande c()on obtient un vecteur et pas une matrice. 1.3 Ne pas confondre listes et vecteurs ! R utilise des types plus complexes d’objets qui lui sont propres et qui sont en général des listes ou des listes de listes. liste simple liste de liste listes de vecteur = data.frame … Les vecteurs regroupent des éléments de même type tandis que les listes regroupent des éléments ou des objets de type quelconque. Le type liste est donc beaucoup plus général, mais aussi plus difficile d’emploi. On peut comparer une liste à un panier de course dans lequel on mélange des choux, des carottes, des navets, une boîte de douze oeufs, un paquet de croquettes pour chiens, etc… # Format vecteur prenom &lt;- c(&quot;Ali&quot;, &quot;Amine&quot;, &quot;Anne&quot;,&quot;Marc&quot;,&quot;Zayneb&quot;) sexe &lt;- c(&quot;H&quot;,&quot;H&quot;,&quot;F&quot;,&quot;H&quot;,&quot;F&quot;) age &lt;- c(21,22,24,18,25) # Format liste Ali &lt;- list(&quot;H&quot;,21) Amine &lt;- list(&quot;F&quot;,22) Anne &lt;- list(&quot;F&quot;,28) Marc &lt;- list (&quot;H&quot;,18) Zayneb &lt;- list(&quot;F&quot;,25) # Ne pas confondre ! Ali &lt;- c(&quot;H&quot;,21) Ali #&gt; [1] &quot;H&quot; &quot;21&quot; Ali &lt;- list(&quot;H&quot;,21) Ali #&gt; [[1]] #&gt; [1] &quot;H&quot; #&gt; #&gt; [[2]] #&gt; [1] 21 1.4 Attention aux types de variables … Chaque valeur, vecteur ou matrice appartient à un seul type de données. Il est important de ne pas les confondre, sous peine d’obtenir des résultats … douteux. On se limitera ici aux principaux types, d’autres étant vus ultérieurement dans l’année : numeric : type général (entier, réels, …) logique : type booleen (TRUE/FALSE) date : année, mois, jour,n heure, minutes, secondes, … character : texte quelconque factor : variable catégorielle (codage d’enquêtes …) La commande str() permet de vérifier le type d’un vecteur (ou d’une matrice) et d’en afficher la dimension. # Format charactère prenom &lt;- c(&quot;Ali&quot;, &quot;Amine&quot;,&quot;Anne&quot;, &quot;Marc&quot;,&quot;Zayneb&quot;) str(prenom) #&gt; chr [1:5] &quot;Ali&quot; &quot;Amine&quot; &quot;Anne&quot; &quot;Marc&quot; &quot;Zayneb&quot; # Format logique likeR &lt;- c(TRUE,FALSE, TRUE, FALSE, FALSE) str(likeR) #&gt; logi [1:5] TRUE FALSE TRUE FALSE FALSE # Format Factor sexe &lt;- c(1,1,2,1,2) sexe&lt;-as.factor(sexe) levels(sexe) &lt;-c(&quot;Homme&quot;,&quot;Femme&quot;) str(sexe) #&gt; Factor w/ 2 levels &quot;Homme&quot;,&quot;Femme&quot;: 1 1 2 1 2 # Format numerique age &lt;- c(21,22,24,18,25) str(age) #&gt; num [1:5] 21 22 24 18 25 # Format date nais&lt;-c(&quot;1999-10-28&quot;,&quot;1998-10-13&quot;, &quot;1996-10-15&quot;,&quot;2002-02-07&quot;,&quot;1995-06-18&quot;) nais&lt;-as.Date(nais) str(nais) #&gt; Date[1:5], format: &quot;1999-10-28&quot; &quot;1998-10-13&quot; &quot;1996-10-15&quot; &quot;2002-02-07&quot; &quot;1995-06-18&quot; 1.5 Types de tableaux et guerres de religion. R est un langage qui a beaucouop évolué au cours du temps, suscitant l’apparition de nouveaux types d’objets mieux adapéts à certaines fonctions. Du coup, il existe plusieurs format de tableaux de données, plus ou moins compatibles entre eux. On notera que dans la fenêtre environnement, les tableaux apparaissent dans la sous-fenêtre data et non plus dans la sous-fenêtre values comme c’était le cas pour les éléments, vecteurs ou matrices. 1.5.1 Le type data.frame : C’est le type d’origine correspondant à ce qu’on appelle le langage R-Base. Il se présente en pratique comme une liste de vecteurs qui peuvent être de types différents mais qui sont de même longueur. # Création d&#39;un data.frame tab1&lt;-data.frame(prenom,nais, age,sexe,likeR) str(tab1) #&gt; &#39;data.frame&#39;: 5 obs. of 5 variables: #&gt; $ prenom: chr &quot;Ali&quot; &quot;Amine&quot; &quot;Anne&quot; &quot;Marc&quot; ... #&gt; $ nais : Date, format: &quot;1999-10-28&quot; &quot;1998-10-13&quot; ... #&gt; $ age : num 21 22 24 18 25 #&gt; $ sexe : Factor w/ 2 levels &quot;Homme&quot;,&quot;Femme&quot;: 1 1 2 1 2 #&gt; $ likeR : logi TRUE FALSE TRUE FALSE FALSE 1.5.2 Le type tibble c’est un type créé par Hadley Wickham pour développer la suite de fonctions Tidyverse ou ggplot # Création d&#39;un tibble library(tidyr, quiet=T) tab2&lt;-tibble(prenom,nais, age,sexe,likeR) str(tab2) #&gt; tibble [5 × 5] (S3: tbl_df/tbl/data.frame) #&gt; $ prenom: chr [1:5] &quot;Ali&quot; &quot;Amine&quot; &quot;Anne&quot; &quot;Marc&quot; ... #&gt; $ nais : Date[1:5], format: &quot;1999-10-28&quot; &quot;1998-10-13&quot; ... #&gt; $ age : num [1:5] 21 22 24 18 25 #&gt; $ sexe : Factor w/ 2 levels &quot;Homme&quot;,&quot;Femme&quot;: 1 1 2 1 2 #&gt; $ likeR : logi [1:5] TRUE FALSE TRUE FALSE FALSE 1.5.3 Le type data.table C’est un type récent créé pour traiter les tableaux de très grande taille à l’aide du package … data.table # Création d&#39;un data.table library(data.table, quiet=T) #&gt; Warning: package &#39;data.table&#39; was built under R version 4.3.3 #&gt; #&gt; Attaching package: &#39;data.table&#39; #&gt; The following objects are masked from &#39;package:lubridate&#39;: #&gt; #&gt; hour, isoweek, mday, minute, month, quarter, second, wday, week, #&gt; yday, year #&gt; The following objects are masked from &#39;package:dplyr&#39;: #&gt; #&gt; between, first, last #&gt; The following object is masked from &#39;package:purrr&#39;: #&gt; #&gt; transpose tab3&lt;-data.table(prenom,nais, age,sexe,likeR) str(tab3) #&gt; Classes &#39;data.table&#39; and &#39;data.frame&#39;: 5 obs. of 5 variables: #&gt; $ prenom: chr &quot;Ali&quot; &quot;Amine&quot; &quot;Anne&quot; &quot;Marc&quot; ... #&gt; $ nais : Date, format: &quot;1999-10-28&quot; &quot;1998-10-13&quot; ... #&gt; $ age : num 21 22 24 18 25 #&gt; $ sexe : Factor w/ 2 levels &quot;Homme&quot;,&quot;Femme&quot;: 1 1 2 1 2 #&gt; $ likeR : logi TRUE FALSE TRUE FALSE FALSE #&gt; - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; 1.6 En résumé R est un langage de programmation multifonction qui évolue depuis maintenant plus de 30 ans et auquel s’ajoutent continuellement de nouveaux packages. A la différence de SPSS, il n’est pas spécialisé uniquement en statistique, même si le coeur du logiciel est bien centré sur la statistique. Pour progresser rapidement en R il est indispensable : de prêter une grande attention aux types de variables et de tableaux. de ne pas chercher à utiliser trop vite de nouveaux packages tant que l’on n’a pas acquis une pratique suffisante du R-Base. de consulter la documentation et les forums de discussion en cas de difficulté. 1.7 Exercices Exercice 1 Construire le vecteur x suivant : #&gt; [1] &quot;Paris&quot; &quot;Londres&quot; &quot;Tokyo&quot; &quot;New York&quot; x &lt;- c(&quot;Paris&quot;, &quot;Londres&quot;,&quot;Tokyo&quot;,&quot;New York&quot;) Construire le vecteur y suivant : #&gt; [1] &quot;France&quot; &quot;Royaume-Uni&quot; &quot;Japon&quot; &quot;USA&quot; y &lt;- c(&quot;France&quot;, &quot;Royaume-Uni&quot;,&quot;Japon&quot;,&quot;USA&quot;) Construire le vecteur z suivant : #&gt; [1] 10.2 14.6 42.8 23.9 z &lt;- c(10.2, 14.6,42.8,23.9) Construire la matrice m1 #&gt; [,1] [,2] [,3] [,4] #&gt; x &quot;Paris&quot; &quot;Londres&quot; &quot;Tokyo&quot; &quot;New York&quot; #&gt; y &quot;France&quot; &quot;Royaume-Uni&quot; &quot;Japon&quot; &quot;USA&quot; m1&lt;-rbind(x,y) Construire le data.frame df #&gt; y x z #&gt; 1 France Paris 10.2 #&gt; 2 Royaume-Uni Londres 14.6 #&gt; 3 Japon Tokyo 42.8 #&gt; 4 USA New York 23.9 df&lt;-data.frame(y,x,z) Exercice 2 (d’après J.Barnier) On a demandé à 4 ménages le revenu des deux conjoints, et le nombre de personnes du ménage : conjoint1 &lt;- c(1200, 1180, 1750, 2100) conjoint2 &lt;- c(1450, 1870, 1690, 0) nb_personnes &lt;- c(4, 2, 3, 2) Calculer le revenu total de chaque ménage, puis diviser par le nombre de personnes pour obtenir le revenu par personne de chaque ménage. revenu_total &lt;- conjoint1 + conjoint2 revenu_total / nb_personnes #&gt; [1] 662.500 1525.000 1146.667 1050.000 Exercice 3 (très difficile !) On a enregistré les données de trois indivius sous forme de listes et on voudrais convertir le tout en data.frame : ind1&lt;-list(prenom=&quot;Alice&quot;,age = 20, likeR=TRUE) ind2&lt;-list(prenom=&quot;Bob&quot;,age = 18, likeR=FALSE) ind3&lt;-list(prenom=&quot;Rose&quot;,age = 14, likeR=TRUE) Voici le résultat attendu : #&gt; prenom age likeR #&gt; 1 Alice 20 TRUE #&gt; 2 Bob 18 FALSE #&gt; 3 Rose 14 TRUE # On forme une liste de liste ... list_ind&lt;-list(ind1,ind2,ind3) # On applique une formule obscure... df&lt;-as.data.frame(do.call(rbind.data.frame,list_ind)) df #&gt; prenom age likeR #&gt; 1 Alice 20 TRUE #&gt; 2 Bob 18 FALSE #&gt; 3 Rose 14 TRUE # Où on utilise un package spécialisé ... library(data.table) df&lt;-rbindlist(list_ind) df #&gt; prenom age likeR #&gt; &lt;char&gt; &lt;num&gt; &lt;lgcl&gt; #&gt; 1: Alice 20 TRUE #&gt; 2: Bob 18 FALSE #&gt; 3: Rose 14 TRUE "],["02-office-killer.html", "Partie 2 Office killer 2.1 Rstudio et les projets R 2.2 Programme R : Excel killer ? 2.3 Document Rmd : Word killer ? 2.4 Diapos Rmd : Power Point killer 2.5 En résumé", " Partie 2 Office killer Mise en place : Télécharger le dossier exo2 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo2.Rproj dans Rstudio. Le but de ce chapitre est de montrer le plus tôt possible aux étudiants les possibilités de R et de son environnement R-Studio en ce qui concerne la production de documents ou de présentations dans le cadre d’une démarche reproductible. L’apprentissage précoce de Rmarkdown nous semble en effet indispensable, ne serait-ce que pour que les étudiants apprennent à prendre en cours des notes mélangeant les exemples de code R et les explications données en cours ou en TD. Mais le but véritable est de convaincre tout ou partie des étudiants qu’ils peuvent remplacer à terme les logiciels de bureautique des suites office par un environnement de travail plus intégré et plus performant… à condition d’oublier la souris pour revenir au clavier ! Real mensch never clcik ! 2.1 Rstudio et les projets R Au commencement, les dieux de la statistique créèrent le langage R. Mais l’interface était vide et vague, les ténèbres couvraient les lignes de code R-Studio dit : Que le projet soit et le projet fut. Si l’on veut s’épargner bien des désagréments dans l’apprentissage de R, il faut prendre dès le départ de bonnes habitudes. Parmi celles-ci, l’une des plus importantes est le fait d’inscrire toujours son travail dans le cadre d’un projet R c’est-à-dire - en simplifiant beaucoup - un répertoire de travail contenant l’ensemble des données, programmes, résultats… que l’on pourra par la suite compresser, archiver et transmettre à quelqu’un d’autre. 2.1.1 Lancement de R studio Sauf à être complètement masochiste, on n’utilise jamais R directement mais on lance d’abord l’interface R-Studio qui facilite conisdérablement l’ensemble des opérations et offre une gamme considérable de services. Il ne faut toutefois pas confondre les deux et il serait par exemple ridicule d’indiquer sur un CV en vue d’un emploi de statisticien que l’on sait utiliser R-studio en oubliant de préciser que l’on maîtrise R. 2.1.2 Création d’un projet Pour créer un projet on utilise le menus déroulant File/new project/ … et on définit un dossier de notre ordinateur (existant ou à créer) qui contiendra le projet. Une fois l’opération effectuée, on pourra constater que ce dossier contient un fichier xxx.Rproj ou xxx est en principe le nom du dossier dans lequel vous avez stocké le projet. Ce fichier contient toute une série d’informations dont nous ne parlerons pas dans ce cours d’initiation mais qui, pour faire simple, définissent un ensemble de réglages du logiciel et de préférences de l’utilisateur. Si vous fermez Rstudio (faites-le !) il vous suffira pour reprendre votre travail là où vous vous étiez arrêté : de lancer R-studio et de cliquer sur File/open project/… suivi du nom du fichier xxx.Rproj ou plus simplement encore de double cliquer sur le fichier xxx.Rproj ce qui lancera automatiquement Rstudio Le dossier contenant votre projet R peut être organisé à votre convenance. Certains mettent tout les fichier pêle-mêle dans le dossier. D’autres préfèrent créer des sous-dossiers contenant des données, des programmes, des résultats, des figures. Vous déciderez à l’usage de ce qui vous convient le mieux, mais le point important est que tout ce qui entre ou sort de vos programmes R doit être de préférence stocké dans le répertoire du projet. 2.2 Programme R : Excel killer ? C’est pourquoi tu quittera Word et Excel, et t’attachera à R studio, et vous deviendrez une seule chair. La fonction initiale d’un langage de programmation comme R est … de créer des programmes c’est-à-dire des ensembles d’instruction permettant d’accomplir une tâche à l’intérieur d’une chaîne de production. Dans le cas d’un logiciel spécialisé dans l’analyse statistique, il s’agira donc de partir de données (statistiques, géographiques, textuelles, …) pour aboutir à des résultats prenant la forme de tableaux, cartes ou graphiques. Il ne s’agit donc en somme que d’une étape du travail de recherche où le principal avantage de R est d’automatiser une tâche et de faciliter sa reproduction ultérieure avec en arrière plan un objectif de productivité puisque l’ordinateur réalise en quelques millisecondes des tâches qui prendraient des heures avec un logiciel click-bouton de type Excel. Prenons comme exemple le cas d’un éditeur qui souhaite réaliser une grande encyclopédie des jeux olympiques. Il a besoin pour cela d’embaucher un data analyst qui l’aidera à exploiter une grande base de données qu’il a trouvé sur internet, intitulée 120 years of olympic history, athlets and results Deux candidats se présentent pour le poste : Le candidat A est un expert dans la manipulation du package office (Excel, Word, Power Point, …) avec plus de 30 ans d’expérience. Le candidat B est un étudiant de Master 1 ayant suivi un semestre de formation à R et Rstudio. L’éditeur décide de les mettre en concurrence pour voir lequel des deux candidats est le plus efficace et prépare une série d’épreuves qui seront chronométrées 2.2.1 Round 1 : Importation du tableau de données Il faut importer le tableau, déterminer le nombre de lignes et de colonnes puis afficher les 5 premières et 5 dernières lignes On crée un programme R avec File/New File/R Script puis on l’enregistre avec File/Save/ … suivi du nom du programme. # Importation du tableau don &lt;- read.table(file = &quot;resources/data/olympic/120-years-of-olympic-history-athletes-and-results.csv&quot;, header= TRUE, sep =&quot;,&quot;) # détermination du nombre de lignes et de colonnes dim(don) #&gt; [1] 271116 15 # affichage des 5 premières lignes head(don,5) #&gt; ID Name Sex Age Height Weight Team NOC #&gt; 1 1 A Dijiang M 24 180 80 China CHN #&gt; 2 2 A Lamusi M 23 170 60 China CHN #&gt; 3 3 Gunnar Nielsen Aaby M 24 NA NA Denmark DEN #&gt; 4 4 Edgar Lindenau Aabye M 34 NA NA Denmark/Sweden DEN #&gt; 5 5 Christine Jacoba Aaftink F 21 185 82 Netherlands NED #&gt; Games Year Season City Sport #&gt; 1 1992 Summer 1992 Summer Barcelona Basketball #&gt; 2 2012 Summer 2012 Summer London Judo #&gt; 3 1920 Summer 1920 Summer Antwerpen Football #&gt; 4 1900 Summer 1900 Summer Paris Tug-Of-War #&gt; 5 1988 Winter 1988 Winter Calgary Speed Skating #&gt; Event Medal #&gt; 1 Basketball Men&#39;s Basketball &lt;NA&gt; #&gt; 2 Judo Men&#39;s Extra-Lightweight &lt;NA&gt; #&gt; 3 Football Men&#39;s Football &lt;NA&gt; #&gt; 4 Tug-Of-War Men&#39;s Tug-Of-War Gold #&gt; 5 Speed Skating Women&#39;s 500 metres &lt;NA&gt; # Affichage du tableau tail(don,5) #&gt; ID Name Sex Age Height Weight Team NOC Games #&gt; 271112 135569 Andrzej ya M 29 179 89 Poland-1 POL 1976 Winter #&gt; 271113 135570 Piotr ya M 27 176 59 Poland POL 2014 Winter #&gt; 271114 135570 Piotr ya M 27 176 59 Poland POL 2014 Winter #&gt; 271115 135571 Tomasz Ireneusz ya M 30 185 96 Poland POL 1998 Winter #&gt; 271116 135571 Tomasz Ireneusz ya M 34 185 96 Poland POL 2002 Winter #&gt; Year Season City Sport #&gt; 271112 1976 Winter Innsbruck Luge #&gt; 271113 2014 Winter Sochi Ski Jumping #&gt; 271114 2014 Winter Sochi Ski Jumping #&gt; 271115 1998 Winter Nagano Bobsleigh #&gt; 271116 2002 Winter Salt Lake City Bobsleigh #&gt; Event Medal #&gt; 271112 Luge Mixed (Men)&#39;s Doubles &lt;NA&gt; #&gt; 271113 Ski Jumping Men&#39;s Large Hill, Individual &lt;NA&gt; #&gt; 271114 Ski Jumping Men&#39;s Large Hill, Team &lt;NA&gt; #&gt; 271115 Bobsleigh Men&#39;s Four &lt;NA&gt; #&gt; 271116 Bobsleigh Men&#39;s Four &lt;NA&gt; Normalement, les étudiants qui utilisent un tableur ont du aller plus vite et Excel mène sur R par 1-0 2.2.2 Round 2. Inventaire des sports disponible On souhaite faire l’inventaire de l’ensemble des sports disponibles dans la base de données. Puis créer un tableau indiquant les 10 sports sur lesquels on dispose du plus grand nombre d’information. # Création d&#39;une table tab&lt;-table(don$Sport) class(tab) #&gt; [1] &quot;table&quot; # Transformation de la table en data.frame res&lt;-data.frame(tab) # Recodage des noms de variables names(res)&lt;-c(&quot;Sport&quot;,&quot;Nbresul&quot;) # Tri du tableau res&lt;-res[order(-res$Nbresul),] # Affichage de res head(res, 20) #&gt; Sport Nbresul #&gt; 6 Athletics 38624 #&gt; 28 Gymnastics 26707 #&gt; 55 Swimming 23195 #&gt; 48 Shooting 11448 #&gt; 20 Cycling 10859 #&gt; 23 Fencing 10735 #&gt; 44 Rowing 10595 #&gt; 18 Cross Country Skiing 9133 #&gt; 2 Alpine Skiing 8829 #&gt; 66 Wrestling 7154 #&gt; 25 Football 6745 #&gt; 47 Sailing 6586 #&gt; 22 Equestrianism 6344 #&gt; 15 Canoeing 6171 #&gt; 14 Boxing 6047 #&gt; 54 Speed Skating 5613 #&gt; 31 Ice Hockey 5516 #&gt; 30 Hockey 5417 #&gt; 12 Biathlon 4893 #&gt; 9 Basketball 4536 La création d’un tableau est à première vue plus facile avec un logiciel click-bouton. L’expert en Excel va utiliser la fonction tableau croisé dynamique et produire le tableau en quelques secondes. Il devrait par contre perdre un peu de temps pour trier le tableau mais finir par l’emporter. Excel mène 2-0. 2.2.3 Round 3. Sélection d’un sport Vous devez maintenant extraire le tableau des résultats de tir à l’arc (“Archery”) après 1990 en ne conservant que les personnes qui ont obtenu une médaille. # sélection sel &lt;- don[don$Year &gt; 1990 &amp; don$Sport==&quot;Archery&quot; &amp; is.na(don$Medal)==FALSE,] # Affichage head(sel) #&gt; ID Name Sex Age Height Weight Team NOC #&gt; 9542 5233 Virginie Arnold F 28 155 50 France FRA #&gt; 9966 5447 Loedmila Arzjannikova F 34 168 62 Unified Team EUN #&gt; 11205 6126 Mariana Avitia Martnez F 18 164 61 Mexico MEX #&gt; 12356 6710 Bair Dorzhiyevich Badyonov M 32 178 75 Russia RUS #&gt; 22407 11799 Matteo Bisiani M 19 184 85 Italy ITA #&gt; 22409 11799 Matteo Bisiani M 24 184 85 Italy ITA #&gt; Games Year Season City Sport Event #&gt; 9542 2008 Summer 2008 Summer Beijing Archery Archery Women&#39;s Team #&gt; 9966 1992 Summer 1992 Summer Barcelona Archery Archery Women&#39;s Team #&gt; 11205 2012 Summer 2012 Summer London Archery Archery Women&#39;s Individual #&gt; 12356 2008 Summer 2008 Summer Beijing Archery Archery Men&#39;s Individual #&gt; 22407 1996 Summer 1996 Summer Atlanta Archery Archery Men&#39;s Team #&gt; 22409 2000 Summer 2000 Summer Sydney Archery Archery Men&#39;s Team #&gt; Medal #&gt; 9542 Bronze #&gt; 9966 Bronze #&gt; 11205 Bronze #&gt; 12356 Bronze #&gt; 22407 Bronze #&gt; 22409 Silver Là, je parie que les utilisateurs d’Excel ont eu un peu plus de mal … mais on va supposer qu’il y a match nul : Excel = 3, R = 1 2.2.4 Round 4. Analyse de l’âge, du poids, de la taille et de l’IMC des sportifs Résumez statistiquement, l’âge, le poids, la taille et l’Indice de Masse Corporelle (IMC = Poids en kg/ carré de la taille en mètres ) des personnes ayant obtenu une médaille en séparant les hommes et les femmes. tapply(sel$Age, INDEX = sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 17.00 21.00 24.00 24.31 27.00 39.00 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 17.00 21.00 24.00 25.25 27.25 45.00 tapply(sel$Height, INDEX = sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 155.0 165.0 168.0 167.8 170.0 185.0 7 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 170.0 178.0 180.0 179.9 183.0 191.0 2 tapply(sel$Weight, INDEX=sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 50.00 58.00 63.00 62.84 65.00 86.00 7 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 58.00 73.00 78.50 81.71 89.75 110.00 2 sel$IMC &lt;- sel$Weight/(sel$Height/100)**2 tapply(sel$IMC, INDEX=sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 18.78 20.44 22.06 22.31 24.01 28.73 7 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 19.82 22.23 24.43 25.22 27.31 33.58 2 Quelque chose me dit qu’Excel a eu un peu de mal à résoudre le problème. Le score est désormais de 3-2 2.2.5 Round 5 : Nombre de médailles d’or par pays et par épreuve On cherche maintenant à déterminer le nombre de médailles par pays et par épreuve. Attention, dans le cas des épreuves par équipe il ne faut compter les membres d’une équipe qu’une seule fois … # Sélection des lignes (médailles d&#39;or) sel2 &lt;- sel[sel$Medal==&quot;Gold&quot;,] # Selection des colonnes sel3 &lt;- sel2[,c(&quot;NOC&quot;,&quot;Year&quot;,&quot;Event&quot;)] # Elimination des doublons sel4 &lt;-unique(sel3) # Tableau croisé tab&lt;-table(sel4$Event,sel4$NOC) # Tri des pays ayant le plus de médailles # Ajout des marges addmargins(tab) #&gt; #&gt; AUS CHN ESP FRA ITA KOR UKR USA Sum #&gt; Archery Men&#39;s Individual 1 0 0 1 1 2 1 1 7 #&gt; Archery Men&#39;s Team 0 0 1 0 1 4 0 1 7 #&gt; Archery Women&#39;s Individual 0 1 0 0 0 6 0 0 7 #&gt; Archery Women&#39;s Team 0 0 0 0 0 7 0 0 7 #&gt; Sum 1 1 1 1 2 19 1 2 28 Quelque chose me dit qu’Excel a eu un beaucoup de mal à résoudre le problème. Le score est désormais de 3-3 2.2.6 Dernier round. Refaire toute l’analyse en changeant de sport On remplace le sport “Archery” par le sport “Judo” et on refait toute les analyses # (1) Importation du tableau don &lt;- read.table(file = &quot;resources/data/olympic/120-years-of-olympic-history-athletes-and-results.csv&quot;, header= TRUE, sep =&quot;,&quot;) # (2) Sélection du sport et de la data sel &lt;- don[don$Year &gt; 1990 &amp; don$Sport==&quot;Judo&quot; &amp; is.na(don$Medal)==FALSE,] # (3) Caractéristiques des sportifs tapply(sel$Age, INDEX = sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 16.00 23.00 25.00 25.03 28.00 33.00 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 17.00 23.00 25.00 25.32 27.00 34.00 tapply(sel$Height, INDEX = sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 146.0 160.0 166.0 166.1 173.0 186.0 7 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 159.0 170.2 178.0 178.7 185.0 203.0 10 tapply(sel$Weight, INDEX=sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 48.00 55.50 63.00 68.38 76.25 135.00 8 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 60.00 66.00 81.00 86.69 100.00 175.00 10 sel$IMC &lt;- sel$Weight/(sel$Height/100)**2 tapply(sel$IMC, INDEX=sel$Sex, FUN=&quot;summary&quot;) #&gt; $F #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 18.52 21.38 22.85 24.45 25.24 43.60 8 #&gt; #&gt; $M #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s #&gt; 19.37 23.84 25.78 26.76 28.40 56.50 10 # (4) Médailles d&#39;or par pays et épreuve # Sélection des lignes (médailles d&#39;or) sel2 &lt;- sel[sel$Medal==&quot;Gold&quot;,] # Selection des colonnes sel3 &lt;- sel2[,c(&quot;NOC&quot;,&quot;Year&quot;,&quot;Event&quot;)] # Elimination des doublons sel4 &lt;-unique(sel3) # Tableau croisé tab&lt;-table(sel4$Event,sel4$NOC) # Ajout des marges addmargins(tab) #&gt; #&gt; ARG AZE BEL BLR BRA CHN CUB CZE ESP EUN FRA #&gt; Judo Men&#39;s Extra-Lightweight 0 0 0 0 0 0 0 0 0 1 0 #&gt; Judo Men&#39;s Half-Heavyweight 0 0 0 1 0 0 0 1 0 0 0 #&gt; Judo Men&#39;s Half-Lightweight 0 0 0 0 1 0 0 0 0 0 0 #&gt; Judo Men&#39;s Half-Middleweight 0 0 0 0 0 0 0 0 0 0 1 #&gt; Judo Men&#39;s Heavyweight 0 0 0 0 0 0 0 0 0 1 4 #&gt; Judo Men&#39;s Lightweight 0 1 0 0 0 0 0 0 0 0 0 #&gt; #&gt; GEO GER GRE HUN ITA JPN KOR KOS MGL NED POL #&gt; Judo Men&#39;s Extra-Lightweight 0 0 0 0 0 3 1 0 0 0 0 #&gt; Judo Men&#39;s Half-Heavyweight 0 0 0 1 0 1 0 0 1 0 1 #&gt; Judo Men&#39;s Half-Lightweight 1 1 0 0 1 2 0 0 0 0 0 #&gt; Judo Men&#39;s Half-Middleweight 0 1 1 0 0 2 1 0 0 0 0 #&gt; Judo Men&#39;s Heavyweight 0 0 0 0 0 2 0 0 0 0 0 #&gt; Judo Men&#39;s Lightweight 0 0 0 0 1 3 1 0 0 0 0 #&gt; #&gt; PRK ROU RUS SLO TUR USA Sum #&gt; Judo Men&#39;s Extra-Lightweight 0 0 2 0 0 0 7 #&gt; Judo Men&#39;s Half-Heavyweight 0 0 1 0 0 0 7 #&gt; Judo Men&#39;s Half-Lightweight 0 0 0 0 1 0 7 #&gt; Judo Men&#39;s Half-Middleweight 0 0 1 0 0 0 7 #&gt; Judo Men&#39;s Heavyweight 0 0 0 0 0 0 7 #&gt; Judo Men&#39;s Lightweight 0 0 1 0 0 0 7 #&gt; [ reached getOption(&quot;max.print&quot;) -- omitted 9 rows ] Excel n’a aucune chance d’aller plus vite et R remporte le match par KO ! 2.3 Document Rmd : Word killer ? R-Studio dit : « Faisons une interface de rédaction adaptée à notre travail, Que l’utilisateur puissent y insérer les tableaux, les graphiques, les cartes, les références bibliographiques, et tous les écrits qui les commentent. » Nous venons de voir comment une bonne pratique de R peut conduire progressivement à abandonner l’usage des tableurs (Excel, Open Office) sauf peut-être pour l’étape de saisie des données. Dès lors qu’il s’agit de réaliser des graphiques ou des calculs statistiques complexes, la rédaction d’un programme se révèle beaucoup plus intéressante même si elle impose un coût initial d’apprentissage. Mais une bonne pratique de R ou plus précisément des documents R markdown peut vous conduire beaucoup plus loin et vous amener à abandonner également votre logiciel de traitement de texte (Word) et votre outil de présentation (Power Point). Le coût d’apprentissage est naturellement un peu plus élevé mais les bénéfices sont à la mesure de l’investissement. Comme le montre la figure ci-dessous, un document R markdown est en quelques sorte un mélange entre des lignes de code R qui executent des tâches et des lignes de texte où sont expliqués les calculs et commentés les résultats obtenus. En d’autres termes, un document R markdown vous permet de rédiger un article de recherche complet, une présentation à une conférence, un syllabus de cours, dans un seul environnement logiciel (R studio). Nul besoin de ciseau et de colle pour aller chercher tel tableau ici, tel figure là-bas ou telle carte ailleurs. Tous ces éléments sont intégrs au fur et à mesure de la rédaction ce qui facilite considérablement la concentration. Et surtout - on l’a déjà vu pour le programme R - le document peut facilement être reproduit ou mise à jour sans être obligé de réplique des dizaines de click de souris. On va supposer que l’on veut rédiger une fiche de synthèse d’une page sur une épreuve sportive comportant un tableau, un graphique et une carte 2.3.1 Préparation du document Rmarkdown On commence par rassembler dans un dossier les données dont nous aurons besoin et on les stocke dans des sous-dossiers. Dans l’exemple ci-dessous on a créé un dossier appelé olympic avec un sous-dossier data pour les tableaux statistiques, un dossier img pour les photographies et un dossier map pour les fonds de carte. Une fois que cela est fait, on crée un projet R dans le dossier ce qui entraîne la création du fichier `olympic.Rproj’. A l’intérieur de ce projet, on crée un document de type Rmd (R markdown) auquel on donne le titre “Tir à l’arc” et on le sauvegarde sous le nom Rapport.Rmd. 2.3.2 Préparation du plan Au moment de l’ouverture, le document ressemble à ceci: On garde le premier bloc de programme (en gris) et on élimine toute la partie créée par Rstudio pour servir d’exemple. On la remplace par notre plan en utilisant des instructions pour hiérarchiser les parties (##) , sous-parties (###) et sous-sous parties (####). On évitera d’utiliser (#) qui correspond à un titre de chapitre ou d’ouvrage. On clique alors sur le bouton “Knit” (une pelotte de laine bleue) pour visualiser le résultat qui s’affiche sous la forme d’une page .html. 2.3.3 Ajout d’images externes On décide de placer en tête de notre document une image d’une sportive française ayant obtenu la médaille de bronze au JO de Paris 2024. Il y a deux solution pour cela. Soit on utilise directement une commande Markdown, soit on crée un bloc de programme. Dans ce cas on utilisera la commande include_graphics() du package knitr et l’on précisera les paramètres de l’image dans l’en-tête du bloc de programme. Les résultats sont identiques mais la seconde solution est en général préférable car elle permet d’opérer des réglages plus précis, notamment pour les renvois. 2.3.4 Ajout de texte On rédige l’introduction de la note en tapant du texte et en ajoutant du gras ou de l’italique à l’aide des caractères spéciaux du langage Markdown. Dans l’exemple ci-dessous, on a également introduit un lien web vers une URL et une énumération sous forme de puces. Voici le résultat en html une fois que l’on a cliqué sur le bouton knit 2.3.5 Ajout d’un tableau On décide d’ajouter un tableau de l’ensemble des femmes qui ont été médaillées dans l’épreuve individuelle de tir à l’arc de 1992 à 2024. Pour que le tableau soit plus joli on va l’afficher avec la commande kable() du package knitr Voici le résultat dans la page .html 2.3.6 Ajout d’un graphique On souhaite comparer la taille des hommes et des femmes à l’aide d’une boîte à moustache. On introduit donc dans notre document markdown le bloc de code suivant : Ce qui donne le résultat suivant : 2.3.7 Ajout d’une carte Supposons pour finir qu’on veuille afficher une carte du Monde indiquant la répartition par pays des médailles du sport considéré. On dispose pour cela d’un fonds de carte des pays du Monde que l’on va charger pour ensuite visualiser le nombre de médailles par pays. Le programme est un peu plus complexe que les précédents et fait appel aux packages sfet map_sf qui sont spécialisées dans la cartographie. Voici le programme : Et le résultat : 2.4 Diapos Rmd : Power Point killer Lorsque l’on crée un fichier Markdown, on peut décider qu’il ne s’agit pas d’un document mais d’une présentation et opter pour l’un des deux modes par défaut appelés slidy et ioslides. On peut ensuite créer un diaporama en donnant un titre général et en séparant chaque diapo par un titre de niveau 2 correspondant à des lignes débutant par ## comme dans l’exemple ci-dessous : Il ne reste plus qu’à compiler le programme avec l’icône Knit (pelotte de laine) pour générer un document .html en forme de dipositives. 2.5 En résumé R est un Excel killer mais aussi un Word killer voire un Power point killer… Adopter R peut nuire gravement à vos habitudes antérieures de travail. "],["03-R-Base.html", "Partie 3 R-Base 3.1 Tableaux 3.2 Exploration I (var. quali.) 3.3 Exploration II (var. quanti) 3.4 Exploration III (2 variables) 3.5 En résumé", " Partie 3 R-Base Mise en place : Télécharger le dossier exo3 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo3.Rproj dans Rstudio. L’idée pédagogique est d’apprendre directement aux étudiants à programmer en R markdown plutôt qu’en R. Pourquoi ? Parce qu’ainsi ils vont simultanément : taper du code R qu’ils ignorent écrire sous ce code les explications du point de vue informatique observer les résultats statistiques interpréter ces résultats d’un point de vue statistique Cela n’a l’air de rien, mais en procédant ainsi les étudiants apprennent à produire à la fois leurs notes de cours en R, leurs notes de cours en statistiques et … le langage Rmarkdown pour rédiger leurs futurs travaux. Bref, si tout a bien marché, l’étudiant n’aura même pas besoin de consulter le présent document, si ce n’est pour vérifier que son programme donne les mêmes résultats … Les deux exercices qui suivent utilisent volontairement les fonctions de base du langage R (on dit que l’on programme en R-base) à l’exclusion de tout package c’est-à-dire de tout outil graphique ou statistique mis au point ultérieurement. Par comparaison avec le jeu de lego, cela revient à effectuer des constructions avec la boîte de base. A première vue cela peut sembler frustrant. Mais en réalité cela ne bride en rien l’imagination et permet d’apprendre plein de choses sans être distrait … La manipulation des tableaux de données : c’est-à-dire à la fois l’importation, le recodage éventuel des variables et la correction de leur type, la sélection de lignes ou de colonnes pour créer des sous-tableaux. L’exploration statistique univariée : c’est-à-dire le calcul de résumés simples d’une variable à l’aide de paramètres statistiques (valeurs centrales, dispersion) et la production de graphiques élémentaires. Pour rendre l’apprentissage moins austère, nous avons choisi un tableau de données original qui présente les principales caractéristiques de 25 pays européens en 1989, à la veille de la chute du Mur de Berlin. Pour ceux qui ne connaissent pas cette période ancienne, voici une petite carte : Plutôt que de se contenter apprendre par coeur des commandes R (ce qu’il faudra faire, évidemment), les étudiants seront amenés à construire un véritable rapport sur la situation économique, démographique et sociale de l’Europe en 1989, ce qui les amènera à renforcer leur pratique du R markdown. Par ailleurs, on organisera un débat entre les étudiants qui seront placés en deux groupes rivaux chargés de défendre respectivement les pays socialistes et lespays capitalistes. A chaque groupe de montrer que son système politique est le meilleur … 3.1 Tableaux 3.1.1 Importation 3.1.1.1 Localisation des fichiers La commande getwd() permet de connaître la position du répertoire courant. Si vous avez ouvert un projet (ce qui est vivement recommandé) la localisation est l’emplacement du fichier .Rproj. getwd() #&gt; [1] &quot;/Users/claudegrasland1/worldregio/bivaR&quot; La commande list.files() permet d’examiner le contenu du répertoire courant list.files() #&gt; [1] &quot;_bookdown_files&quot; &quot;_bookdown.yml&quot; #&gt; [3] &quot;_build_all.sh&quot; &quot;_build.sh&quot; #&gt; [5] &quot;_output.yml&quot; &quot;01-principes.Rmd&quot; #&gt; [7] &quot;02-office-killer.Rmd&quot; &quot;03-R-base.Rmd&quot; #&gt; [9] &quot;04-Corrélation.Rmd&quot; &quot;05-Régression.Rmd&quot; #&gt; [11] &quot;06-Anova.Rmd&quot; &quot;07-Tabcont.Rmd&quot; #&gt; [13] &quot;08-Graphique-Base.Rmd&quot; &quot;09-Graphique-ggplot.Rmd&quot; #&gt; [15] &quot;10-Tidyverse.Rmd&quot; &quot;bivaR_cache&quot; #&gt; [17] &quot;bivaR_files&quot; &quot;bivaR.Rmd&quot; #&gt; [19] &quot;bivaR.Rproj&quot; &quot;css&quot; #&gt; [21] &quot;DESCRIPTION&quot; &quot;docs&quot; #&gt; [23] &quot;index.Rmd&quot; &quot;js&quot; #&gt; [25] &quot;latex&quot; &quot;LICENSE&quot; #&gt; [27] &quot;oldversion&quot; &quot;README.md&quot; #&gt; [29] &quot;resources&quot; 3.1.1.2 Chargement d’un fichier texte Avec la souris Cliquer sur les menus déroulants File/Import Dataset/From text (base) puis suivre le menu Avec des lignes de code On utilise par exemple la fonction read.table() en précisant les paramètres utiles : euro1988 &lt;- read.table(file = &quot;resources/data/europe88/euro1988.csv&quot;, # nom du fichier et chemin d&#39;accès sep = &quot;;&quot;, # séparateur (ici, des points-virgule) header = TRUE, # ligne d&#39;en-tête avec le nom des variables encoding=&quot;UTF-8&quot;) # encodage adapté au français 3.1.1.3 Dimensions d’un tableau La fonction dim() fournit les dimensions d’un tableau dim(euro1988) #&gt; [1] 25 15 La fonction class() fournit le type d’un tableau class(euro1988) #&gt; [1] &quot;data.frame&quot; 3.1.1.4 Visualisation du contenu d’un tableau Premières lignes avec head() head(euro1988) # Affiche par défaut les 6 premières lignes #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 1 ALB Soc 600 43.0 71 34 27 6 3.3 35 5 29 3.1 4825115 1684833 #&gt; 2 AUT Cap 10000 10.3 75 55 12 12 1.4 18 14 84 7.6 4299715 2335579 #&gt; 3 BEL Cap 9200 9.7 75 95 12 11 1.5 19 14 31 9.9 3636312 2667243 #&gt; 4 BGR Soc 2000 14.5 72 65 13 11 2.0 21 11 111 9.0 5206070 1930219 #&gt; 5 CHE Cap 17800 6.8 77 61 12 9 1.5 17 14 41 6.6 3869378 2243130 #&gt; 6 CSK Soc 3200 13.9 71 74 14 12 2.0 24 11 128 15.6 4487005 2540281 Dernières lignes avec tail() tail(euro1988,2) # Affiche les 2 dernières lignes #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 24 SWE Cap 13200 5.9 77 83 12 11 1.8 18 18 450 8.4 4321587 3961396 #&gt; 25 YUG Soc 2300 27.1 70 47 15 8 2.1 24 8 256 23.6 4686147 1996737 3.1.1.5 Verification des variables Vérifie le type avec str() str(euro1988) #&gt; &#39;data.frame&#39;: 25 obs. of 15 variables: #&gt; $ PAYS: chr &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... #&gt; $ BLOC: chr &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Soc&quot; ... #&gt; $ PNB : int 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ... #&gt; $ TMI : num 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ... #&gt; $ ESP : int 71 75 75 72 77 71 72 75 75 76 ... #&gt; $ URB : int 34 55 95 65 61 74 77 94 84 91 ... #&gt; $ NAT : int 27 12 12 13 12 14 13 10 11 12 ... #&gt; $ MOR : int 6 12 11 11 9 12 13 11 11 8 ... #&gt; $ FEC : num 3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ... #&gt; $ JEU : int 35 18 19 21 17 24 19 15 18 23 ... #&gt; $ VIE : int 5 14 14 11 14 11 14 15 15 12 ... #&gt; $ SUP : int 29 84 31 111 41 128 108 248 43 505 ... #&gt; $ POP : num 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ... #&gt; $ X : num 4825115 4299715 3636312 5206070 3869378 ... #&gt; $ Y : num 1684833 2335579 2667243 1930219 2243130 ... Recode avec les fonctions as.xxx() euro1988$BLOC&lt;-as.factor(euro1988$PAYS) str(euro1988) #&gt; &#39;data.frame&#39;: 25 obs. of 15 variables: #&gt; $ PAYS: chr &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... #&gt; $ BLOC: Factor w/ 25 levels &quot;ALB&quot;,&quot;AUT&quot;,&quot;BEL&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... #&gt; $ PNB : int 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ... #&gt; $ TMI : num 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ... #&gt; $ ESP : int 71 75 75 72 77 71 72 75 75 76 ... #&gt; $ URB : int 34 55 95 65 61 74 77 94 84 91 ... #&gt; $ NAT : int 27 12 12 13 12 14 13 10 11 12 ... #&gt; $ MOR : int 6 12 11 11 9 12 13 11 11 8 ... #&gt; $ FEC : num 3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ... #&gt; $ JEU : int 35 18 19 21 17 24 19 15 18 23 ... #&gt; $ VIE : int 5 14 14 11 14 11 14 15 15 12 ... #&gt; $ SUP : int 29 84 31 111 41 128 108 248 43 505 ... #&gt; $ POP : num 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ... #&gt; $ X : num 4825115 4299715 3636312 5206070 3869378 ... #&gt; $ Y : num 1684833 2335579 2667243 1930219 2243130 ... 3.1.1.6 Résume du tableau La fonction summary() donne un aperçu général des variables summary(euro1988) #&gt; PAYS BLOC PNB TMI #&gt; Length:25 ALB : 1 Min. : 600 Min. : 5.80 #&gt; Class :character AUT : 1 1st Qu.: 2300 1st Qu.: 8.50 #&gt; Mode :character BEL : 1 Median : 8600 Median : 9.70 #&gt; BGR : 1 Mean : 7580 Mean :12.99 #&gt; CHE : 1 3rd Qu.:12000 3rd Qu.:14.50 #&gt; CSK : 1 Max. :17800 Max. :43.00 #&gt; (Other):19 #&gt; ESP URB NAT MOR FEC #&gt; Min. :70.00 Min. :30.00 Min. :10.0 Min. : 6.00 Min. :1.400 #&gt; 1st Qu.:72.00 1st Qu.:58.00 1st Qu.:12.0 1st Qu.: 9.00 1st Qu.:1.500 #&gt; Median :75.00 Median :71.00 Median :12.0 Median :11.00 Median :1.700 #&gt; Mean :73.72 Mean :68.44 Mean :13.4 Mean :10.36 Mean :1.816 #&gt; 3rd Qu.:75.00 3rd Qu.:83.00 3rd Qu.:14.0 3rd Qu.:11.00 3rd Qu.:2.000 #&gt; Max. :77.00 Max. :95.00 Max. :27.0 Max. :14.00 Max. :3.300 #&gt; #&gt; JEU VIE SUP POP #&gt; Min. :15.00 Min. : 5.00 Min. : 3.0 Min. : 0.40 #&gt; 1st Qu.:19.00 1st Qu.:11.00 1st Qu.: 70.0 1st Qu.: 6.60 #&gt; Median :19.00 Median :13.00 Median :128.0 Median :10.30 #&gt; Mean :21.16 Mean :12.52 Mean :190.7 Mean :19.83 #&gt; 3rd Qu.:23.00 3rd Qu.:14.00 3rd Qu.:301.0 3rd Qu.:23.60 #&gt; Max. :35.00 Max. :18.00 Max. :551.0 Max. :61.20 #&gt; #&gt; X Y #&gt; Min. :2498763 Min. :1535337 #&gt; 1st Qu.:3713871 1st Qu.:1996737 #&gt; Median :4166231 Median :2540281 #&gt; Mean :4091984 Mean :2572739 #&gt; 3rd Qu.:4686147 3rd Qu.:2851709 #&gt; Max. :5206070 Max. :4230412 #&gt; 3.1.2 Transformations 3.1.2.1 Copie intégrale Elle s’effectue avec l’opérateur &lt;- tab&lt;-euro1988 dim(tab) #&gt; [1] 25 15 head(tab,2) #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 1 ALB ALB 600 43.0 71 34 27 6 3.3 35 5 29 3.1 4825115 1684833 #&gt; 2 AUT AUT 10000 10.3 75 55 12 12 1.4 18 14 84 7.6 4299715 2335579 tail(tab,2) #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 24 SWE SWE 13200 5.9 77 83 12 11 1.8 18 18 450 8.4 4321587 3961396 #&gt; 25 YUG YUG 2300 27.1 70 47 15 8 2.1 24 8 256 23.6 4686147 1996737 3.1.2.2 Sélection de lignes On utilise la syntaxe tab2&lt;-tab[conditions , ] avec les opérateurs logiques suivants == : est égal à != : est différent de &gt; : est strictement supérieur à &lt; : est strictement inférieur à &gt;= : est supérieur ou égal à &lt;= : est inférieur ou égal à &amp; : ET (vrai si les deux conditions sont vérifiées) | : OU inclusif (vrai si l’une des conditions est vérifiée) xor : OU exclusif (vrai si une seule des conditions est vérifiée) Exemple de sélection des pays socialistes tabsoc&lt;-euro1988[euro1988$BLOC==&quot;Soc&quot;,] tabsoc #&gt; [1] PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; &lt;0 rows&gt; (or 0-length row.names) Exemple de sélection des pays non socialistes tabcap&lt;-euro1988[euro1988$BLOC!=&quot;Soc&quot;,] tabcap #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 1 ALB ALB 600 43.0 71 34 27 6 3.3 35 5 29 3.1 4825115 1684833 #&gt; 2 AUT AUT 10000 10.3 75 55 12 12 1.4 18 14 84 7.6 4299715 2335579 #&gt; 3 BEL BEL 9200 9.7 75 95 12 11 1.5 19 14 31 9.9 3636312 2667243 #&gt; 4 BGR BGR 2000 14.5 72 65 13 11 2.0 21 11 111 9.0 5206070 1930219 #&gt; 5 CHE CHE 17800 6.8 77 61 12 9 1.5 17 14 41 6.6 3869378 2243130 #&gt; 6 CSK CSK 3200 13.9 71 74 14 12 2.0 24 11 128 15.6 4487005 2540281 #&gt; 7 DDR DDR 3700 9.2 72 77 13 13 1.7 19 14 108 16.6 4166231 2825762 #&gt; 8 DEU DEU 12000 8.6 75 94 10 11 1.4 15 15 248 61.2 3962835 2640209 #&gt; 9 DNK DNK 12600 8.4 75 84 11 11 1.5 18 15 43 5.1 3958433 3234283 #&gt; 10 ESP ESP 4800 9.0 76 91 12 8 1.7 23 12 505 39.0 2875285 1646307 #&gt; 11 FIN FIN 12200 5.8 74 62 12 10 1.6 19 13 337 4.9 4774974 4230412 #&gt; 12 FRA FRA 10100 8.0 75 73 14 10 1.8 21 13 551 55.9 3441707 2245325 #&gt; 13 GBR GBR 8900 9.5 75 91 13 12 1.8 19 15 245 57.1 3212580 3065463 #&gt; [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 12 rows ] Exemple de sélection des pays de plus 10 millions d’habitant tabbig&lt;-euro1988[euro1988$POP&gt;20,] tabbig #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; 8 DEU DEU 12000 8.6 75 94 10 11 1.4 15 15 248 61.2 3962835 2640209 #&gt; 10 ESP ESP 4800 9.0 76 91 12 8 1.7 23 12 505 39.0 2875285 1646307 #&gt; 12 FRA FRA 10100 8.0 75 73 14 10 1.8 21 13 551 55.9 3441707 2245325 #&gt; 13 GBR GBR 8900 9.5 75 91 13 12 1.8 19 15 245 57.1 3212580 3065463 #&gt; 17 ITA ITA 8600 10.1 75 72 10 10 1.4 19 13 301 57.3 4184347 1884241 #&gt; 21 POL POL 2100 17.5 71 61 17 10 2.2 26 9 313 38.0 4622269 2851709 #&gt; 23 ROU ROU 1200 25.6 70 49 16 11 2.3 25 9 238 23.0 5120263 2251425 #&gt; 25 YUG YUG 2300 27.1 70 47 15 8 2.1 24 8 256 23.6 4686147 1996737 Exemple de sélection des pays socialistes de plus 20 millions d’habitant (on mélange deux conditions avec l’opérateur &amp;) tabsocbig&lt;-euro1988[euro1988$BLOC==&quot;Soc&quot; &amp; euro1988$POP&gt;20,] tabsocbig #&gt; [1] PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X Y #&gt; &lt;0 rows&gt; (or 0-length row.names) 3.1.2.3 Sélection de colonnes On utilise la syntaxe tab2&lt;-tab[ , liste ] avec différentes syntaxes pour les listes de variables : Sélection nominale tab&lt;-euro1988[,c(&quot;PAYS&quot;, &quot;BLOC&quot;, &quot;PNB&quot;, &quot;TMI&quot;,&quot;POP&quot;)] head(tab,2) #&gt; PAYS BLOC PNB TMI POP #&gt; 1 ALB ALB 600 43.0 3.1 #&gt; 2 AUT AUT 10000 10.3 7.6 Sélection de positions tab&lt;-euro1988[,c(1:4, 13)] head(tab,2) #&gt; PAYS BLOC PNB TMI POP #&gt; 1 ALB ALB 600 43.0 3.1 #&gt; 2 AUT AUT 10000 10.3 7.6 3.1.2.4 Sélection simultanée de lignes et colonnes On utilise la syntaxe tab2&lt;-tab[ conditions , liste] Exemple : PNB et BLOC des pays de moins de 5 millions d’habitant tab&lt;-euro1988[euro1988$POP&lt;5, c(&quot;PAYS&quot;,&quot;BLOC&quot;,&quot;POP&quot;,&quot;PNB&quot;)] tab #&gt; PAYS BLOC POP PNB #&gt; 1 ALB ALB 3.1 600 #&gt; 11 FIN FIN 4.9 12200 #&gt; 16 IRL IRL 3.5 5100 #&gt; 18 LUX LUX 0.4 16500 #&gt; 20 NOR NOR 4.2 15500 3.1.3 Extractions 3.1.3.1 Extraction d’une Variable = Vecteur Solution n°1 : utilisation de l’opérateur $ myvar&lt;-euro1988$POP str(myvar) #&gt; num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ... mean(myvar) #&gt; [1] 19.828 -Solution n°2 : utilisation de [ , ] myvar&lt;-euro1988[,13] str(myvar) #&gt; num [1:25] 3.1 7.6 9.9 9 6.6 15.6 16.6 61.2 5.1 39 ... mean(myvar) #&gt; [1] 19.828 3.1.3.2 Création d’une matrice On sélectionne les lignes et les colonnes puis on convertit en matrice avec l’instruction as.matrix(). Attention, les variables doivent être de même type (toutes numériques ou toutes caractère ou …), sinon R effectue une conversion forcée. Exemple 1 : création d’une matrice de corrélation On commence par extraire trois variables du tableau pour en faire une matrice : mymat&lt;-euro1988[,c(&quot;PNB&quot;,&quot;TMI&quot;,&quot;FEC&quot;)] row.names(mymat)&lt;-euro1988$PAYS # facultatif : donne le nom des lignes str(mymat) #&gt; &#39;data.frame&#39;: 25 obs. of 3 variables: #&gt; $ PNB: int 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ... #&gt; $ TMI: num 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ... #&gt; $ FEC: num 3.3 1.4 1.5 2 1.5 2 1.7 1.4 1.5 1.7 ... mymat&lt;-as.matrix(mymat) str(mymat) #&gt; num [1:25, 1:3] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ... #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ : chr [1:25] &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... #&gt; ..$ : chr [1:3] &quot;PNB&quot; &quot;TMI&quot; &quot;FEC&quot; Puis on applique la fonction cor() à cette matrice pour en faire une matrice de corrélation ; mycor&lt;-cor(mymat) mycor #&gt; PNB TMI FEC #&gt; PNB 1.0000000 -0.6584308 -0.6144008 #&gt; TMI -0.6584308 1.0000000 0.8136871 #&gt; FEC -0.6144008 0.8136871 1.0000000 str(mycor) #&gt; num [1:3, 1:3] 1 -0.658 -0.614 -0.658 1 ... #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ : chr [1:3] &quot;PNB&quot; &quot;TMI&quot; &quot;FEC&quot; #&gt; ..$ : chr [1:3] &quot;PNB&quot; &quot;TMI&quot; &quot;FEC&quot; Exemple 2 : Création d’une matrice de distance On commence par extraire les coordonnées (X,Y) sous forme de matrice matcoo&lt;-as.matrix(euro1988[,c(&quot;X&quot;,&quot;Y&quot;)]) row.names(matcoo)&lt;-euro1988$PAYS # facultatif : donne le nom des lignes str(matcoo) #&gt; num [1:25, 1:2] 4825115 4299715 3636312 5206070 3869378 ... #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ : chr [1:25] &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... #&gt; ..$ : chr [1:2] &quot;X&quot; &quot;Y&quot; head(matcoo) #&gt; X Y #&gt; ALB 4825115 1684833 #&gt; AUT 4299715 2335579 #&gt; BEL 3636312 2667243 #&gt; BGR 5206070 1930219 #&gt; CHE 3869378 2243130 #&gt; CSK 4487005 2540281 Puis on transforme ces coordonnées en distance à l’aide de la fonction dist() matdis&lt;-as.matrix(dist(matcoo)) str(matdis) #&gt; num [1:25, 1:25] 0 836370 1542200 453145 1106855 ... #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ : chr [1:25] &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... #&gt; ..$ : chr [1:25] &quot;ALB&quot; &quot;AUT&quot; &quot;BEL&quot; &quot;BGR&quot; ... matdis[1:10,1:5] #&gt; ALB AUT BEL BGR CHE #&gt; ALB 0.0 836370.2 1542200.5 453144.9 1106855.4 #&gt; AUT 836370.2 0.0 741690.6 992872.1 440155.5 #&gt; BEL 1542200.5 741690.6 0.0 1734169.4 483933.6 #&gt; BGR 453144.9 992872.1 1734169.4 0.0 1372828.3 #&gt; CHE 1106855.4 440155.5 483933.6 1372828.3 0.0 #&gt; CSK 919842.9 277453.7 860114.5 942990.5 685391.6 #&gt; DDR 1317515.9 508033.5 553120.4 1372320.3 653897.6 #&gt; DEU 1286962.2 454189.8 327639.9 1431684.2 407929.4 #&gt; DNK 1775368.8 961323.9 652147.5 1804766.4 995146.1 #&gt; ESP 1950211.4 1582434.4 1273370.9 2348013.0 1159491.1 Et on calcule le pays le plus proche de tous les autres à l’aide de la fonction apply() (qu’on verra ultérieurement dans un autre chapitre) mean(matdis) #&gt; [1] 1262347 access&lt;-apply(matdis, FUN=mean,1) access&lt;-access[order(access)] round(access,0) #&gt; DEU AUT DDR LUX CSK CHE BEL NLD HUN POL #&gt; 898957 926937 932604 944407 954421 966312 981428 984509 1043514 1062733 #&gt; ITA DNK FRA YUG GBR ROU ALB BGR GRC IRL #&gt; 1095500 1105659 1125130 1133254 1301552 1309032 1348834 1450710 1558508 1559733 #&gt; SWE NOR ESP FIN PRT #&gt; 1592972 1692199 1701144 1923979 1964658 3.2 Exploration I (var. quali.) 3.2.1 Sélection et recodage Les variables qualitatives nominales ou factor sont des objets composés d’une liste de numéros et d’une liste d’étiquettes. # Chargement du tableau de données don &lt;- read.table(file = &quot;resources/data/europe88/euro1988.csv&quot;, # nom du fichier et chemin d&#39;accès sep = &quot;;&quot;, # séparateur (ici, des points-virgule) header = TRUE, # ligne d&#39;en-tête avec le nom des variables encoding=&quot;UTF-8&quot;) # encodage adapté au français # Extraction de la variable X&lt;-don$BLOC X #&gt; [1] &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; #&gt; [13] &quot;Cap&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Cap&quot; #&gt; [25] &quot;Soc&quot; # Vérification du type str(X) #&gt; chr [1:25] &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Soc&quot; &quot;Soc&quot; &quot;Cap&quot; &quot;Cap&quot; &quot;Cap&quot; ... Si la variable chargée est de type character il faut la transformer avec as.factor() et repérer les niveaux disponibles avec levels() X&lt;-as.factor(X) class(X) #&gt; [1] &quot;factor&quot; levels(X) #&gt; [1] &quot;Cap&quot; &quot;Soc&quot; On peut remplacer les niveaux en utilisant l’instruction levels()à nouveau, mais suivie d’un vecteur de charactères indiquant les changements de nom. levels(X)&lt;-c(&quot;Capitaliste&quot;, &quot;Socialiste&quot;) X #&gt; [1] Socialiste Capitaliste Capitaliste Socialiste Capitaliste Socialiste #&gt; [7] Socialiste Capitaliste Capitaliste Capitaliste Capitaliste Capitaliste #&gt; [13] Capitaliste Capitaliste Socialiste Capitaliste Capitaliste Capitaliste #&gt; [19] Capitaliste Capitaliste Socialiste Capitaliste Socialiste Capitaliste #&gt; [25] Socialiste #&gt; Levels: Capitaliste Socialiste str(X) #&gt; Factor w/ 2 levels &quot;Capitaliste&quot;,..: 2 1 1 2 1 2 2 1 1 1 ... On peut transformer une variable quantitative en facteur avec la fonction cut() Y&lt;-cut(don$POP, breaks=c(0,10,30,100)) Y #&gt; [1] (0,10] (0,10] (0,10] (0,10] (0,10] (10,30] (10,30] (30,100] #&gt; [9] (0,10] (30,100] (0,10] (30,100] (30,100] (10,30] (10,30] (0,10] #&gt; [17] (30,100] (0,10] (10,30] (0,10] (30,100] (10,30] (10,30] (0,10] #&gt; [25] (10,30] #&gt; Levels: (0,10] (10,30] (30,100] str(Y) #&gt; Factor w/ 3 levels &quot;(0,10]&quot;,&quot;(10,30]&quot;,..: 1 1 1 1 1 2 2 3 1 3 ... On peut ensuite recoder les classes avec levels() levels(Y)&lt;-c(&quot;Petit&quot;,&quot;Moyen&quot;,&quot;Grand&quot;) Y #&gt; [1] Petit Petit Petit Petit Petit Moyen Moyen Grand Petit Grand Petit Grand #&gt; [13] Grand Moyen Moyen Petit Grand Petit Moyen Petit Grand Moyen Moyen Petit #&gt; [25] Moyen #&gt; Levels: Petit Moyen Grand str(Y) #&gt; Factor w/ 3 levels &quot;Petit&quot;,&quot;Moyen&quot;,..: 1 1 1 1 1 2 2 3 1 3 ... 3.2.2 Table de dénombrement Pour dénomber une variable qualitative, on utilise l’instruction table() qui crée un objet particulier qui n’est ni un data.frame, ni une matrix. tab&lt;-table(X) tab #&gt; X #&gt; Capitaliste Socialiste #&gt; 17 8 str(tab) #&gt; &#39;table&#39; int [1:2(1d)] 17 8 #&gt; - attr(*, &quot;dimnames&quot;)=List of 1 #&gt; ..$ X: chr [1:2] &quot;Capitaliste&quot; &quot;Socialiste&quot; On peut créer des tables à 2, 3 ou 4 dimensions tab2&lt;-table(X,Y) tab2 #&gt; Y #&gt; X Petit Moyen Grand #&gt; Capitaliste 9 3 5 #&gt; Socialiste 2 5 1 str(tab2) #&gt; &#39;table&#39; int [1:2, 1:3] 9 2 3 5 5 1 #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ X: chr [1:2] &quot;Capitaliste&quot; &quot;Socialiste&quot; #&gt; ..$ Y: chr [1:3] &quot;Petit&quot; &quot;Moyen&quot; &quot;Grand&quot; Un objet de type table peut être manipulé par des fonctions spéciales comme addmargins() quii rajoute des sommes en ligne (et en colonne si la table est de dimension 2) addmargins(tab) #&gt; X #&gt; Capitaliste Socialiste Sum #&gt; 17 8 25 addmargins(tab2) #&gt; Y #&gt; X Petit Moyen Grand Sum #&gt; Capitaliste 9 3 5 17 #&gt; Socialiste 2 5 1 8 #&gt; Sum 11 8 6 25 Les objets de type table sont souvent la source de crises de nerf de la part des étudiants qui les confondent avec des objets de type vecteur, matrice ou data.frame. Il existe des fonctions de conversion d’un type vers un autre mais leur emploi n’est pas très simple. On retiendra donc dans l’immédiat que les résultats de l’instruction tablesont des objets transitoires qui servent uniquement à afficher des résultats ou produire des graphiques à l’aide des instructions plot() ou barplot(). 3.2.3 Graphique avec plot() La fonction plot() s’applique à la plupart de objets R. Elle produit des résultats différents selon le type d’objet qu’elle a identifié. Si on l’applique à un vecteur de type factor on obtient un diagramme en bâtons (à ne pas confondre avec un histogramme) plot(X) On peut améliorer le graphique en lui ajoutant des paramètres c’est-à-dire des instructions séparées par des virgules. Le retour à la ligne après chaque paramètre n’est pas obligatoire mais il est recommandé car il rend le code plus clair. plot(X, col=c(&quot;blue&quot;,&quot;red&quot;), main= &quot;Europe en 1988&quot;, xlab = &quot;Type politique&quot;, ylab = &quot;Nombre de pays&quot;) 3.3 Exploration II (var. quanti) 3.3.1 Résumés numériques Une variable numérique peut faire l’objet d’un ensemble de résumés statistiques à l’aide de fonctions élémentaires min() : minimum max() : maximum mean() : moyenne sd() : écart-type (en anglais : standard deviation, soit sd en abrégé) sum() : somme X &lt;- don$FEC min(X) #&gt; [1] 1.4 max(X) #&gt; [1] 3.3 mean(X) #&gt; [1] 1.816 sd(X) #&gt; [1] 0.4160128 Pour calculer les quantiles on peut utiliser la fonction quantile() en paramétrant la valeur de fréquence cumulée ascendante quantile(X,0) : minimum quantile(X,0.10) : D1 (premier décile) quantile(X,0.25) : Q1 (premier quartile) quantile(X,0.5) : Q2 (médiane) quantile(X,0.75) : Q3 (troisième quartile) quantile(X,0.90) : D9 (dernier décile) quantile(X,1) : maximum X&lt;-don$FEC quantile(X,0.5) #&gt; 50% #&gt; 1.7 sel&lt;-c(0,0.25,0.5,0.75,1) quantile(X,sel) #&gt; 0% 25% 50% 75% 100% #&gt; 1.4 1.5 1.7 2.0 3.3 sel&lt;-c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1) quantile(X,sel) #&gt; 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% #&gt; 1.40 1.44 1.50 1.60 1.70 1.70 1.80 1.80 2.02 2.26 3.30 Il peut arriver qu’une fonction soit manquante dans R, comme par exemple le coefficient de variation. Dans ce cas, on peut faire le calcul par des lignes de code ou créer sa propre fonction avec l’instruction function(). La fonction qui est stockée en mémoire apparaît dans la fenêtre Environnement. Lorsqu’on a créé plusieurs fonctions, on peut en faire un programme R qu’on charge en mémoire au début de chaque session. A plus long terme, on peut en faire un package qu’on partagera avec les autres utilisateurs de R. A titre d’exemple, nous créons une fonction cv() qui calcule le rapport entre l’écart-type et la moyenne d’une distribution : # lignes de code X &lt;- don$FEC sd(X)/mean(X) #&gt; [1] 0.2290819 # fonction cv&lt;-function(var) {sd(var)/mean(var)} cv(X) #&gt; [1] 0.2290819 3.3.2 Dénombrement Une variable quantitative peut être discrétisée avec cut(). Elle devient alors un facteur qu’on peut dénomber avec table() puis visualiseer avec plot() sous la forme de diagramme en bâtons. X&lt;-cut(don$FEC, c(1,1.5,2,2.5,3,3.5)) str(X) #&gt; Factor w/ 5 levels &quot;(1,1.5]&quot;,&quot;(1.5,2]&quot;,..: 5 1 1 2 1 2 2 1 1 2 ... table(X) #&gt; X #&gt; (1,1.5] (1.5,2] (2,2.5] (2.5,3] (3,3.5] #&gt; 7 13 4 0 1 plot(X, col=c(&quot;green&quot;,&quot;yellow&quot;,&quot;orange&quot;,&quot;red&quot;,&quot;brown&quot;), main = &quot;Fécondité en Europe en 1988&quot;, xlab = &quot;classes&quot;) 3.3.3 Boîte à moustaches La fonction boxplot() permet de visualiser une distribution sous forme de boîte à moustache où l’on repère facilement : la médiane les quartiles Q1 et Q3 le minimum et le maximum les valeurs extrêmes situées à une distance supéreiure à 1.5 x (Q3-Q1) de la médiane La syntaxe de base est la suivante : X&lt;-don$FEC boxplot(X) Mais on peut améliorer la figure avec quelques paramètres de plus boxplot(X,horizontal = TRUE, col = &quot;gray80&quot;, main = &quot;Fécondité des pays européens en 1988&quot;, xlab = &quot;nb. enfants par femme&quot;) Et on peut retirer les valeurs exceptionnelles avec le paramètre outline=FALSE boxplot(X,horizontal = TRUE, col = &quot;gray80&quot;, main = &quot;Fécondité des pays européens en 1988&quot;, xlab = &quot;nb. enfants par femme&quot;, outline = FALSE) 3.3.4 Histogramme Dans le cas d’une variable quantitative continue, la visualisation la plus logique est l’histogramme que l’on peut tracer avec la fonction hist(). Celle-ci comporte de nombreux paramètres que l’on peut visualiser dans la fenêtre Help qui se trouve en bas à gauche de R-studio : Comme d’hebitude, on peut appliquer la syntaxe la plus simple : X&lt;-don$FEC hist(X) On peut ensuite améliorer avec l’ajout de titres et un choix précis de classes. Dans le cas de la fécondité, il est par exemple important d’utiliser le seuil de 2.1 enfants par femme qui correspond au renouvellement des générations. On remarque que si les classes sont d’amplitudes inégales R utilise la densité de probabilité (rapport entre effectif et amplitude de la classe) et non plus l’effectif ce qui est statistiquement correct (et que ne fait pas Excel …). hist(X, breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3), col=c(&quot;blue&quot;, &quot;lightblue&quot;,&quot;lightyellow&quot;,&quot;orange&quot;,&quot;red&quot;), main = &quot;Fécondité des pays européens en 1988&quot;, ylab = &quot;Densité de probabilité&quot;, xlab = &quot;Nombre d&#39;enfants par femme&quot;, xlim=c(1,3.5)) On peut également ajouter une courbe lissée de la distribution avec les fonctions lines() etdensity()en indiquant la portée du lissage à l'aide du paramètrebw`(band width) qui est exprimé dans l’unité de mesure de X hist(X, breaks = c(1.2, 1.5, 1.8, 2.1, 2.4, 3.3), col=c(&quot;blue&quot;, &quot;lightblue&quot;,&quot;green&quot;,&quot;yellow&quot;,&quot;orange&quot;), main = &quot;Fécondité des pays européens en 1988&quot;, ylab = &quot;Densité de probabilité&quot;, xlab = &quot;Nombre d&#39;enfants par femme&quot;, xlim=c(1,3.5)) lines(density(X,bw=0.3),col=&quot;red&quot;,lwd=2) 3.4 Exploration III (2 variables) Nous verrons en détail dans les chapitres suivants comment croiser deux variables d’un point de vue statistiques. Mais on peut déjà indiquer brièvement comment les visualiser rapidement à l’aide de trois exemples 3.4.1 Deux variables qualitatives Tableau de contingence X &lt;- don$BLOC levels(X)&lt;-c(&quot;Capitalise&quot;,&quot;Socialiste&quot;) Y&lt;-cut(don$POP, breaks=c(0,10,30,100)) levels(Y) &lt;- c(&quot;petit&quot;,&quot;moyen&quot;,&quot;grand&quot;) tab&lt;-table(X,Y) addmargins(tab) #&gt; Y #&gt; X petit moyen grand Sum #&gt; Cap 9 3 5 17 #&gt; Soc 2 5 1 8 #&gt; Sum 11 8 6 25 Graphique plot(tab, col=c(&quot;yellow&quot;,&quot;orange&quot;,&quot;brown&quot;)) Test (Chi-2) test&lt;-chisq.test(X,Y) #&gt; Warning in chisq.test(X, Y): Chi-squared approximation may be incorrect test #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: X and Y #&gt; X-squared = 5.0336, df = 2, p-value = 0.08072 3.4.2 Deux variables quantitatives Paramètres principaux Y &lt;- don$TMI X&lt;-don$PNB summary(X) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 600 2300 8600 7580 12000 17800 summary(Y) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 5.80 8.50 9.70 12.99 14.50 43.00 Graphique plot(X,Y, xlab=&quot;PNB par habitant&quot;,ylab=&quot;Mortalité infantile&quot;) text(X,Y,don$PAYS,pos = 4,cex=0.6) Test (Pearson) cor.test(Y,X) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: Y and X #&gt; t = -4.1955, df = 23, p-value = 0.0003459 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -0.8360497 -0.3558907 #&gt; sample estimates: #&gt; cor #&gt; -0.6584308 3.4.3 Une quantitative et une qualitative Graphique Y &lt;- don$TMI X &lt;- as.factor(don$BLOC) levels(X)&lt;-c(&quot;Capitalise&quot;,&quot;Socialiste&quot;) plot(X,Y, col=c(&quot;blue&quot;,&quot;red&quot;), xlab =&quot;Mortalité infantile&quot;, ylab = &quot;Bloc politique&quot;, horizontal=T) - Test (Fischer) mod&lt;-aov(Y~X) summary(mod) #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; X 1 797.4 797.4 20.85 0.000137 *** #&gt; Residuals 23 879.7 38.2 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.5 En résumé Nous avons survolé les principales fonctions élémentaires de R-Base pour montrer qu’il est facile et surtout rapide de les employer en lieu et place d’un tableur comme Excel ou d’un logiciel de statistique click-bouton. Il reste encore beaucoup à apprendre mais à ce stade il est important de bien consolider les acquis et de connaître par coeur le nom des principales fonctions de base qui ont été présentées au cours de ce chapitre. "],["04-Corrélation.html", "Partie 4 Corrélation 4.1 Préparation des données 4.2 Exploration visuelle 4.3 Coefficients de corrélation 4.4 Matrice de corrélation", " Partie 4 Corrélation Mise en place : Télécharger le dossier exo4 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo4.Rproj dans Rstudio. 4.1 Préparation des données 4.1.1 Chargement du tableau principal On charge notre bon vieux fichier des pays européens en 1988 don&lt;-read.table(file = &quot;resources/data/europe88/euro1988.csv&quot;, sep = &quot;;&quot;, header = T) don$BLOC&lt;-as.factor(don$BLOC) levels(don$BLOC)&lt;-c(&quot;Capitaliste&quot;,&quot;Socialiste&quot;) head(don) #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X #&gt; 1 ALB Socialiste 600 43.0 71 34 27 6 3.3 35 5 29 3.1 4825115 #&gt; 2 AUT Capitaliste 10000 10.3 75 55 12 12 1.4 18 14 84 7.6 4299715 #&gt; 3 BEL Capitaliste 9200 9.7 75 95 12 11 1.5 19 14 31 9.9 3636312 #&gt; 4 BGR Socialiste 2000 14.5 72 65 13 11 2.0 21 11 111 9.0 5206070 #&gt; 5 CHE Capitaliste 17800 6.8 77 61 12 9 1.5 17 14 41 6.6 3869378 #&gt; 6 CSK Socialiste 3200 13.9 71 74 14 12 2.0 24 11 128 15.6 4487005 #&gt; Y #&gt; 1 1684833 #&gt; 2 2335579 #&gt; 3 2667243 #&gt; 4 1930219 #&gt; 5 2243130 #&gt; 6 2540281 4.1.2 Choix des deux variables à analyser En dehors de BLOC et PAYS, on ne garde que deux variables que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses. eur&lt;-don[,c(&quot;PAYS&quot;,&quot;BLOC&quot;,&quot;URB&quot;,&quot;TMI&quot;)] colnames(eur)&lt;-c(&quot;PAYS&quot;,&quot;BLOC&quot;,&quot;X&quot;,&quot;Y&quot;) eur$X&lt;-as.numeric(eur$X) eur$Y&lt;-as.numeric(eur$Y) head(eur) #&gt; PAYS BLOC X Y #&gt; 1 ALB Socialiste 34 43.0 #&gt; 2 AUT Capitaliste 55 10.3 #&gt; 3 BEL Capitaliste 95 9.7 #&gt; 4 BGR Socialiste 65 14.5 #&gt; 5 CHE Capitaliste 61 6.8 #&gt; 6 CSK Socialiste 74 13.9 4.1.3 On est malin … Mais comme on ne sait plus ce que sont X et Y, on le précise avec des chaînes de caractères qu’on pourra utiliser dans les graphiques. Et on peut préparer une version multilangue … # Pour la version française fr_titre &lt;- &quot;Les pays européens en 1988&quot; fr_nomX &lt;- &quot;Taux d&#39;urbanisation en %&quot; fr_nomY &lt;- &quot;Taux de mortalité infantile en p. 1000&quot; fr_auteur &lt;- &quot;Claude Grasland, Université Paris Diderot, 2020&quot; # Pour la version arabe ar_titre &lt;- &quot;البلدان الأوروبية في عام 1988&quot; ar_nomX &lt;- &quot;معدل التحضر في المائة&quot; ar_nomY &lt;- &quot;معدل وفيات الرضع في عام 1000&quot; ar_auteur &lt;- &quot;كلود غراسلاند، جامعة باريس ديدرو، 2020&quot; # Pour la version anglaise en_titre &lt;- &quot;European countries in 1988&quot; en_nomX &lt;- &quot;Urbanisation rate %&quot; en_nomY &lt;- &quot;Infant mortality rate p. 1000&quot; en_auteur &lt;- &quot;Claude Grasland, University Paris Diderot, 2020&quot; # Pour la version russe ru_titre &lt;- &quot;Европейские страны в 1988 году&quot; ru_nomX &lt;- &quot;Уровень урбанизации в %&quot; ru_nomY &lt;- &quot;Коэффициент младенческой смертности в 1000 году&quot; ru_auteur &lt;- &quot;Клод Грассленд, Парижский университет Дидро, 2020&quot; 4.1.4 On est paresseux … Comme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux eur_soc&lt;-eur[eur$BLOC==&quot;Socialiste&quot;,] eur_cap&lt;-eur[eur$BLOC==&quot;Capitaliste&quot;,] 4.2 Exploration visuelle 4.2.1 Visualisation avec plot(X,Y) La manière la plus simple d’analyser la relation entre X et Y est d’utiliser un simple plot plot(eur$X,eur$Y) La fonction plot() comporte de nombreux paramètres permettant d’améliorer le graphique et de l’habiller. Voici un exemple d’habillage en français plot(eur$X,eur$Y, main = fr_titre, # titre cex.main = 1, # police du titre sub = fr_auteur, # sous-titre cex.sub = 0.6, # police du sous-titre xlab = fr_nomX, # nom de l&#39;axe X xlim = c(20,100), # intervalle de l&#39;axe X ylab = fr_nomY, # nom de l&#39;axe Y ylim = c(0,50), # intervalle de l&#39;axe Y cex.axis = 0.8, # police des gradations d&#39;axes cex.lab = 0.8, # police des noms d&#39;axes cex = 0.6, # taille des symboles col = &quot;blue&quot;) # couleur des symboles Ou en anglais: il suffit de changer le nom des variables relatives aux titres. plot(eur$X,eur$Y, main = en_titre, # titre cex.main = 1, # police du titre sub = en_auteur, # sous-titre cex.sub = 0.5, # police du sous-titre xlab = en_nomX, # nom de l&#39;axe X xlim = c(20,100), # intervalle de l&#39;axe X ylab = en_nomY, # nom de l&#39;axe Y ylim = c(0,50), # intervalle de l&#39;axe Y cex.axis = 0.7, # police des gradations d&#39;axes cex.lab = 0.7, # police des noms d&#39;axes cex = 0.6, # taille des symboles col = &quot;blue&quot;) # couleur des symboles 4.2.2 Identification des points avec cor + text(…) On peut ajouter au graphique généré par plot(X,Y) une couche de labels avec text(X,Y,Code). On précise la position avec pos =, la taille de police avex cex = et la couleur avec col =. plot(x = eur$X, y = eur$Y, cex=0.5, col= &quot;blue&quot;, ylim =c(0,50)) text(x = eur$X, y = eur$Y, label = eur$PAYS, cex = 0.7, pos=3, col = &quot;blue&quot;) 4.2.3 Ajout de lignes horizontales ou verticales avec cor() + abline(…) On peut rajouter à un graphique des lignes horizontales ou verticales avec abline en précisant leur position avec h= ou v=, leur épaisseur avec lwd = , leur style avec lty= et leur couleur avec col= plot(eur$X,eur$Y, main = fr_titre, # titre cex.main = 1, # police du titre sub = fr_auteur, # sous-titre cex.sub = 0.6, # police du sous-titre xlab = fr_nomX, # nom de l&#39;axe X xlim = c(20,100), # intervalle de l&#39;axe X ylab = fr_nomY, # nom de l&#39;axe Y ylim = c(0,50), # intervalle de l&#39;axe Y cex.axis = 0.8, # police des gradations d&#39;axes cex.lab = 0.8, # police des noms d&#39;axes cex = 0.6, # taille des symboles col = &quot;blue&quot;) # couleur des symboles # Ajout d&#39;une ligne horizontale correspondant à la moyenne de Y abline(h=mean(eur$Y),col=&quot;red&quot;,lwd = 1, lty = 2) # Ajout d&#39;une ligne verticlae correspondant à la moyenne de X abline(v=mean(eur$X),col=&quot;red&quot;,lwd = 1, lty = 2) text(x = eur$X, y = eur$Y, label = eur$PAYS, cex = 0.6, pos=3, col = &quot;blue&quot;) La fonction abline() peut servir aussi à tracer la droite de régression Y=aX+b produite par la fonction lm() plot(eur$X,eur$Y) maregression = lm(eur$Y~eur$X) abline(maregression,col=&quot;red&quot;) 4.2.4 Au delà de R-Base … Il existe des packages spécialisés permettant de faire des graphiques plus sophistiqués. Mais on les apprendra ultérieuement. Juste un exemple : library(car) scatterplot(eur$X,eur$Y) 4.3 Coefficients de corrélation 4.3.1 Définition 4.3.1.1 Relation linéaire/monotone/complexe il existe une relation linéaire entre deux variables quantitatives X et Y si l’on peut prédire leurs valeurs respectives par les fonctions Y = a1.X + b1 et X = a2.X = b2 il existe une relation monotone entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X far une fonction Y=f(X) qui est strictement croissante ou strictement décroissante. il existe une relation complexe entre deux variables quantitatives X et Y si l’on peut prédire les valeurs Y en fonction de celle de X par une fonction Y=f(X) qui comporte au moins un point minimum ou maximum de changement de pente (annulation de la dérivée première) 4.3.1.2 Relation positive/négative/nulle Une relation linéaire ou monotone est positive si à un accroissement de X correspond un accroissement de Y Une relation linéaire ou monotone est négative si à un accroissement de X correspond une diminution de Y une relation est nulle si une variation de X n’entraine pas de variation de Y 4.3.1.3 Relation forte/faible/nulle Une relation linéaire est forte si une valeur de X permet de prédire la valeur de Y avec une faible marge d’erreur. Une relation linéaire ou monotone est faible si une valeur de X permet de prédire la valeur de Y avec une forte marge d’erreur. une relation linéaire est nulle si une valeur de X ne permet aucunement de prédire la valeur de Y 4.3.1.4 Relation significative/non siginificative Une relation linéaire est significative si l’effectif permettant de la mettre en évidence est suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard. Une relation linéaire ou monotone est non significative si l’effectif permettant de la mettre en évidence n’est pas suffisamment grand pour qu’on puisse exclure qu’elle soit l’effet du hasard. On considère traditionnellement qu’une relation est significative s’il y a moins de 5% de chances qu’elle soit l’effet du hasard (p-value &lt; 0.05). 4.3.2 La fonction cor() La fonction cor() permet de mesurer le coefficient de corrélation de deux variable X et Y. Elle permet de détecter les relations linéaires en choisissant le paramètre (par défaut) method = pearson Elle permet de détecter les relations non linéaires en choisissant le paramètre method = spearman qui mesure l’existence d’une relation monotone entre les rangs de X et Y La syntaxe de la fonction cor() est très simple et permet de calculer trois types de corrélation. La méthode par défaut est pearson c’est-à-dire le coefficient de corrélation linéaire cor(eur$X,eur$Y) #&gt; [1] -0.6547219 cor(eur$X,eur$Y, method = &quot;spearman&quot;) #&gt; [1] -0.5699443 cor(eur$X,eur$Y, method = &quot;kendall&quot;) #&gt; [1] -0.4053653 cor() permet de savoir si la relation est linéaire ou monotone cor() permet de repérer l’effet d’une valeur exceptionnelle cor() permet de savoir si la relation est positive ou négative cor() permet de avoir si la relation est forte ou faible 4.3.3 La fonction cor.test() la fonction cor() permet de savoir si une relation est forte ou faible, positive ou négative, linéaire ou non linéaire. Mais cor() ne permet pas de savoir si une relation est significative ou pas. C’est la fonction cor.test() qui permet de tester la significativité d’une relation en fournissant un intervalle de confiance du coefficient de corrélation et une probabilité de rejet de H0 : il n’y a pas de relation appelée en anglais la p-value. p-value &gt; 0.10 : relation non significative 0.10 &gt; p-value &gt; 0.05 : relation presque significative p-value &lt; 0.05 : relation significative p-value &lt; 0.01 : relation très significative Même syntaxe que cor() : cor.test(eur$Y,eur$X) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: eur$Y and eur$X #&gt; t = -4.1541, df = 23, p-value = 0.0003835 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -0.8340765 -0.3501838 #&gt; sample estimates: #&gt; cor #&gt; -0.6547219 cor.test(eur$Y,eur$X, method=&quot;spearman&quot;) #&gt; Warning in cor.test.default(eur$Y, eur$X, method = &quot;spearman&quot;): Cannot compute #&gt; exact p-value with ties #&gt; #&gt; Spearman&#39;s rank correlation rho #&gt; #&gt; data: eur$Y and eur$X #&gt; S = 4081.9, p-value = 0.002936 #&gt; alternative hypothesis: true rho is not equal to 0 #&gt; sample estimates: #&gt; rho #&gt; -0.5699443 4.3.4 En résumé : intensité ou significativité ? Le carré du coefficient de corrélation appelé r-square ou r2 permet de mesurer le pouvoir explicatif de X par rapport à Y. Il ne dépend pas du nombre d’observations. le test de significativité ou p-value mesure la significativité de la relation c’est-à-dire le fait que la relation entre X et Y ne soit pas l’effet du hasard. Il dépend à la fois du niveau de corrélation et du nombre d’observations. A gauche : une relation forte mais non significative A droite : une relation faible mais très significative Analysez le diagramme suivant : Analysez les deux diagrammes suivants : 4.4 Matrice de corrélation 4.4.1 Objectif de l’analyse Soit un ensemble de variables quantitatives continues \\((X_1...X_i...X_k)\\) décrivant les mêmes individus. On se propose de construire la matrice \\(R_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) leur coefficient de corrélation (linéaire ou de rang) Puis de construire la matrice \\(p_{ij}[1...i...k ; 1...j...k]\\) indiquant pour chaque paire de variable \\(ij\\) la probabilité H0 d’absence de relation, c’est-à-dire le degré de significativité de la corrélation. 4.4.2 Utilisation des résultats Mettre en évidence des groupes de variables significativement corrélées entre elles, que ce soit de façon positive ou négative. Préparer la réalisation d’une analyse en composantes principales qui regroupera les variables corrélées entre elles en facteurs. Identifier des variables non redondantes pour construire un modèle de régression multiple. Indentifier des variables fortement corrélées pouvant servir de proxy pour estimer des valeurs manquantes dans un tableau 4.4.3 Visualisation d’une matrice de corrélation _ Sous la forme de tableaux montrant si possible à la fois les coefficients de corrélation et les seuils de significativité. Sous la forme de graphes montrant de façon visuelle l’intesité, le signe et la significativité des relations. Sous la forme de plans factoriels résultant d’une analyse en composantes principales. Chacun de ces objectifs supposant en général l’emploi de packages spécialisés. 4.4.4 Exemple : création d’un tableau quantitatif On ne sélectionne que des variables quantitatives et on ajoute les noms des pays en attribut des lignes. tab&lt;-don[,c(&quot;PNB&quot;,&quot;TMI&quot;,&quot;ESP&quot;,&quot;URB&quot;,&quot;NAT&quot;,&quot;MOR&quot;,&quot;FEC&quot;)] row.names(tab)&lt;-don$PAYS head(tab,3) #&gt; PNB TMI ESP URB NAT MOR FEC #&gt; ALB 600 43.0 71 34 27 6 3.3 #&gt; AUT 10000 10.3 75 55 12 12 1.4 #&gt; BEL 9200 9.7 75 95 12 11 1.5 On calcule la corrélation resul&lt;-cor(tab) str(resul) #&gt; num [1:7, 1:7] 1 -0.658 0.83 0.508 -0.466 ... #&gt; - attr(*, &quot;dimnames&quot;)=List of 2 #&gt; ..$ : chr [1:7] &quot;PNB&quot; &quot;TMI&quot; &quot;ESP&quot; &quot;URB&quot; ... #&gt; ..$ : chr [1:7] &quot;PNB&quot; &quot;TMI&quot; &quot;ESP&quot; &quot;URB&quot; ... On affiche la matrice de corrélation en arrondissant les valeurs round(resul,3) #&gt; PNB TMI ESP URB NAT MOR FEC #&gt; PNB 1.000 -0.658 0.830 0.508 -0.466 0.125 -0.614 #&gt; TMI -0.658 1.000 -0.728 -0.655 0.797 -0.414 0.814 #&gt; ESP 0.830 -0.728 1.000 0.583 -0.501 -0.071 -0.619 #&gt; URB 0.508 -0.655 0.583 1.000 -0.514 0.352 -0.554 #&gt; NAT -0.466 0.797 -0.501 -0.514 1.000 -0.482 0.950 #&gt; MOR 0.125 -0.414 -0.071 0.352 -0.482 1.000 -0.426 #&gt; FEC -0.614 0.814 -0.619 -0.554 0.950 -0.426 1.000 4.4.5 Utilisation du package psych La fonction cor.test() de Rbase ne permet pas de calculer les corrélations pour toute une matrice. Aussi on charge le package psych qui dispose d’une fonction corr.test() beaucoup plus puissante qui crée plusieurs matrices de résultats library(psych) #&gt; #&gt; Attaching package: &#39;psych&#39; #&gt; The following object is masked from &#39;package:car&#39;: #&gt; #&gt; logit #&gt; The following objects are masked from &#39;package:ggplot2&#39;: #&gt; #&gt; %+%, alpha results&lt;-psych::corr.test(tab) names(results) #&gt; [1] &quot;r&quot; &quot;n&quot; &quot;t&quot; &quot;p&quot; &quot;p.adj&quot; &quot;se&quot; &quot;sef&quot; &quot;adjust&quot; #&gt; [9] &quot;sym&quot; &quot;ci&quot; &quot;ci2&quot; &quot;ci.adj&quot; &quot;stars&quot; &quot;Call&quot; On retrouve la matrice des coefficiences de corrélation round(results$r,3) #&gt; PNB TMI ESP URB NAT MOR FEC #&gt; PNB 1.000 -0.658 0.830 0.508 -0.466 0.125 -0.614 #&gt; TMI -0.658 1.000 -0.728 -0.655 0.797 -0.414 0.814 #&gt; ESP 0.830 -0.728 1.000 0.583 -0.501 -0.071 -0.619 #&gt; URB 0.508 -0.655 0.583 1.000 -0.514 0.352 -0.554 #&gt; NAT -0.466 0.797 -0.501 -0.514 1.000 -0.482 0.950 #&gt; MOR 0.125 -0.414 -0.071 0.352 -0.482 1.000 -0.426 #&gt; FEC -0.614 0.814 -0.619 -0.554 0.950 -0.426 1.000 Mais aussi la matrice des tests de significativité round(results$p,3) #&gt; PNB TMI ESP URB NAT MOR FEC #&gt; PNB 0.000 0.006 0.000 0.086 0.114 1.000 0.014 #&gt; TMI 0.000 0.000 0.001 0.006 0.000 0.170 0.000 #&gt; ESP 0.000 0.000 0.000 0.027 0.086 1.000 0.013 #&gt; URB 0.010 0.000 0.002 0.000 0.086 0.254 0.045 #&gt; NAT 0.019 0.000 0.011 0.009 0.000 0.103 0.000 #&gt; MOR 0.552 0.040 0.738 0.085 0.015 0.000 0.170 #&gt; FEC 0.001 0.000 0.001 0.004 0.000 0.034 0.000 On peut aussi faire une jolie matrice colorée avec des tests de signficativité sous forme d’étoiles corPlot(tab, stars=TRUE, diag=FALSE) 4.4.6 Utilisation du package factoMineR Si on veut voir les axes factoriels d’une analyse en composante principales on utilise la fonction PCA() de FactoMineR library(FactoMineR) monacp&lt;-PCA(tab, graph=FALSE) On pourra ensuite visualiser la corrélation des variables avec les principaux axes factoriels et les coordonnées des individus sur ceux-ci. 4.4.6.1 Corrélation des variables avec les axes factoriels plot.PCA(monacp,choix = &quot;varcor&quot;) 4.4.6.2 Coordonnées des individus sur les axes factoriels plot.PCA(monacp,choix = &quot;ind&quot;,) "],["05-Régression.html", "Partie 5 Régression 5.1 Préparation des données 5.2 Forme de la relation 5.3 Ajustement du modèle 5.4 Diagnostics du modèle 5.5 Améliorations du modèle", " Partie 5 Régression Mise en place : Télécharger le dossier exo5 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo5.Rproj dans Rstudio. 5.1 Préparation des données 5.1.1 Chargement du tableau principal On charge notre bon vieux fichier des pays européens en 1988 don&lt;-read.table(file = &quot;resources/data/europe88/euro1988.csv&quot;, sep = &quot;;&quot;, header = T) don$BLOC&lt;-as.factor(don$BLOC) levels(don$BLOC)&lt;-c(&quot;Capitaliste&quot;,&quot;Socialiste&quot;) head(don) #&gt; PAYS BLOC PNB TMI ESP URB NAT MOR FEC JEU VIE SUP POP X #&gt; 1 ALB Socialiste 600 43.0 71 34 27 6 3.3 35 5 29 3.1 4825115 #&gt; 2 AUT Capitaliste 10000 10.3 75 55 12 12 1.4 18 14 84 7.6 4299715 #&gt; 3 BEL Capitaliste 9200 9.7 75 95 12 11 1.5 19 14 31 9.9 3636312 #&gt; 4 BGR Socialiste 2000 14.5 72 65 13 11 2.0 21 11 111 9.0 5206070 #&gt; 5 CHE Capitaliste 17800 6.8 77 61 12 9 1.5 17 14 41 6.6 3869378 #&gt; 6 CSK Socialiste 3200 13.9 71 74 14 12 2.0 24 11 128 15.6 4487005 #&gt; Y #&gt; 1 1684833 #&gt; 2 2335579 #&gt; 3 2667243 #&gt; 4 1930219 #&gt; 5 2243130 #&gt; 6 2540281 5.1.2 Choix des deux variables à analyser En dehors de BLOC et PAYS, on ne garde que les deux variables PNB et TMI que l’on renomme X et Y avec colnames() et que l’on convertit en type numérique général. Il suffira par la suite de modifier le choix des variables X et Y pour faire d’autres analyses. eur&lt;-don[,c(&quot;PAYS&quot;,&quot;BLOC&quot;,&quot;PNB&quot;,&quot;TMI&quot;)] colnames(eur)&lt;-c(&quot;PAYS&quot;,&quot;BLOC&quot;,&quot;X&quot;,&quot;Y&quot;) eur$X&lt;-as.numeric(eur$X) eur$Y&lt;-as.numeric(eur$Y) head(eur) #&gt; PAYS BLOC X Y #&gt; 1 ALB Socialiste 600 43.0 #&gt; 2 AUT Capitaliste 10000 10.3 #&gt; 3 BEL Capitaliste 9200 9.7 #&gt; 4 BGR Socialiste 2000 14.5 #&gt; 5 CHE Capitaliste 17800 6.8 #&gt; 6 CSK Socialiste 3200 13.9 On prépare les titres # Pour la version française titre &lt;- &quot;Les pays européens en 1988&quot; nomX &lt;- &quot;Produit National brut ($/hab)&quot; nomY &lt;- &quot;Taux de mortalité infantile en p. 1000&quot; auteur &lt;- &quot;Claude Grasland, Université Paris Diderot, 2020&quot; Comme on prévoit qu’il y aura des différences entre pays socialistes et capitalistes, on crée deux sous-tableaux eur_soc&lt;-eur[eur$BLOC==&quot;Socialiste&quot;,] eur_cap&lt;-eur[eur$BLOC==&quot;Capitaliste&quot;,] 5.2 Forme de la relation 5.2.1 Vérification de la normalité de X et Y La régression linéaire met en relation deux variables quantitatives X et Y dont on suppose que la distribution est normale (gaussienne) , c’est-à-dire unimodale et symérique. On peut tester la normalité des disributions par inspection visuelle à l’aide de hist() Les fonctions qqnorm() et qqline() sont plus précises … qqnorm(eur$X, col=&quot;blue&quot;,ylab=nomX) qqline(eur$X,col=&quot;red&quot;) Les fonctions qqnorm() et qqline() sont plus précises … qqnorm(eur$Y, col=&quot;blue&quot;,ylab=nomY) qqline(eur$Y,col=&quot;red&quot;) Mais la solution la plus précise est le test de Shapiro qui pose l’hypothèse H0 : la distribution est normale. shapiro.test(eur$X) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: eur$X #&gt; W = 0.9175, p-value = 0.04495 shapiro.test(eur$Y) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: eur$Y #&gt; W = 0.72466, p-value = 1.594e-05 5.2.2 Visualisation de la forme de la relation On peut faire un simple plot(X,Y). Mais on peut aussi créer pour cela une fonction personalisée adapté à ses préférences monplot &lt;- function (varX , varY, varN ) { plot(varX,varY, main = titre, # titre cex.main = 1, # police du titre cex = 0.6, # taille des symboles pch = 19, # cercles pleins col = &quot;red&quot;) # couleur des symboles text(varX,varY,varN,cex=0.5,pos=3) # nom des élément abline(v=mean(varX),lty=2,lwd=1,col=&quot;blue&quot;) # moyenne X abline(h=mean(varY),lty=2,lwd=1,col=&quot;blue&quot;) # moyenne Y } Je peux désormais utiliser ma fonction monplot() ! monplot(varX = eur$X,varY = eur$Y, varN = eur$PAYS) Je peux décider de ne pas afficher le label des points. monplot(varX = eur$X,varY = eur$Y, varN = NULL) 5.2.3 Analyse de la corrélation Je commence par celuler le coefficient de corrélation linéaire (r) et le pouvoir explicatif de X par rapport à Y (r2) cor(eur$X,eur$Y) # coefficient de corrélation (r) #&gt; [1] -0.6584308 100*cor(eur$X,eur$Y)**2 # pouvoir explicatif (r2) #&gt; [1] 43.35312 Puis, je teste la significativité de la corrélation linéaire … cor.test(eur$X,eur$Y) # test de significativité (p-value) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: eur$X and eur$Y #&gt; t = -4.1955, df = 23, p-value = 0.0003459 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -0.8360497 -0.3558907 #&gt; sample estimates: #&gt; cor #&gt; -0.6584308 … et je la compare à celle du coefficient de corrélation de rang de Spearman cor.test(eur$X,eur$Y, method=&quot;spearman&quot;) # test de significativité (p-value) #&gt; Warning in cor.test.default(eur$X, eur$Y, method = &quot;spearman&quot;): Cannot compute #&gt; exact p-value with ties #&gt; #&gt; Spearman&#39;s rank correlation rho #&gt; #&gt; data: eur$X and eur$Y #&gt; S = 4796.3, p-value = 1.094e-07 #&gt; alternative hypothesis: true rho is not equal to 0 #&gt; sample estimates: #&gt; rho #&gt; -0.8447182 On peut conclure des analyses précédentes que : il existe une relation significative (p-value &lt; 0.05) cette relation est positive (r &gt; 0 ) cette relation a un pouvoir explicatif moyen (r2 = 45%) Mais … la relation est monotone mais non linéaire car le coefficient de Spearman (-0.90) est beaucoup plus fort que le coefficient de Pearson (-0.68) et également plus significatif 5.3 Ajustement du modèle 5.3.1 Hypothèses statistiques Conditions a priori X et Y sont deux variables normales (gaussienne) il existe une corrélation significative entre X et Y (p&lt; 0.05) X explique une part suffisamment forte de Y (r2 &gt; 20% ) Le nuage de point affiche une forme linéaire les points sont répartis de façon régulière le long du nuage de points Il n’y a pas de valeurs exceptionnelles susceptibles de perturber le calcul. On charge le package car (companion to applied regession). library(car) Méthode des moindres carrés ordinaire (MCO) La droite \\(y_i = a.x_i + b + \\epsilon_i\\) qui minimise la somme des carrés des écarts entre les valeurs observées \\(y_i\\) et les valeurs estimées \\(\\hat{y_i}\\) a pour équation : \\(COV(X,Y) = \\sum_{i=1}^k \\sum_{j=1}^k (x_{i}-\\bar{x})^2.(y_{i}-\\bar{y})^2\\) \\(a = COV(X,Y) / (\\sigma_X)^2\\) \\(b = \\bar{y} - a.\\bar{x}\\) Analyse de la variance La somme des carré des écarts totale (\\(SCE_{tot}\\)) correspond à la variance de la variable à expliquer : \\(SCE_{tot} = \\sum_{i=1}^k (y_{i}-\\bar{y})^2\\) La somme des carré des écarts résiduels (\\(SCE_{err}\\)) correspond à la somme des carrés des différences entre valeurs observées et estimées \\(SCE_{error} = \\sum_{i=1}^k (y_{i}-\\hat{y})^2\\) Le pouvoir explicatif d’un modèle de régression correspond à la part de la variance de Y expliquée par X. \\(Var. expliquée = (SCE_{tot}-SCE_{res}) / SCE_{tot} = r(X,Y)^{2}\\) Vérifications a posteriori Un modèle de régression n’est valide que si les résidus de ce modèle \\(\\epsilon_i = (y_i - \\hat{y}_i)\\) remplissent les conditions suivantes : Normalité de la distribution des résidus Absence d’autocorrélation des résidus Homogénéité de la variance des résidus Absence de valeur à fort effet de levier Si ces quatre conditions ne sont pas remplies, les estimations de Y en fonction de X seront entâchées d’erreur et leur intervalle de confiance ne sera pas valable. 5.3.2 La fonction lm() La fonction lm() ou lm est l’abbréviation de linear model permet d’effectuer la plupart des modèles de régression linéaire basés sur la méthode des moindres carrés ordinaire. Sa syntaxe est a priori très simple et renvoie les coefficients b et a du modèle de régression. lm(eur$Y~eur$X) #&gt; #&gt; Call: #&gt; lm(formula = eur$Y ~ eur$X) #&gt; #&gt; Coefficients: #&gt; (Intercept) eur$X #&gt; 20.890709 -0.001042 Mais en réalité lm() crée une liste de résultats que l’on a intérêt à stocker pour en examiner les composantes une à une. monmodel&lt;-lm(eur$Y~eur$X) str(monmodel) #&gt; List of 12 #&gt; $ coefficients : Named num [1:2] 20.89071 -0.00104 #&gt; ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;eur$X&quot; #&gt; $ residuals : Named num [1:25] 22.73 -0.17 -1.6 -4.31 4.46 ... #&gt; ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... #&gt; $ effects : Named num [1:25] -64.96 26.96 -5.02 -8.69 2.2 ... #&gt; ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;(Intercept)&quot; &quot;eur$X&quot; &quot;&quot; &quot;&quot; ... #&gt; $ rank : int 2 #&gt; $ fitted.values: Named num [1:25] 20.27 10.47 11.3 18.81 2.34 ... #&gt; ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... #&gt; $ assign : int [1:2] 0 1 #&gt; $ qr :List of 5 #&gt; ..$ qr : num [1:25, 1:2] -5 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 ... #&gt; .. ..- attr(*, &quot;dimnames&quot;)=List of 2 #&gt; .. .. ..$ : chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... #&gt; .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;eur$X&quot; #&gt; .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 #&gt; ..$ qraux: num [1:2] 1.2 1.14 #&gt; ..$ pivot: int [1:2] 1 2 #&gt; ..$ tol : num 1e-07 #&gt; ..$ rank : int 2 #&gt; ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; #&gt; $ df.residual : int 23 #&gt; $ xlevels : Named list() #&gt; $ call : language lm(formula = eur$Y ~ eur$X) #&gt; $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language eur$Y ~ eur$X #&gt; .. ..- attr(*, &quot;variables&quot;)= language list(eur$Y, eur$X) #&gt; .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 #&gt; .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 #&gt; .. .. .. ..$ : chr [1:2] &quot;eur$Y&quot; &quot;eur$X&quot; #&gt; .. .. .. ..$ : chr &quot;eur$X&quot; #&gt; .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;eur$X&quot; #&gt; .. ..- attr(*, &quot;order&quot;)= int 1 #&gt; .. ..- attr(*, &quot;intercept&quot;)= int 1 #&gt; .. ..- attr(*, &quot;response&quot;)= int 1 #&gt; .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; #&gt; .. ..- attr(*, &quot;predvars&quot;)= language list(eur$Y, eur$X) #&gt; .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; #&gt; .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;eur$Y&quot; &quot;eur$X&quot; #&gt; $ model :&#39;data.frame&#39;: 25 obs. of 2 variables: #&gt; ..$ eur$Y: num [1:25] 43 10.3 9.7 14.5 6.8 13.9 9.2 8.6 8.4 9 ... #&gt; ..$ eur$X: num [1:25] 600 10000 9200 2000 17800 3200 3700 12000 12600 4800 ... #&gt; ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language eur$Y ~ eur$X #&gt; .. .. ..- attr(*, &quot;variables&quot;)= language list(eur$Y, eur$X) #&gt; .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 #&gt; .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 #&gt; .. .. .. .. ..$ : chr [1:2] &quot;eur$Y&quot; &quot;eur$X&quot; #&gt; .. .. .. .. ..$ : chr &quot;eur$X&quot; #&gt; .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;eur$X&quot; #&gt; .. .. ..- attr(*, &quot;order&quot;)= int 1 #&gt; .. .. ..- attr(*, &quot;intercept&quot;)= int 1 #&gt; .. .. ..- attr(*, &quot;response&quot;)= int 1 #&gt; .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; #&gt; .. .. ..- attr(*, &quot;predvars&quot;)= language list(eur$Y, eur$X) #&gt; .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; #&gt; .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;eur$Y&quot; &quot;eur$X&quot; #&gt; - attr(*, &quot;class&quot;)= chr &quot;lm&quot; Un résumé des résultats principaux est fourni avec summary() appliqué à l’objet créé par lm(). summary(monmodel) On obtient ainsi : l’équation de la droite Y = a.X+b la significativité et l’intervalle de confiance de a et b le pouvoir explicatif du modèle \\(r(X,Y)^2\\) #&gt; #&gt; Call: #&gt; lm(formula = eur$Y ~ eur$X) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -7.8351 -2.7982 -1.6039 0.6391 22.7345 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 20.8907087 2.2796125 9.164 3.86e-09 *** #&gt; eur$X -0.0010420 0.0002484 -4.196 0.000346 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 6.427 on 23 degrees of freedom #&gt; Multiple R-squared: 0.4335, Adjusted R-squared: 0.4089 #&gt; F-statistic: 17.6 on 1 and 23 DF, p-value: 0.0003459 On peut également analyser plus en détail la variance en appliquant anova() à l’objet créé par lm() ce qui monte la quantité de variance expliquée par X et la quantité de variance résiduelle. Le test de Fisher (Pr&gt;F) détermine si le modèle est significatif et renvoie la même valeur que la p-value du coeff. de corrélation. anova(monmodel) #&gt; Analysis of Variance Table #&gt; #&gt; Response: eur$Y #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; eur$X 1 727.09 727.09 17.602 0.0003459 *** #&gt; Residuals 23 950.05 41.31 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 On peut extraire de l’objet créé par lm() les valeurs estimées de Y et les résidus c’est-à-dire les erreurs d’estimation. eur$Y_estim&lt;-monmodel$fitted.values eur$Y_resid&lt;-monmodel$residuals head(eur) #&gt; PAYS BLOC X Y Y_estim Y_resid #&gt; 1 ALB Socialiste 600 43.0 20.26548 22.7345189 #&gt; 2 AUT Capitaliste 10000 10.3 10.47025 -0.1702487 #&gt; 3 BEL Capitaliste 9200 9.7 11.30389 -1.6038855 #&gt; 4 BGR Socialiste 2000 14.5 18.80662 -4.3066167 #&gt; 5 CHE Capitaliste 17800 6.8 2.34229 4.4577101 #&gt; 6 CSK Socialiste 3200 13.9 17.55616 -3.6561615 On peut tracer la droite de régression avec abline() monplot(eur$X,eur$Y,eur$PAYS) abline(monmodel, col=&quot;blue&quot;,lwd=2) On peut enfin analyser a posteriori la qualité de la régression avec plot(). par(mfrow=c(2,2)) plot(monmodel,labels.id = eur$PAYS) 5.4 Diagnostics du modèle 5.4.1 Diagnostic 1 : Indépendance des résidus ? L’objectif est de savoir si les résidus se répartissent régulièrement de part et d’autre de la droite de régression tout au long de celle-ci. Si c’est bien le cas le graphique residuals Vs Fitted généré par plot(monmodel,1) devrait donner une droite horizontale : plot(monmodel,1,labels.id = eur$PAYS) On peut tester statistiquement l’indépendance des résidus à l’aide du test de Durbin-Watson qui mesure si deux valeurs successives ont des résidus proches. L’indépendance des résidus est rejetée si p-value &lt; 0.05 durbinWatsonTest(monmodel) #&gt; lag Autocorrelation D-W Statistic p-value #&gt; 1 -0.03883526 1.455678 0.178 #&gt; Alternative hypothesis: rho != 0 Ici on trouve p-value &gt; 0.05 donc les résidus sont indépendants. 5.4.2 Diagnostic 2 : Normalité des résidus ? L’objectif est de savoir si les résidus ont une distribution normale Si c’est bien le cas le graphique généré par plot(monmodel,2) devrait donner une droite oblique : plot(monmodel,2,labels.id = eur$PAYS) On peut tester statistiquement la normalité des résidus à l’aide du test de Shapiro-Wilk. Les résidus sont normaux si p-value &gt; 0.05 shapiro.test(monmodel$residuals) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: monmodel$residuals #&gt; W = 0.81605, p-value = 0.0004263 Ici on trouve une p-value très clairement inférieure à 0.05 donc la distribution des résidus n’est pas gaussienne. 5.4.3 Diagnostic 3 : Homogénéité des résidus ? L’objectif est de savoir si la variance des résidus est constante, c’est-à-dire si il s’écarte environ de la même distance tout au long de la droite . Si c’est bien le cas le graphique généré par plot(monmodel,3) devrait donner une droite horizontale plot(monmodel,3,labels.id = eur$PAYS) On peut tester statistiquement l’homogénéité des résidus à l’aide du test de Breush-Pagan. L’hypothèse d’homogénéité est rejetée si la p-value est inférieure à 0.05. ncvTest(monmodel) #&gt; Non-constant Variance Score Test #&gt; Variance formula: ~ fitted.values #&gt; Chisquare = 9.429701, Df = 1, p = 0.002135 Ici, la p-value est inférieure à 0.05 donc les résidus ne sont pas homogènes. 5.4.4 Diagnostic 4 : Absence de valeur exceptionnelles ? L’objectif est de savoir s’il existe des valeurs qui exercent une influence exceptionnelle sur les résultats de la régression. On peut reprérer ces valeurs de plusieurs manières, notamment à l’aide de la distance de Cook générée par plot(monmodel,4).O n repère le cas particulier de l’Albanie : plot(monmodel,4,labels.id = eur$PAYS) Le test statistique de Bonferroni permet de déterminer s’il existe des valeurs exceptionnelles avec une p-value &lt; 0.05. outlierTest(monmodel, labels = eur$PAYS) #&gt; rstudent unadjusted p-value Bonferroni p #&gt; ALB 5.905381 6.0791e-06 0.00015198 Ici, on doit conclure qu’il existe au moins une valeur exceptionnelle, l’Albanie, susceptible de fausser les conclusions du modèle de régression. 5.5 Améliorations du modèle 5.5.1 Modèle linéaire (R2 = 46%) scatterplot(eur$X,eur$Y, ellipse = T,smooth = F,pch=19) text(eur$X,eur$Y, eur$PAYS, col=&quot;red&quot;,pos=2,cex=0.6) 5.5.2 Modèle linéaire sans l’Albanie (R2 = 53%) eur2&lt;-eur[eur$PAYS !=&quot;ALB&quot;,] scatterplot(eur2$X,eur2$Y, ellipse = T,smooth = F,pch=19) text(eur2$X,eur2$Y, eur2$PAYS, col=&quot;red&quot;,pos=2,cex=0.6) 5.5.3 Modèle exponentiel (R2 = 63%) scatterplot(eur$X,log(eur$Y), ellipse = T,smooth = F, pch=19) text(eur$X,log(eur$Y), eur$PAYS, col=&quot;red&quot;,pos=2,cex=0.6) 5.5.4 Modèle puissance (R2 = 83%) scatterplot(log(eur$X),log(eur$Y), ellipse = T,smooth = F, pch=19) text(log(eur$X),log(eur$Y), eur$PAYS, col=&quot;red&quot;,pos=2,cex=0.6) "],["06-Anova.html", "Partie 6 Analyse de variance 6.1 Préparation des données 6.2 Rappels sur la régression 6.3 Test d’égalité des moyennes 6.4 Analyse de variance 6.5 Annexe : les variables hybrides", " Partie 6 Analyse de variance Mise en place : Télécharger le dossier exo6 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo6.Rproj dans Rstudio. 6.1 Préparation des données 6.1.1 Chargement du fichier On charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points. don&lt;-read.table(file = &quot;resources/data/tips/tips.csv&quot;, sep = &quot;;&quot;, header = T) head(don) #&gt; IDEN TOTBILL TIP SEX SMOKER DAY TIME SIZE #&gt; 1 R001 16.99 1.01 1 0 6 1 2 #&gt; 2 R002 10.34 1.66 0 0 6 1 3 #&gt; 3 R003 21.01 3.50 0 0 6 1 3 #&gt; 4 R004 23.68 3.31 0 0 6 1 2 #&gt; 5 R005 24.59 3.61 1 0 6 1 4 #&gt; 6 R006 25.29 4.71 0 0 6 1 4 6.1.2 Contenu du fichier Ce dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives. Sources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics. 6.1.3 Dictionaire des variables IDEN : identifiant du repas TOTBILL : prix du repas (en dollars des années 1990) TIP : pourboire (en dollars des années 1990) SEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme) SMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1) DAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …) TIME : repas pris en journée (0) ou le soir (1) SIZE : nombre de convives 6.1.4 Recodage des variables Le type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français : don$IDEN&lt;-as.character(don$IDEN) don$SEX&lt;-as.factor(don$SEX) levels(don$SEX)&lt;-c(&quot;Homme&quot;,&quot;Femme&quot;) don$SMOKER&lt;-as.factor(don$SMOKER) levels(don$SMOKER)&lt;-c(&quot;Non fumeur&quot;, &quot;Fumeur&quot;) don$DAY&lt;-as.factor(don$DAY) levels(don$DAY)&lt;-c(&quot;Mercredi&quot;,&quot;Jeudi&quot;,&quot;Vendredi&quot;,&quot;Samedi&quot;) don$TIME&lt;-as.factor(don$TIME) levels(don$TIME)&lt;-c(&quot;Journée&quot;,&quot;Soirée&quot;) 6.1.5 Ajout d’une nouvelle variable On crée la variable PCT qui est le rapport entre le pourboire (TIP) et le prix total (TOTBILL) du repas exprimé en pourcentage. don$PCT&lt;-100*don$TIP/don$TOTBILL 6.1.6 Résumé de l’ensemble du tableau summary(don) #&gt; IDEN TOTBILL TIP SEX #&gt; Length:244 Min. : 3.07 Min. : 1.000 Homme:157 #&gt; Class :character 1st Qu.:13.35 1st Qu.: 2.000 Femme: 87 #&gt; Mode :character Median :17.80 Median : 2.900 #&gt; Mean :19.79 Mean : 2.998 #&gt; 3rd Qu.:24.13 3rd Qu.: 3.562 #&gt; Max. :50.81 Max. :10.000 #&gt; SMOKER DAY TIME SIZE PCT #&gt; Non fumeur:151 Mercredi:62 Journée: 68 Min. :1.00 Min. : 3.564 #&gt; Fumeur : 93 Jeudi :19 Soirée :176 1st Qu.:2.00 1st Qu.:12.913 #&gt; Vendredi:87 Median :2.00 Median :15.477 #&gt; Samedi :76 Mean :2.57 Mean :16.080 #&gt; 3rd Qu.:3.00 3rd Qu.:19.148 #&gt; Max. :6.00 Max. :71.034 6.2 Rappels sur la régression 6.2.1 La distribution de PCT est-elle normale ? hist(don$PCT, breaks = 10,col=&quot;lightyellow&quot;,probability = TRUE) lines(density(don$PCT,bw=3),col=&quot;red&quot;,lwd=1) La distribution semble normale . Mais est-ce l’avis du test de Shapiro ? shapiro.test(don$PCT) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: don$PCT #&gt; W = 0.79943, p-value &lt; 2.2e-16 Que nous apprend la boxplot ? boxplot(don$PCT, col=&quot;lightyellow&quot;,horizontal = T) La distribution devient presque parfaitement gaussienne si on retire les 4 valeurs exceptionnelles ! don2&lt;-don[don$PCT&lt;30,] shapiro.test(don2$PCT) #&gt; #&gt; Shapiro-Wilk normality test #&gt; #&gt; data: don2$PCT #&gt; W = 0.99435, p-value = 0.5066 hist(don2$PCT, breaks = 10,col=&quot;lightyellow&quot;,probability = TRUE) lines(density(don2$PCT,bw=3),col=&quot;red&quot;,lwd=1) 6.2.2 Y-a-t-il une relation entre le prix du repas et le pourboire ? On fait le graphique … plot(don2$TOTBILL,don2$TIP) Puis on teste le coefficient de Pearson et celui de Sperman cor.test(don2$TIP,don2$TOTBILL) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: don2$TIP and don2$TOTBILL #&gt; t = 14.906, df = 239, p-value &lt; 2.2e-16 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.6223204 0.7543075 #&gt; sample estimates: #&gt; cor #&gt; 0.6941023 cor.test(don2$TIP,don2$TOTBILL, method=&quot;spearman&quot;) #&gt; Warning in cor.test.default(don2$TIP, don2$TOTBILL, method = &quot;spearman&quot;): #&gt; Cannot compute exact p-value with ties #&gt; #&gt; Spearman&#39;s rank correlation rho #&gt; #&gt; data: don2$TIP and don2$TOTBILL #&gt; S = 688482, p-value &lt; 2.2e-16 #&gt; alternative hypothesis: true rho is not equal to 0 #&gt; sample estimates: #&gt; rho #&gt; 0.7048791 6.2.3 Modèle de régression On calcule le modèle de régression mareg&lt;-lm(don2$TIP~don2$TOTBILL) plot(don2$TOTBILL,don2$TIP, xlab=&quot;Repas ($)&quot;,ylab = &quot;Pourboire ($)&quot;,pch=19,cex=0.5) abline(mareg,col=&quot;red&quot;,lwd=1) 6.3 Test d’égalité des moyennes 6.3.1 Hypothèses On considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à deux modalités divisant P en deux sous population P1 et P2. Soit par exemple la variable Y = PCT et la variable X = SEX. On peut se demander si les femmes sont plus généreuses que les hommes, les hommes sont plus généreux que les femmes, les hommes sont différents des femmes, etc… Y&lt;-don2$PCT nomY &lt;-&quot;Pourboire relatif (%)&quot; X&lt;-don2$SEX nomX &lt;- &quot;Sexe du client&quot; #X&lt;-don2$SMOKER #nomX&lt;- &quot;Tabagisme&quot; #X&lt;-don2$TIME #nomX&lt;- &quot;Moment de la journée&quot; 6.3.2 Visualisations Le plus simple est d’utiliser boxplot() en version de base … boxplot(Y~X) … ou améliorée boxplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX, col=&quot;gray80&quot;) On peut aussi utiliser le package beanplot() en version simple … library(beanplot) beanplot(Y~X) … ou améliorée : library(beanplot) beanplot(Y~X,horizontal=T, xlab = nomY, ylab=nomX,col = &quot;gray80&quot;) 6.3.3 Paramètres principaux On détermine la moyenne et l’écart-type de chaque échantillon avec la fonction tapply() couplée avec les fonctions mean(), sd() ou summary() tapply(Y,X, mean) #&gt; Homme Femme #&gt; 15.41076 16.16741 tapply(Y,X,sd) #&gt; Homme Femme #&gt; 4.732686 4.329426 tapply(Y,X, summary) #&gt; $Homme #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 3.564 12.136 15.325 15.411 18.622 29.199 #&gt; #&gt; $Femme #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 5.643 13.999 15.522 16.167 19.284 27.952 6.3.4 Test d’égalité des moyennes Si la distribution est gaussienne on utilise le test de Student : t.test(Y~X) #&gt; #&gt; Welch Two Sample t-test #&gt; #&gt; data: Y by X #&gt; t = -1.254, df = 186.21, p-value = 0.2114 #&gt; alternative hypothesis: true difference in means between group Homme and group Femme is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -1.9470273 0.4337437 #&gt; sample estimates: #&gt; mean in group Homme mean in group Femme #&gt; 15.41076 16.16741 Si ce n’est pas le cas et s’il y a des valeurs exceptionnelles on préfèrera le test de Wilcoxon basé sur les rangs des valeurs (comme le coefficient de corrélation de Spearman) wilcox.test(Y~X) #&gt; #&gt; Wilcoxon rank sum test with continuity correction #&gt; #&gt; data: Y by X #&gt; W = 5953, p-value = 0.1908 #&gt; alternative hypothesis: true location shift is not equal to 0 Lorsque les deux tests divergent dans leur conclusions, il y a certainement un problème de violation de l’hypothèse gaussienne. Dans ce cas, il faut sans doute transformer Y ou retirer des valeurs exceptionnelles (Cf.cours sur la corrélation et la régression) 6.4 Analyse de variance 6.4.1 Hypothèses On considère une variable Y quantitative continue définie sur une population de réféence P et une variable X qualitative à k modalités divisant P en k sous population P1…Pk. Soit par exemple la variable Y = PCT et la variable X = DAY. On peut se demander si la générosité des pourboires varie en fonction des jours de la semaine (mercredi, jeudi, vendredi ou samedi). On fera toutefois attention au fait que l’échantillon n’est pas très équilibré table(don2$DAY) #&gt; #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 62 19 86 74 6.4.2 Calcul des paramètres principaux On va calculer les paramètres principaux de chacune des quatre sous population à l’aide de la superfonction tapply() dont la syntaxe est la suivante tapply(variable à analyser, variable de partition , function) La fonction tapply() s’applique sur les tableaux (data.frame). Il y a des fonctions équvalentes pour les listes, les matrices, etc… moy&lt;-tapply(X = don2$PCT, INDEX = don2$DAY, FUN = mean) moy #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 16.12756 16.99130 15.11450 15.61781 ect&lt;-tapply(don2$PCT, don2$DAY, sd) ect #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 3.865182 4.766531 4.803544 4.858665 100*ect/moy #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 23.96631 28.05277 31.78104 31.10976 tapply(don2$PCT, don2$DAY, summary) #&gt; $Mercredi #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 7.296 13.821 15.385 16.128 19.269 26.631 #&gt; #&gt; $Jeudi #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 10.36 13.37 15.56 16.99 19.66 26.35 #&gt; #&gt; $Vendredi #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 3.564 12.373 15.099 15.114 18.767 29.199 #&gt; #&gt; $Samedi #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 5.945 11.737 15.965 15.618 18.494 28.054 6.4.3 Visualisation On utilise comme précédemment boxplot() : boxplot(don2$PCT~don2$DAY, col=&quot;gray80&quot;) Ou bien beanplot() : library(beanplot) beanplot(don2$PCT~don2$DAY,col = &quot;gray80&quot;) 6.4.4 Modélisation simple La solution la plus simple est d’utiliser la fonction lm() que l’on a déjà vu pour la régression. monmodel&lt;-lm(don2$PCT~don2$DAY) summary(monmodel) #&gt; #&gt; Call: #&gt; lm(formula = don2$PCT ~ don2$DAY) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -11.5507 -2.7549 -0.1519 3.2335 14.0845 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 16.1276 0.5836 27.634 &lt;2e-16 *** #&gt; don2$DAYJeudi 0.8637 1.2050 0.717 0.474 #&gt; don2$DAYVendredi -1.0131 0.7656 -1.323 0.187 #&gt; don2$DAYSamedi -0.5097 0.7912 -0.644 0.520 #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 4.595 on 237 degrees of freedom #&gt; Multiple R-squared: 0.01435, Adjusted R-squared: 0.001876 #&gt; F-statistic: 1.15 on 3 and 237 DF, p-value: 0.3295 On peut ensuite appliquer une analyse de variance avec anova() sur le modèle pour mesurer la variance totale et la variance résiduelle ainsi que la significativité de la relation. anova(monmodel) #&gt; Analysis of Variance Table #&gt; #&gt; Response: don2$PCT #&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #&gt; don2$DAY 3 72.9 24.293 1.1503 0.3295 #&gt; Residuals 237 5004.9 21.117 Et on peut effectuer quelques diagnostics sur les résidus : par(mfrow = c(2,2)) plot(monmodel,c(1,2,3,4)) 6.4.5 Modélisation avancée D’un point de vue statistique, l’analyse de variance à un facteur fait appel à des modèles et des hhypothèses plus sophistiqués que le modèle de base présenté ici et comporte de nombreux tests. On se reportera donc ave profit aux trois cours en lignes de Claire Della Vedova pour une approche plus poussée https://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-1/ https://statistique-et-logiciel-r.com/anova-a-un-facteur-partie-2-la-pratique/ https://statistique-et-logiciel-r.com/anova-a-un-facteur-quand-les-hypotheses-ne-sont-pas-satisfaites/ 6.5 Annexe : les variables hybrides Le nombre de convives (SIZE) n’est ni une variable quantitative continue, ni une variable qualitative de type catégorielle. On peut donc l’appréhender de deux points de vue différents sur le plan statistique variable quantitative discrète : ce qui permet d’utiliser un modèle de régression linéaire. variable qualitative ordinale : ce qui permet d’utiliser un modèle d’analyse de variance. 6.5.1 SIZE = quantitative discrète hist(don$SIZE, breaks=6, col=&quot;gray80&quot;) modreg&lt;-lm(don2$PCT~don2$SIZE) summary(modreg) #&gt; #&gt; Call: #&gt; lm(formula = don2$PCT ~ don2$SIZE) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -12.4591 -2.9738 -0.2625 3.4693 13.2193 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 17.2116 0.8545 20.143 &lt;2e-16 *** #&gt; don2$SIZE -0.5944 0.3108 -1.913 0.057 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 4.574 on 239 degrees of freedom #&gt; Multiple R-squared: 0.01507, Adjusted R-squared: 0.01095 #&gt; F-statistic: 3.658 on 1 and 239 DF, p-value: 0.057 plot(don2$SIZE,don2$PCT, col=&quot;blue&quot;, pch=19, cex=0.7) abline(modreg, col=&quot;red&quot;) 6.5.2 SIZE = qualitative ordinale On recode les catégories trop rares … don2$SIZE2&lt;-as.factor(don2$SIZE) levels(don2$SIZE2)&lt;-c(&quot;1-2&quot;,&quot;1-2&quot;,&quot;3+&quot;,&quot;3+&quot;,&quot;3+&quot;,&quot;3+&quot;) summary(don2$SIZE2) #&gt; 1-2 3+ #&gt; 157 84 plot(don2$SIZE2) tapply(don2$PCT, don2$SIZE2, mean) #&gt; 1-2 3+ #&gt; 16.09466 14.89818 tapply(don2$PCT, don2$SIZE2, sd) #&gt; 1-2 3+ #&gt; 4.626275 4.472961 beanplot(don2$PCT~don2$SIZE2) modvar&lt;-lm(don2$PCT~don2$SIZE2) summary(modvar) #&gt; #&gt; Call: #&gt; lm(formula = don2$PCT ~ don2$SIZE2) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -12.5308 -2.7696 -0.3176 3.4082 13.1553 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 16.0947 0.3650 44.093 &lt;2e-16 *** #&gt; don2$SIZE23+ -1.1965 0.6183 -1.935 0.0541 . #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 4.574 on 239 degrees of freedom #&gt; Multiple R-squared: 0.01543, Adjusted R-squared: 0.01131 #&gt; F-statistic: 3.745 on 1 and 239 DF, p-value: 0.05414 "],["07-Tabcont.html", "Partie 7 Analyse d’enquêtes 7.1 Introduction 7.2 Préparation des données 7.3 Opinion USA 7.4 Opinion USA / Sexe 7.5 Opinion USA / Âge 7.6 Opinion USA / Age &amp; Sexe", " Partie 7 Analyse d’enquêtes Mise en place : Télécharger le dossier exo7 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo6.Rproj dans Rstudio. 7.1 Introduction On propose ici une démarche simplifiée de l’analyse d’enquête utilisant les fonctions R-base et quelques fonctions supplémentaires issues du package questionR qui permettent de simplifier l’écriture des programmes. Les explications détaillées se trouvent dans le très beau site web analyse-R auquel ont notamment contribué Julien Barnier et Joseph Larmarange. https://larmarange.github.io/analyse-R/ ce programme suffit pour des analyses simples de questionnaires. Mais pour des analyses plus avancées, il faudra utiliser des packages plus avancés comme survey. 7.2 Préparation des données 7.2.1 Importation du fichier au format .RDS don&lt;-readRDS(&quot;resources/data/pew/Pew_2007_2017.Rdata&quot;) str(don) #&gt; tibble [62,060 × 10] (S3: tbl_df/tbl/data.frame) #&gt; $ survey : Factor w/ 2 levels &quot;Spring2007&quot;,&quot;Spring2017&quot;: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ country : Factor w/ 30 levels &quot;Argentina&quot;,&quot;Brazil&quot;,..: 5 5 5 5 5 5 5 5 5 5 ... #&gt; $ sex : Factor w/ 2 levels &quot;Male&quot;,&quot;Female&quot;: 1 2 1 1 2 1 1 1 1 2 ... #&gt; $ age : num [1:62060] 50 79 43 74 78 36 42 61 21 41 ... #&gt; $ today : Factor w/ 5 levels &quot;1.Typical&quot;,&quot;2.Particularly good&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ use_internet: Factor w/ 4 levels &quot;1.Yes&quot;,&quot;2.No&quot;,..: 1 2 1 2 2 1 1 2 1 1 ... #&gt; $ opi_USA : Factor w/ 6 levels &quot;1.Very favorable&quot;,..: 3 2 3 1 2 1 2 2 2 2 ... #&gt; $ opi_CHN : Factor w/ 6 levels &quot;1.Very favorable&quot;,..: 3 2 3 3 3 2 2 3 2 2 ... #&gt; $ opi_RUS : Factor w/ 6 levels &quot;1.Very favorable&quot;,..: 3 2 2 3 3 2 2 3 3 2 ... #&gt; $ weight : num [1:62060] 1.009 0.954 0.996 0.989 0.982 ... #&gt; ..- attr(*, &quot;label&quot;)= chr &quot;Weighting factor&quot; #&gt; ..- attr(*, &quot;format.spss&quot;)= chr &quot;F9.6&quot; #&gt; ..- attr(*, &quot;display_width&quot;)= int 10 7.2.2 (simplifiée) des variables Les données sont issues de deux vagues de la Global attitude Survey réalisée par le Pew Research Center en 2007 et 2017. Nous avons conservé uniquement des variables communes aux deux enquêtes et posées de façon identique. survey : date d’enquête (2007 ou 2017) country : lieu d’enquête (pays présents aux deux dates) sex : sexe de l’individu age : âge de l’individu today : état d’esprit du jour (typique, très bon, très mauvais) use_internet: usage d’internet opi_USA : opinion sur les USA opi_CHN : opinion sur la Chine opi_RUS : opinion sur la Russie weight : poids de l’individu pour les redressements 7.2.3 Résumé des variables (tri à plat) summary(don) #&gt; survey country sex age #&gt; Spring2007:28061 India : 4499 Male :30125 Min. :18.00 #&gt; Spring2017:33999 United States: 3472 Female:31935 1st Qu.:28.00 #&gt; Lebanon : 2552 Median :40.00 #&gt; Jordan : 2548 Mean :42.59 #&gt; South Africa : 2295 3rd Qu.:55.00 #&gt; Nigeria : 2202 Max. :97.00 #&gt; (Other) :44492 #&gt; today use_internet #&gt; 1.Typical :36554 1.Yes :32385 #&gt; 2.Particularly good:20216 2.No :25892 #&gt; 3.Particularly bad : 4775 3.Don&#39;t know: 232 #&gt; 4.Don&#39;t know : 419 4.Refused : 69 #&gt; 5.Refused : 96 NA&#39;s : 3482 #&gt; #&gt; #&gt; opi_USA opi_CHN #&gt; 1.Very favorable :10081 1.Very favorable : 8002 #&gt; 2.Somewhat favorable :21725 2.Somewhat favorable :21860 #&gt; 3.Somewhat unfavorable:14502 3.Somewhat unfavorable:15097 #&gt; 4.Very unfavorable :10629 4.Very unfavorable : 8402 #&gt; 5.Don&#39;t know : 4718 5.Don&#39;t know : 8183 #&gt; 6.Refused : 405 6.Refused : 516 #&gt; #&gt; opi_RUS weight #&gt; 1.Very favorable : 5650 Min. : 0.02301 #&gt; 2.Somewhat favorable :18105 1st Qu.: 0.65138 #&gt; 3.Somewhat unfavorable:16806 Median : 1.00000 #&gt; 4.Very unfavorable :10144 Mean : 1.00032 #&gt; 5.Don&#39;t know :10719 3rd Qu.: 1.11834 #&gt; 6.Refused : 636 Max. :18.74950 #&gt; 7.2.4 Tailles des échantillons par pays et par date On examine la taille des échantillons collectés dans les différents pays table(don$country,don$survey) #&gt; #&gt; Spring2007 Spring2017 #&gt; Argentina 800 1012 #&gt; Brazil 1000 1007 #&gt; Canada 982 1000 #&gt; Chile 800 987 #&gt; France 1004 996 #&gt; Germany 1000 995 #&gt; Ghana 707 1129 #&gt; India 2040 2459 #&gt; Indonesia 995 996 #&gt; Israel 887 1050 #&gt; Italy 501 899 #&gt; Japan 762 1009 #&gt; Jordan 1000 1548 #&gt; Kenya 997 1117 #&gt; Lebanon 1000 1552 #&gt; Mexico 828 1000 #&gt; Nigeria 1092 1110 #&gt; Peru 800 998 #&gt; Poland 504 1142 #&gt; Russia 991 1002 #&gt; Senegal 700 1083 #&gt; South Africa 1000 1295 #&gt; South Korea 718 1010 #&gt; Spain 500 995 #&gt; Sweden 996 996 #&gt; Tanzania 702 1061 #&gt; Turkey 971 1050 #&gt; United Kingdom 982 1028 #&gt; United States 1999 1473 #&gt; Venezuela 803 1000 7.2.5 Sélection d’un échantillon On décide par exemple d’analyser l’échantillon des réponses françaises en 2017 : fra17&lt;-don[don$country ==&quot;France&quot; &amp; don$survey==&quot;Spring2017&quot;,] source &lt;- &quot;Source : Pew Research Center, Global Attitude Survey, 2017, France&quot; summary(fra17) #&gt; survey country sex age #&gt; Spring2007: 0 France :996 Male :502 Min. :18.00 #&gt; Spring2017:996 Argentina: 0 Female:494 1st Qu.:40.00 #&gt; Brazil : 0 Median :54.00 #&gt; Canada : 0 Mean :52.55 #&gt; Chile : 0 3rd Qu.:66.00 #&gt; Germany : 0 Max. :94.00 #&gt; (Other) : 0 #&gt; today use_internet opi_USA #&gt; 1.Typical :685 1.Yes :868 1.Very favorable : 45 #&gt; 2.Particularly good:245 2.No :127 2.Somewhat favorable :383 #&gt; 3.Particularly bad : 54 3.Don&#39;t know: 1 3.Somewhat unfavorable:353 #&gt; 4.Don&#39;t know : 12 4.Refused : 0 4.Very unfavorable :190 #&gt; 5.Refused : 0 5.Don&#39;t know : 25 #&gt; 6.Refused : 0 #&gt; #&gt; opi_CHN opi_RUS weight #&gt; 1.Very favorable : 47 1.Very favorable : 40 Min. :0.1830 #&gt; 2.Somewhat favorable :360 2.Somewhat favorable :309 1st Qu.:0.3459 #&gt; 3.Somewhat unfavorable:381 3.Somewhat unfavorable:385 Median :0.6281 #&gt; 4.Very unfavorable :168 4.Very unfavorable :241 Mean :0.9987 #&gt; 5.Don&#39;t know : 40 5.Don&#39;t know : 21 3rd Qu.:1.1900 #&gt; 6.Refused : 0 6.Refused : 0 Max. :4.1079 #&gt; 7.2.6 Recodage des modalités Si l’on souhaite rendre un rapport en français, on va recoder les modalités des variables qui nous intéressent et en profiter pour déclarer manquantes les valeurs correspondant à des non-réponses ou des refus de répondre. levels(fra17$sex)&lt;-c(&quot;Homme&quot;,&quot;Femme&quot;) levels(fra17$today)&lt;-c(&quot;Typique&quot;,&quot;Très Bon&quot;,&quot;Très Mauvais&quot;,NA,NA) levels(fra17$use_internet)&lt;-c(&quot;Oui&quot;,&quot;Non&quot;,NA,NA) levels(fra17$opi_USA)&lt;-c(&quot;Trés Fav.&quot;,&quot;Fav.&quot;,&quot;Défav.&quot;,&quot;Très Déf.&quot;,NA,NA) levels(fra17$opi_RUS)&lt;-c(&quot;Trés Fav.&quot;,&quot;Fav.&quot;,&quot;Défav.&quot;,&quot;Très Déf.&quot;,NA,NA) levels(fra17$opi_CHN)&lt;-c(&quot;Trés Fav.&quot;,&quot;Fav.&quot;,&quot;Défav.&quot;,&quot;Très Déf.&quot;,NA,NA) 7.2.7 Découpage de variables quantitatives en classes On peut transformer la variable quantitative âge en variable qualitative (factor) à l’aide de la fonction cut(). La question va évidemment être de décider : combien on fait de classes ? selon quels seuils ? avec quels noms ? On peut décider de créer cinq classesd’âge à l’aide des quintiles de la distribution : fra17$age5&lt;-cut(fra17$age, breaks = quantile(fra17$age,c(0,0.2,0.4,0.6,0.8, 1)), include.lowest = T) levels(fra17$age5) &lt;-c(&quot;18-36 ans&quot;,&quot;37-49 ans&quot;,&quot;50-59 ans&quot;,&quot;60-68 ans&quot;,&quot;69-94-ans&quot;) Mais on peut aussi décider qu’on veut travailler sur les générations en choisissant les dates de 1949, 1969 et 1989 fra17$gen&lt;-2017-fra17$age fra17$gen4&lt;-cut(fra17$gen, breaks=c(min(fra17$gen), 1949, 1969, 1989, max(fra17$gen)), include.lowest = T) levels(fra17$gen4)&lt;-c(&quot; 1950&lt; &quot;,&quot;1950-69&quot;,&quot;1970-89&quot;,&quot;&gt; 1990&quot;) 7.2.8 Sélection On ne garde que les variable qui nous intéressent pour l’analyse. sel&lt;-fra17[,c(&quot;sex&quot;,&quot;age5&quot;,&quot;gen4&quot;,&quot;opi_USA&quot;,&quot;weight&quot;)] summary(sel) #&gt; sex age5 gen4 opi_USA weight #&gt; Homme:502 18-36 ans:212 1950&lt; :218 Trés Fav.: 45 Min. :0.1830 #&gt; Femme:494 37-49 ans:187 1950-69:407 Fav. :383 1st Qu.:0.3459 #&gt; 50-59 ans:199 1970-89:264 Défav. :353 Median :0.6281 #&gt; 60-68 ans:203 &gt; 1990 :107 Très Déf.:190 Mean :0.9987 #&gt; 69-94-ans:195 NA&#39;s : 25 3rd Qu.:1.1900 #&gt; Max. :4.1079 7.3 Opinion USA 7.3.1 la fonction table() Le dénombrement des modalités d’une variable se fait généralement avec la fonction table() qui permet de croiser une ou plusieurs variables. Ci-dessous on donne des exemples de croisement à une, deux ou trois variables t1&lt;-table(sel$opi_USA) kable(t1) Var1 Freq Trés Fav. 45 Fav. 383 Défav. 353 Très Déf. 190 t2&lt;-table(sel$opi_USA,sel$sex) kable(t2) Homme Femme Trés Fav. 27 18 Fav. 204 179 Défav. 164 189 Très Déf. 97 93 t3&lt;-table(sel$opi_USA,sel$sex,sel$gen4) kable(t3) Var1 Var2 Var3 Freq Trés Fav. Homme 1950&lt; 5 Fav. Homme 1950&lt; 39 Défav. Homme 1950&lt; 37 Très Déf. Homme 1950&lt; 31 Trés Fav. Femme 1950&lt; 2 Fav. Femme 1950&lt; 26 Défav. Femme 1950&lt; 41 Très Déf. Femme 1950&lt; 31 Trés Fav. Homme 1950-69 9 Fav. Homme 1950-69 78 Défav. Homme 1950-69 71 Très Déf. Homme 1950-69 33 Trés Fav. Femme 1950-69 7 Fav. Femme 1950-69 73 Défav. Femme 1950-69 82 Très Déf. Femme 1950-69 43 Trés Fav. Homme 1970-89 7 Fav. Homme 1970-89 57 Défav. Homme 1970-89 40 Très Déf. Homme 1970-89 25 Trés Fav. Femme 1970-89 6 Fav. Femme 1970-89 51 Défav. Femme 1970-89 55 Très Déf. Femme 1970-89 15 Trés Fav. Homme &gt; 1990 6 Fav. Homme &gt; 1990 30 Défav. Homme &gt; 1990 16 Très Déf. Homme &gt; 1990 8 Trés Fav. Femme &gt; 1990 3 Fav. Femme &gt; 1990 29 Défav. Femme &gt; 1990 11 Très Déf. Femme &gt; 1990 4 7.3.2 Visualisation avec plot ou barplot Les objets de type table à une ou deux dimensions s’affichent facilement avec barplot() barplot(t1, main=&quot;Opinion sur les USA&quot;) barplot(t2, main = &quot;Opinion sur les USA et Sexe&quot;) 7.3.3 Recodage On peut regrouper des modalités entre elle en leur donnant le même nom et en éliminer d’autres en leur donnant la modalité NA. sel$opi_USA2&lt;-sel$opi_USA levels(sel$opi_USA2) #&gt; [1] &quot;Trés Fav.&quot; &quot;Fav.&quot; &quot;Défav.&quot; &quot;Très Déf.&quot; levels(sel$opi_USA2)&lt;-c(&quot;Favorable&quot;,&quot;Favorable&quot;,&quot;Défavorable&quot;,&quot;Défavorable&quot;,NA,NA) t&lt;-table(sel$opi_USA2) t #&gt; #&gt; Favorable Défavorable #&gt; 428 543 prop.table(t) #&gt; #&gt; Favorable Défavorable #&gt; 0.4407827 0.5592173 barplot(100*t/sum(t)) A ce stade, on a certes établi le fait qu’il y a une proportion plus grande d’opinion défavorables (56%) que favorables (44%) mais il faut établir un intervalle de confiance pour savoir si cela est simplement dû au biais d’écdhantillonage. 7.3.4 Calcul de l’intervalle de confiance On va conduire un test pour trancher entre trois possibilités : opinion majoritairement favorable aux USA opinion majoritairement défavorable aux USA opinion partagée sans majorité claire On se fixe un intervalle de confiance de 95% (risque d’erreur de 5%) On se reportera pour plus de détails à : https://larmarange.github.io/analyse-R/intervalles-de-confiance.html prop.test(t) #&gt; #&gt; 1-sample proportions test with continuity correction #&gt; #&gt; data: t, null probability 0.5 #&gt; X-squared = 13.384, df = 1, p-value = 0.0002538 #&gt; alternative hypothesis: true p is not equal to 0.5 #&gt; 95 percent confidence interval: #&gt; 0.4093399 0.4726998 #&gt; sample estimates: #&gt; p #&gt; 0.4407827 Il semble donc que l’on puisse conclure que les français sont majoritairement défavorables aux USA puisque la proportion d’opinion favorbales est de 44% avec un intervalle de confiance compris entre 40.9 et 47.3 d’opinion favorable (pour un risque d’erreur p&lt;0.05) 7.3.5 Prise en compte de la variable de redressement. On a toutefois oublié de tenir compte de la variable de redressement (poids) qui tient compte du fit que l’échantillonage obtenu comportait des sur et sous-représentations de certaines cétégories de population. Du coup, il faut réécrire l’ensemble du programme en utilisant l’instruction wtd.table du package questionr. t&lt;-wtd.table(sel$opi_USA2, weights=sel$weight) t #&gt; Favorable Défavorable #&gt; 462.4494 510.0442 prop.table(t) #&gt; Favorable Défavorable #&gt; 0.4755295 0.5244705 prop.test(t) #&gt; #&gt; 1-sample proportions test with continuity correction #&gt; #&gt; data: t, null probability 0.5 #&gt; X-squared = 2.2325, df = 1, p-value = 0.1351 #&gt; alternative hypothesis: true p is not equal to 0.5 #&gt; 95 percent confidence interval: #&gt; 0.4437896 0.5074651 #&gt; sample estimates: #&gt; p #&gt; 0.4755295 On voit que la proportion d’opinion favorable est plus élevée après redressement (47.6%) ce qui du coup modifie l’intervalle de confiance (44.4% à 50.7%) et ne permet plus d’exclure l’hypothèse que l’opinion favorable soit en fait majoritaire. On concluera donc que L’opinion des français sur les USA en 2017 est partagée. 7.4 Opinion USA / Sexe On choisit d’analyser la relation entre l’avis sur les USA et le sexe et on pose H0 : il n’y a pas de relation entre les deux variables. 7.4.1 tableau de contingence On commence par recoder les deux variables puis par créer le tableau de contingence pondéré par la variable de pondération. On l’affiche en ajoutant les sommes en ligne et en colonnes avec addmargins() levels(sel$sex) &lt;- c(&quot;Homme&quot;,&quot;Femme&quot;) tabcont&lt;-wtd.table(sel$sex,sel$opi_USA2, weights = sel$weight) tabcont #&gt; Favorable Défavorable #&gt; Homme 238.0424 231.8120 #&gt; Femme 224.4070 278.2321 addmargins(tabcont) #&gt; Favorable Défavorable Sum #&gt; Homme 238.0424 231.8120 469.8544 #&gt; Femme 224.4070 278.2321 502.6391 #&gt; Sum 462.4494 510.0442 972.4936 7.4.2 Pourcentages On peut calculer trois tableaux de pourcentage différents à l’aide des fonctions lprop, cprop et prop du package questionr. On se contentera d’afficher le tableau des % en lignes pusique c’est celui qui donne la répartition des avis défavorables eyt favorables pour chaque sexe. lprop(tabcont) #&gt; Favorable Défavorable Total #&gt; Homme 50.7 49.3 100.0 #&gt; Femme 44.6 55.4 100.0 #&gt; All 47.6 52.4 100.0 Commentaire : On constate que les femmes sont a priori moins favorables aux USA (44.6%) que les hommes (50.7%) mais il est difficile d’affirmer à ce stade que la relation est significative. 7.4.3 Première visualisation Onpeut visualiser notre table avec plot() plot(tabcont, col=c(&quot;lightyellow&quot;,&quot;lightblue&quot;), # main=titre, sub=source, ) 7.4.4 test du chi-2 On réalise le test du chi-2 avec la fonction chisq.test() qui crée un objet complexe qui rappelle celui qui est créé par lm() pour la régression. toto&lt;-chisq.test(tabcont) toto #&gt; #&gt; Pearson&#39;s Chi-squared test with Yates&#39; continuity correction #&gt; #&gt; data: tabcont #&gt; X-squared = 3.2885, df = 1, p-value = 0.06977 Ici, la relation est presque significative (p = 0.07). On ne peut pas rejeter H0 avec un risque d’erreur inférerieur à 5% mais on pourrait le faire pour un risque d’erreur de 10%. 7.4.5 Analyse des résidus Lorsque la relation est significative, l’analyse des résidus permet de voir quelles sont les cases présentent des anomalies significatives. On peut pour cela imprimer quatre tableaux correspondant aux valeurs observées, aux valeurs attendues, aux écarts entre les deux (résidus bruts) et à un test sur les écarts les plus significatifs (résidus standardisés). ce que l’on peut aussi faire graphiquement kable(toto$observed,caption = &quot;Valeurs observées&quot;) Table 7.1: Valeurs observées Favorable Défavorable Homme 238.0424 231.8120 Femme 224.4070 278.2321 kable(toto$expected, caption = &quot;Valeurs attendues&quot;) Table 7.1: Valeurs attendues Favorable Défavorable Homme 223.4296 246.4248 Femme 239.0198 263.6194 kable(tabcont-toto$expected, caption = &quot;Résidus bruts&quot;) Table 7.1: Résidus bruts Favorable Défavorable Homme 14.61274 -14.61274 Femme -14.61274 14.61274 kable(toto$stdres, caption= &quot;Résidus standardisés&quot;) Table 7.1: Résidus standardisés Favorable Défavorable Homme 1.877656 -1.877656 Femme -1.877656 1.877656 On peut aussi visualiser graphiquement les résidus standardisés avec avec mosaicplot() et l’option shade=T. Seules les cases ayant des résidus standardisés supérieures à +2 ou inférieurs à -2 seront colorées, ce qui revient à visualiser uniquement les anomalies significatives avec un risque d’erreur p&lt; 0.05. mosaicplot(tabcont,shade=T) 7.5 Opinion USA / Âge Supposons qu’on veuille analyser la relation entre l’opinion sur les USA et l’effet des classes d’âge ou des génération. Les deux variables age5 et gen4 sont issuesde la même variable mais elle n’ont pas le même sens d’un point de vue thématique 7.5.1 Effet de génération tabcont&lt;-wtd.table(sel$gen4,sel$opi_USA2, weights=sel$poids) #&gt; Warning: Unknown or uninitialised column: `poids`. #&gt; Warning in wtd.table(sel$gen4, sel$opi_USA2, weights = sel$poids): no weights #&gt; argument given, using uniform weights of 1 round(addmargins(tabcont),1) #&gt; Favorable Défavorable Sum #&gt; 1950&lt; 72 140 212 #&gt; 1950-69 167 229 396 #&gt; 1970-89 121 135 256 #&gt; &gt; 1990 68 39 107 #&gt; Sum 428 543 971 lprop(tabcont) #&gt; Favorable Défavorable Total #&gt; 1950&lt; 34.0 66.0 100.0 #&gt; 1950-69 42.2 57.8 100.0 #&gt; 1970-89 47.3 52.7 100.0 #&gt; &gt; 1990 63.6 36.4 100.0 #&gt; All 44.1 55.9 100.0 plot(tabcont, col=c(&quot;lightyellow&quot;,&quot;lightblue&quot;), main=&quot;Opinion sur les USA selon la génération&quot;, sub=source, ) On remarque que l’opinion sur les USA semble de plus en plus positive au fur et à mesure des générations. Mais il faut tester pour voir si cet effet est significatif. titi&lt;-chisq.test(tabcont) titi #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: tabcont #&gt; X-squared = 26.901, df = 3, p-value = 6.175e-06 On obtient donc une relation très significative (Chi-2 = 26.9 , degrés de liberté =3, p &lt; 0.001) entre la génération des personnes et leur opinion sur les USA. L’étude des résidus standardisés montre que cette relation est liée au fait que les générations récentes sont beaucoup plus favorables aux USA que les générations anciennes. On peut visualiser la relation avec la fonction mosaicplot(shaded=T) mosaicplot(tabcont, shade = T) 7.5.2 Effet d’âge Aurions nous tiré les mêmes conclusions en prenant un âge en 5 classes ? tabcont&lt;-wtd.table(sel$age5,sel$opi_USA2, weights=sel$poids) #&gt; Warning: Unknown or uninitialised column: `poids`. #&gt; Warning in wtd.table(sel$age5, sel$opi_USA2, weights = sel$poids): no weights #&gt; argument given, using uniform weights of 1 round(addmargins(tabcont),1) #&gt; Favorable Défavorable Sum #&gt; 18-36 ans 123 87 210 #&gt; 37-49 ans 80 101 181 #&gt; 50-59 ans 84 109 193 #&gt; 60-68 ans 75 120 195 #&gt; 69-94-ans 66 126 192 #&gt; Sum 428 543 971 lprop(tabcont) #&gt; Favorable Défavorable Total #&gt; 18-36 ans 58.6 41.4 100.0 #&gt; 37-49 ans 44.2 55.8 100.0 #&gt; 50-59 ans 43.5 56.5 100.0 #&gt; 60-68 ans 38.5 61.5 100.0 #&gt; 69-94-ans 34.4 65.6 100.0 #&gt; All 44.1 55.9 100.0 plot(tabcont, col=c(&quot;lightyellow&quot;,&quot;lightblue&quot;), main=&quot;Opinion sur les USA selon l&#39;âge&quot;, sub=source, ) titi&lt;-chisq.test(tabcont) titi #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: tabcont #&gt; X-squared = 27.75, df = 4, p-value = 1.402e-05 On voit que la relation serait tout aussi significative et montrerait une variation continue de l’avius sur les USA avec l’âge, mais avec une opposition particulière des moins de 36 ans et des plus de 68 ans. mosaicplot(tabcont, shade = T) 7.6 Opinion USA / Age &amp; Sexe On va se limiter au cas où l’on veut étudier la relation entre X et Y toutes choses égales quant à l’effet d’une troisième variable Z qui sert de variable de contrôle. Par exemple, on veut savoir s’il existe un lien entre l’âge (X) et l’avis sur les USA (Y) demeure valable aussi bien pour les hommes que pour les femmes (Z). 7.6.1 Sous-échantillon des hommes hom&lt;-sel[sel$sex==&quot;Homme&quot;,] tabcont&lt;-wtd.table(hom$age5,hom$opi_USA2) #&gt; Warning in wtd.table(hom$age5, hom$opi_USA2): no weights argument given, using #&gt; uniform weights of 1 round(addmargins(tabcont),0) #&gt; Favorable Défavorable Sum #&gt; 18-36 ans 65 49 114 #&gt; 37-49 ans 46 49 95 #&gt; 50-59 ans 39 46 85 #&gt; 60-68 ans 40 58 98 #&gt; 69-94-ans 41 59 100 #&gt; Sum 231 261 492 lprop(tabcont) #&gt; Favorable Défavorable Total #&gt; 18-36 ans 57.0 43.0 100.0 #&gt; 37-49 ans 48.4 51.6 100.0 #&gt; 50-59 ans 45.9 54.1 100.0 #&gt; 60-68 ans 40.8 59.2 100.0 #&gt; 69-94-ans 41.0 59.0 100.0 #&gt; All 47.0 53.0 100.0 chisq.test(tabcont) #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: tabcont #&gt; X-squared = 7.6622, df = 4, p-value = 0.1048 Dans le sous échantillon des 492 hommes, on n’observe pas de relation significative entre l’avis sur les USA et l’âge (Chi-2 = 7.6 pour 4 degré de liberté, p &gt; 0.10) 7.6.2 Sous-échantillon des femmes fem&lt;-sel[sel$sex==&quot;Femme&quot;,] tabcont&lt;-wtd.table(fem$age5,fem$opi_USA2) #&gt; Warning in wtd.table(fem$age5, fem$opi_USA2): no weights argument given, using #&gt; uniform weights of 1 round(addmargins(tabcont),0) #&gt; Favorable Défavorable Sum #&gt; 18-36 ans 58 38 96 #&gt; 37-49 ans 34 52 86 #&gt; 50-59 ans 45 63 108 #&gt; 60-68 ans 35 62 97 #&gt; 69-94-ans 25 67 92 #&gt; Sum 197 282 479 lprop(tabcont) #&gt; Favorable Défavorable Total #&gt; 18-36 ans 60.4 39.6 100.0 #&gt; 37-49 ans 39.5 60.5 100.0 #&gt; 50-59 ans 41.7 58.3 100.0 #&gt; 60-68 ans 36.1 63.9 100.0 #&gt; 69-94-ans 27.2 72.8 100.0 #&gt; All 41.1 58.9 100.0 chisq.test(tabcont) #&gt; #&gt; Pearson&#39;s Chi-squared test #&gt; #&gt; data: tabcont #&gt; X-squared = 23.273, df = 4, p-value = 0.0001117 Dans le sous échantillon des 479 femmes, on observe en revanche une relation très significative entre l’avis sur les USA et l’âge (Chi-2 = 23.3 pour 4 degré de liberté, p &lt; 0.001) 7.6.3 Régression logistique La suite logique des analyses bivariées de variables qualitatives est la régression logistique qui permet de modéliser une variable qualitative binaire (Y) par un ensemble dr’autres variables qualitatives ou quantitatives (X1, X2, X3, …). Par exemple, on peut se demander si le fait d’être favorable ou très favorable aux USA (Y) dépend simultanément du sexe (X1) et de l’âge (X2). sel$opi_USA_fav&lt;-sel$opi_USA2==&quot;Favorable&quot; toto&lt;-glm(sel$opi_USA_fav ~ sel$sex + sel$age5 , family = &quot;binomial&quot;) anova(toto,test = &quot;Chisq&quot;) #&gt; Analysis of Deviance Table #&gt; #&gt; Model: binomial, link: logit #&gt; #&gt; Response: sel$opi_USA_fav #&gt; #&gt; Terms added sequentially (first to last) #&gt; #&gt; #&gt; Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) #&gt; NULL 970 1332.4 #&gt; sel$sex 1 3.3421 969 1329.1 0.06753 . #&gt; sel$age5 4 27.4485 965 1301.7 1.613e-05 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(toto) #&gt; #&gt; Call: #&gt; glm(formula = sel$opi_USA_fav ~ sel$sex + sel$age5, family = &quot;binomial&quot;) #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.4517 0.1532 2.949 0.00319 ** #&gt; sel$sexFemme -0.2281 0.1317 -1.732 0.08328 . #&gt; sel$age537-49 ans -0.5771 0.2053 -2.811 0.00494 ** #&gt; sel$age550-59 ans -0.5853 0.2024 -2.892 0.00383 ** #&gt; sel$age560-68 ans -0.8097 0.2035 -3.978 6.94e-05 *** #&gt; sel$age569-94-ans -0.9910 0.2070 -4.788 1.69e-06 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 1332.4 on 970 degrees of freedom #&gt; Residual deviance: 1301.6 on 965 degrees of freedom #&gt; (25 observations deleted due to missingness) #&gt; AIC: 1313.6 #&gt; #&gt; Number of Fisher Scoring iterations: 4 Au bout du compte, l’effet principal demeure bien celui de l’âge. L’effet du sexe devient non significatif lorsque l’onb contrôle l’âge (p&gt;0.05). Les femmes sont moins favorables aux USA mais cet effet s’explique en partie au moins par leur plus grande longévité. "],["08-Graphique-Base.html", "Partie 8 Graphiques avec R-Base 8.1 Introduction 8.2 Préparation des données 8.3 La fonction génératrice plot() 8.4 Les autres fonctions génératrice 8.5 Les fonctions complémentaires 8.6 Conclusion", " Partie 8 Graphiques avec R-Base Mise en place : Télécharger le dossier exo8 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo8.Rproj dans Rstudio. 8.1 Introduction 8.1.1 Pourquoi s’em…bêter à utiliser les fonctions primitives de R pour faire des graphiques ? On peut se demander si cela vaut la peine d’utiliser R-base pour faire des graphiques. En effet R propose maintenant des packages produisant facilement de très jolis graphiques statiques (ggplot2) ou dynamiques (plotly). La réponse est cependant oui car : il faut pouvoir relire et améliorer des programmes anciens les primitives graphiques de R permettent de créer ses propres applications les packages ggplot2 et plotly reprennent des concepts de R-base Et la plus raison la plus importante : c’est l’occasion d’apprendre à créer ses propres fonctions et ainsi de meiiux apprécier les qualités et les défauts de celles que l’on trouve dans les packages qu’on utilise. 8.1.2 Trois étapes pour créer un graphique Comme indiqué par Sophie Baillargeon dans son excellent cours de R de l’Université de Laval (Québec) , un programme pour créer un graphique avec le système graphique de base en R se décompose typiquement en 3 étapes utilisant des fonctions différentes : Etape 1 : La configuration des paramètres graphiques généraux (facultatif) : énoncé par ou layout. Etape 2 : L’initialisation d’un graphique (obligatoire) : fonction de base : plot (choisit un graphique pertinent à produire selon ce qu’elle reçoit en entrée), ou fonction pour un type spécifique graphiques : pairs, matplot, pie, barplot, dotchart, mosaicplot, hist, boxplot, qqnorm, qqplot, curve, etc. Etape 3. L’ajout séquentiel d’éléments au graphique (facultatif) : fonctions d’ajouts à un graphique déjà initialisé : points, matpoints, lines, matlines, abline, segments, arrows, rect, polygon, legend, text, mtext, title, axis, box, qqline, etc.; matplot, barplot, hist, boxplot, curve avec l’argument add = TRUE. 8.2 Préparation des données 8.2.1 Chargement du fichier On charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points. don&lt;-read.table(file = &quot;resources/data/tips/tips.csv&quot;, sep = &quot;;&quot;, header = T) head(don) #&gt; IDEN TOTBILL TIP SEX SMOKER DAY TIME SIZE #&gt; 1 R001 16.99 1.01 1 0 6 1 2 #&gt; 2 R002 10.34 1.66 0 0 6 1 3 #&gt; 3 R003 21.01 3.50 0 0 6 1 3 #&gt; 4 R004 23.68 3.31 0 0 6 1 2 #&gt; 5 R005 24.59 3.61 1 0 6 1 4 #&gt; 6 R006 25.29 4.71 0 0 6 1 4 8.2.2 Contenu du fichier Ce dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives. Sources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics. 8.2.3 Dictionaire des variables IDEN : identifiant du repas TOTBILL : prix du repas (en dollars des années 1990) TIP : pourboire (en dollars des années 1990) SEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme) SMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1) DAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …) TIME : repas pris en journée (0) ou le soir (1) SIZE : nombre de convives 8.2.4 Recodage des variables Le type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français : don$IDEN&lt;-as.character(don$IDEN) don$SEX&lt;-as.factor(don$SEX) levels(don$SEX)&lt;-c(&quot;Homme&quot;,&quot;Femme&quot;) don$SMOKER&lt;-as.factor(don$SMOKER) levels(don$SMOKER)&lt;-c(&quot;Non fumeur&quot;, &quot;Fumeur&quot;) don$DAY&lt;-as.factor(don$DAY) levels(don$DAY)&lt;-c(&quot;Mercredi&quot;,&quot;Jeudi&quot;,&quot;Vendredi&quot;,&quot;Samedi&quot;) don$TIME&lt;-as.factor(don$TIME) levels(don$TIME)&lt;-c(&quot;Journée&quot;,&quot;Soirée&quot;) 8.2.5 Ajout d’une nouvelle variable On crée la variable PCT qui est le rapport entre le pourboire (TIP) et le prix total (TOTBILL) du repas exprimé en pourcentage. don$PCT&lt;-100*don$TIP/don$TOTBILL 8.2.6 Résumé de l’ensemble du tableau summary(don) #&gt; IDEN TOTBILL TIP SEX #&gt; Length:244 Min. : 3.07 Min. : 1.000 Homme:157 #&gt; Class :character 1st Qu.:13.35 1st Qu.: 2.000 Femme: 87 #&gt; Mode :character Median :17.80 Median : 2.900 #&gt; Mean :19.79 Mean : 2.998 #&gt; 3rd Qu.:24.13 3rd Qu.: 3.562 #&gt; Max. :50.81 Max. :10.000 #&gt; SMOKER DAY TIME SIZE PCT #&gt; Non fumeur:151 Mercredi:62 Journée: 68 Min. :1.00 Min. : 3.564 #&gt; Fumeur : 93 Jeudi :19 Soirée :176 1st Qu.:2.00 1st Qu.:12.913 #&gt; Vendredi:87 Median :2.00 Median :15.477 #&gt; Samedi :76 Mean :2.57 Mean :16.080 #&gt; 3rd Qu.:3.00 3rd Qu.:19.148 #&gt; Max. :6.00 Max. :71.034 ##.Paramètres généraux et disposition des graphiques 8.2.7 La fonction par() La fonction par() ne produit pas directement de graphique mais permet de : définir la disposition de plusieurs graphiques spécifier la largeur des marges définir des paramètres généraux valables pour tous les graphiques Elle se comporte donc comme une feuille de style ou un CSS. Il est de ce fait prudent de stocker les paramètres d’origine avant de les modifier. Il y a 66 paramètres différents … Il est prudent de les stocker dans leur configuration d’origine avant de les modifier. # Stockage des paramètres d&#39;origine old&lt;- par() # Affichage des paramètres d&#39;origine head(old) #&gt; $xlog #&gt; [1] FALSE #&gt; #&gt; $ylog #&gt; [1] FALSE #&gt; #&gt; $adj #&gt; [1] 0.5 #&gt; #&gt; $ann #&gt; [1] TRUE #&gt; #&gt; $ask #&gt; [1] FALSE #&gt; #&gt; $bg #&gt; [1] &quot;white&quot; 8.2.8 fonction par() + mfrow Supposons que l’on veuille disposer verticalement une boxplot et un histogramme de la variable PCT. On va utiliser l’instruction mfrow=c(2,1) pour placerles deux figures suivantes sur des lignes séparées : par(mfrow=c(2,1)) hist(don$PCT, main=&quot;Histogramme&quot;, xlab=&quot;Pourboires (%)&quot;) boxplot(don$PCT, horizontal=T, main=&quot;Boxplot&quot;, xlab = &quot;Pourboires (%)&quot;) Si l’on préfère une disposition horizontale on modifie le paramètre mfrow : par(mfrow=c(1,2)) hist(don$PCT, main=&quot;Histogramme&quot;, xlab=&quot;Pourboires (%)&quot;) boxplot(don$PCT, horizontal=T, main=&quot;Boxplot&quot;, xlab = &quot;Pourboires (%)&quot;) 8.2.9 Autres paramètres de par() On peut ajouter toute une série d’autres paramètres par défaut. Par exemple, pour faire un graphique sur fonds noir (bg) à traits blancs (fg), puis régler la taille (cex) et la couleur (col) des différents textes. par(mfrow = c(1,2), bg=&quot;black&quot;, fg=&quot;white&quot;, cex.main = 1, col.main = &quot;gray80&quot;, cex.lab = 0.8, col.lab = &quot;orange&quot;, cex.axis = 0.6, col.axis = &quot;red&quot; ) hist(don$PCT, main=&quot;Histogramme&quot;, xlab=&quot;Pourboires (%)&quot;,col=&quot;lightyellow&quot;) boxplot(don$PCT, horizontal=T, main=&quot;Boxplot&quot;, xlab = &quot;Pourboires (%)&quot;,col=&quot;lightyellow&quot;) 8.2.10 La fonction layout() La fonction layout() permet une gestion plus précise de la disposition de différents graphiques sur une même fenêtre que la fonction par(). Sa syntaxe semble difficile mais elle est plus simple si on crée la matrice d’allocation des figures avec rbind() ce qui permet de visualiser la position de chaque figure facilement ## Divise la figure en 2 lignes et 2 colonnes ## alloue la figure 1 à toute la première ligne ## alloue les figures 2 et 3 à la deuxième ligne mat&lt;-rbind(c(1,1), c(2,3)) layout(mat) boxplot(don$PCT~don$SEX, horizontal=T) # Figure 1 hist(don$PCT) # Figure 2 plot(don$SEX) # Figure 3 On peut préciser la longueur et la largeur des différentes lignes et colonnes avec widths et heights . On peut visualiser le résultat de la mise en page avec layout.show() mat&lt;-rbind(c(1,2), c(0,3)) nf &lt;- layout(mat, widths = c(1,4), heights = c(4,1), respect=T) layout.show(nf) On peut ensuite remplir le layout avec des figures, par exemple un plot et deux boxplots mat&lt;-rbind(c(1,2), c(0,3)) par(mar=c(2,2,0,0)) layout(mat, widths = c(1,4), heights = c(4,1), respect=TRUE) boxplot(don$PCT,ann = F) plot(don$TOTBILL,don$PCT,pch=19,col=&quot;red&quot;,cex=0.6,xlab=&quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) boxplot(don$TOTBILL, horizontal=T) 8.3 La fonction génératrice plot() 8.3.1 Une super-fonction L’instruction plot() n’est pas une fonction graphique comme les autres car elle va renvoyer des résultats différents selon les circonstances. En d’autres termes c’est un outil de programmation orienté objet qui va adapter le résultat à la nature des variables et plus généralement des objets qui lui sont fournis en entrée. Par exemple, un plot() d’une variable de type factor va donner le même résultat que barplot() appliqué à la table de dénombrement de cette variable Autre exemple, la fonction lm() génère un objet complexe (modèle de régression linéaire). Lorsque l’on effectue un plot de cet objet, on utilise en fait une fonction plot.lm() qui fournit les diagnostics de la régression. 8.3.2 plot(X) / X de type factor La fonction plot() est pratique pour visualiser une variable de type factor à l’aide d’un barplot(). par(mfrow=c(1,2)) X&lt;-don$SEX plot(X, main=&quot;plot(x=factor)&quot;) barplot(table(X), main=&quot;barplot(table(x=factor))&quot;) 8.3.3 plot(X) / X de type numeric Mais elle est sans intérêt pour une variable de type numérique, sauf si on la trie avec sort() par(mfrow=c(1,2)) plot(don$TIP, main=&quot;Sans intérêt ...&quot;) plot(sort(don$TIP),main=&quot;Un peu mieux...&quot;) 8.3.4 plot(X,Y) / X et Y de type factor Plot renvoie un graphique de type mosaicplot() par(mfrow=c(1,2),mar=c(2,2,0,2)) plot(don$SEX,don$TIME) plot(don$TIME,don$SEX) 8.3.5 plot(X,Y) / X et Y de type numerique Plot renvoie un graphique de type scatterplot() par(mfrow=c(1,1)) plot(don$TOTBILL,don$TIP) 8.3.6 plot(X,Y) / X de type factor et Y de type numerique Plot renvoie un graphique de type boxplot() si le factor est en premier, par(mfrow=c(1,1)) plot(don$SEX,don$TIP, horizontal=T) 8.3.7 plot(X,Y) / X de type factor et Y de type numerique Plot renvoie un diagramme de faible intérêt si la variable factor est en second. Il s’agit en termes statistiques d’un ensemble de diagrammes de distribution . plot(don$TIP,don$SEX) 8.3.8 plot(model) / model = lm(Y~X) L’appplication de plot à un modèle linéaire issu de lm() permet de générer 6 graphiques différents (Cf. cours sur la régression). Par défaut, R affiche les graphiques n° 1,2,3,5 (mais je préfère le n°4 …) par(mfrow=c(2,2)) model&lt;-lm(don$PCT~don$TOTBILL) plot(model) Le graphique n°1 vérifie si les résidus sont réguliers plot(model,1, main= &quot;Absence d&#39;autocorrélation ?&quot;,labels.id = don$IDEN) Le graphique n°2 vérifie si les résidus sont distribués de façon gaussienne plot(model,2, main= &quot;Normalité ?&quot;,labels.id = don$IDEN) Le graphique n°3 vérifie si la variance des résidus est constante plot(model,3, main= &quot;Homogénéité ?&quot;,labels.id = don$IDEN) Le graphique n°4 vérifie si des valeurs exceptionnelles existent à l’aide de la distance de Cook. plot(model,4, main= &quot;Valeurs exceptionnelles ?&quot;,labels.id = don$IDEN) 8.4 Les autres fonctions génératrice On peut créer un graphque avec plot() mais aussi avec d’autres fonctions dont le nom se termine en général par —plot pour bien rappeler leur rôle de création du graphique. barplot boxplot hist density pie matplot pairs mosaicplot curve … 8.4.1 La fonction barplot() La fonction barplot() permett de créer des diagrammes en barres qui résultent en général du dénombrement d’une ou deux variable qualitative à l’aide des fonctions table() ou xtabs(). mytable &lt;- table(don$DAY) mytable #&gt; #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 62 19 87 76 myxtabs &lt;- xtabs(~don$DAY) myxtabs #&gt; don$DAY #&gt; Mercredi Jeudi Vendredi Samedi #&gt; 62 19 87 76 Cas d’une table à une seule variable : barplot(height = table(don$DAY), xlab = &quot;fréquence&quot;, ylab = &quot;jour de la semaine&quot;) Cas d’une table à une deux variables : barplot(height = table(don$DAY,don$SEX), xlab = &quot;fréquence&quot;, ylab = &quot;jour de la semaine&quot;) Exemple de figure complète avec toute une série de paramètres optionnels placés soit dans barplot(), soit dans par() par(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6) barplot(height = table(don$DAY,don$SEX), horiz = TRUE, col = rainbow(n=4,alpha = 0.5), legend=TRUE, ylab = &quot;fréquence&quot;, xlab = &quot;jour de la semaine&quot;, main = &quot;Qui paye le repas ?&quot;, sub = &quot;Source : Pourboires de 244 repas dans un restaurant américains au début des années 1990 (Bryant &amp; Smith, 1995)&quot;) On remarque que les hommes paient plus souvent le repas que les femmes le vendredi et surtout le samedi … 8.4.2 Les fonctions hist() et density() On présente ensemble ces trois fonctions qui sont très complémentaires puisqu’elles permettent l’une et l’autre de créer un histogramme hist() et de lui adjoindre avec lines() une courbe lissée générée par density(). La syntaxe minimale est la suivante : hist(don$PCT, probability = TRUE) lines(density(don$PCT)) On peut ensuite préciser les paramètres des trois fonctions façon plus ou moins complexes par(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6, bg=&quot;black&quot;,fg=&quot;white&quot;,col.lab=&quot;white&quot;,col.axis=&quot;white&quot;,col.main=&quot;white&quot;) hist(don$PCT, probability = TRUE, breaks = quantile(don$PCT,c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)), col=terrain.colors(n=10,alpha=0.8), xlab = &quot;Pourboires en %&quot;, ylab = &quot;Densité de probabilité&quot;, main = &quot;Histogramme des pourboires par déciles&quot;, sub = &quot;Source : Pourboires de 244 repas dans un restaurant américains au début des années 1990 (Bryant &amp; Smith, 1995)&quot;, xlim =c(0,30) ) lines(density(don$PCT,bw=2), col=&quot;red&quot;,lwd=2) Et si on doit faire plusieurs figures, on peut créer sa fonction : monhist&lt;-function(var, nomvar=&quot;variable&quot;) { par(cex.main = 1, cex.lab = 0.8, cex.axis =0.8, cex.sub=0.6, bg=&quot;black&quot;,fg=&quot;white&quot;,col.lab=&quot;white&quot;,col.axis=&quot;white&quot;, col.main=&quot;white&quot;, col.sub=&quot;white&quot;) hist(var, probability = TRUE, breaks = unique(quantile(var,c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1))), col=terrain.colors(n=10,alpha=0.8), xlab = nomvar, ylab = &quot;Densité de probabilité&quot;, main= &quot;Mon bel histogramme par déciles ...&quot; ) lines(density(var), col=&quot;red&quot;,lwd=2) } Application de la fonction au prix du repas monhist(don$TOTBILL,&quot;Prix du repas (en $)&quot;) Application de la fonction aumontant du pourboire monhist(don$TIP,&quot;Montant du pourboire (en $)&quot;) 8.5 Les fonctions complémentaires Il s’agit de fonctions qui ne peuvent pas s’executer seules mais ne peuvent être lancées qu’après l’execution d’une fonction graphique principale comme plot(), barplot(), hist(), … Nous en avons déjà vu un exemple avec la fonction lines() qui s’execute après la fonction hist() mais ne peut fonctionner seule. Le programme ci-dessous renverra un message d’erreur lines(density(don$PCT), col=&quot;red&quot;,lwd=2) # ne marchera pas Error in plot.xy(xy.coords(x, y), type = type, …) : plot.new has not been called yet 8.5.1 Exemple d’un nuage de points (X,Y) On va prendre comme exemple l’ajout de fonctions graphiques complémentaires à un nuage de point : plot(don$TOTBILL,don$TIP, xlab = &quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) On neutralise l’affichage des points générés par plot() et on les trace avec la fonction points() en précisant leur taille (nombre de repas) et leur couleur (hommes ou femmes) et en ajoutant une légende avec legend() plot(don$TOTBILL,don$TIP, cex=0,xlab = &quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) points(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19) legend(&quot;topleft&quot;, c(&quot;Hommes&quot;,&quot;Femmes&quot;), col=c(&quot;black&quot;,&quot;red&quot;), pch=19, cex=1) On ajoute ensuite une grille avec grid() et des droites correspondant à la moyenne de X et à celle de Y avec abline(v= …) et abline(h= …) plot(don$TOTBILL,don$TIP, cex=0,xlab = &quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) points(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19) legend(&quot;topleft&quot;, c(&quot;Hommes&quot;,&quot;Femmes&quot;), col=c(&quot;black&quot;,&quot;red&quot;), pch=19, cex=1) grid() abline(v=mean(don$TOTBILL), lty=2,lwd=2,col=&quot;blue&quot;) abline(h=mean(don$TIP), lty=2,lwd=2,col=&quot;blue&quot;) On ajoute ensuite une droite de régression avec abline(model) ` plot(don$TOTBILL,don$TIP, cex=0,xlab = &quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) points(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19) legend(&quot;topleft&quot;, c(&quot;Hommes&quot;,&quot;Femmes&quot;), col=c(&quot;black&quot;,&quot;red&quot;), pch=19, cex=1) grid() abline(v=mean(don$TOTBILL), lty=2,lwd=2,col=&quot;blue&quot;) abline(h=mean(don$TIP), lty=2,lwd=2,col=&quot;blue&quot;) maregression &lt;- lm(don$TIP~don$TOTBILL) abline(maregression,lty=1,lwd=3,col=&quot;brown&quot;) On peut aussi ajouter un texte à l’emplacement de son choix avec text(). Par exemple, repérer les individus à très forts résidus plot(don$TOTBILL,don$TIP, cex=0,xlab = &quot;Prix du repas&quot;,ylab=&quot;Pourboire&quot;) points(don$TOTBILL,don$TIP, cex=sqrt(don$SIZE)/2, col=don$SEX, pch=19) legend(&quot;topleft&quot;, c(&quot;Hommes&quot;,&quot;Femmes&quot;), col=c(&quot;black&quot;,&quot;red&quot;), pch=19, cex=1) grid() abline(v=mean(don$TOTBILL), lty=2,lwd=2,col=&quot;blue&quot;) abline(h=mean(don$TIP), lty=2,lwd=2,col=&quot;blue&quot;) maregression &lt;- lm(don$TIP~don$TOTBILL) abline(maregression,lty=1,lwd=3,col=&quot;brown&quot;) don2&lt;-don[abs(maregression$residuals)&gt;2,] text(don2$TOTBILL,don2$TIP,don2$IDEN,cex = 0.5, pos = 1, col=&quot;gray30&quot;) 8.6 Conclusion 8.6.1 On peut faire de beaux graphiques avec R-Base … Pour cela il faut bien comprendre les trois étapes : Fixer les paramètres graphiques généraux avec par() ou layout() Utiliser une fonction génératrice comme plot(), barplot(), ou hist() Ajouter des fonctions complémentaires comme lines(), points(), text(), abline(), … Et si on ne veut pas refaire toujours les mêmes codes : créer ses propres fonctions en suivant l’exemple de monhist() 8.6.2 On peut utiliser des packages spécialisés Plusieurs packages réalisées à partir des primitives graphiques de R-Base sont spécialisés dans la réalisation d’analyses bivariées et adaptés au type des variables. car : pour croiser deux variables quantitatives library(car) scatterplot(don$TOTBILL,don$TIP) vcd : pour croiser deux variables qualitatives library(vcd) mosaicplot(don$SEX~don$DAY,shade=T) beanplot : pour croiser une variable qualitative et une variable quantitative library(beanplot) beanplot(don$PCT~don$DAY,shade=T) #&gt; log=&quot;y&quot; selected 8.6.3 ggally : un package spécialisé dans la statistique bivariée Le récent package ggally est spécialisé dans l’analyse des relations statistiques entre deux variables. Il reprend plusieurs autres packages (notamment ggplot2) pour offrir une solution intégrée avec une syntaxe simple et intuitive. 8.6.4 ggplot2 : un package graphique universel ? Fruit des travaux d’Hadley Wickham et de l’équipe de développement de R-Studio, le package ggplot2 est un élément central de l’univers tidyverse, au point de faire désormais partie des “standards” de l’apprentissage de R. Mais sa connaissance approfondie est longue et pas toujours intuitive malgré les efforts de ses auteurs. A la longue, les paramètres de base des graphiques ggplot2 peuvent apparaître lassants et il faut donc bien approfondir sa connaissance pour réaliser des figures originales au niveau du style. Sinon c’est un peu le “fast food” de la visualisation : universel mais manquant de goût et d’originalité… "],["09-Graphique-ggplot.html", "Partie 9 Graphiques avec ggplot2 9.1 Introduction 9.2 préparation des données 9.3 Principes généraux 9.4 X discrète 9.5 X quantitative continue 9.6 X et Y quantitatives continues 9.7 X quantitative continue et Y discrète 9.8 Deux variables X et Y discrètes 9.9 Conclusion", " Partie 9 Graphiques avec ggplot2 Mise en place : Télécharger le dossier exo8 et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo8.Rproj dans Rstudio. 9.1 Introduction 9.1.1 ggplot2 et tydiverse ggplot2 est un package de visualisation graphique qui s’incrit dans l’écosystème plus général du tydiverse mis au point par Hadley Wickham, l’un des grands prêtres de R, responsable scientifique en chef de Rstudio. http://hadley.nz/ ggplot2 est considéré actuellement comme la référence mondiale en matière de visualisation de données statistiques sous R en raison de sa puissance et de sa polyvalence. mais son usage avancé n’est pas très facile même si les principes de base sont (relativement) simples. ggplot2 peut fonctionner sans tidyverse mais il est probablement plus efficace lorsque l’on l’utilise à l’intérieur de son écosystème. En d’autres termes, l’apprentissage de ggplot2 est souvent couplé avec celui de tidyverse. Voir par exemple l’excellent cours de J. Barnier. 9.1.2 ggplot2 cheatsheet Il est recommandé d’imprimer et d’avoir toujours avec soi la ggplot2 cheatsheet qui est disponible en français. 9.2 préparation des données 9.2.1 Chargement du fichier On charge un fichier statistique appelé tips.csv où les séparateurs sont des points-virgules et les décimales des points. don&lt;-read.table(file = &quot;resources/data/tips/tips.csv&quot;, sep = &quot;;&quot;, header = T) head(don) #&gt; IDEN TOTBILL TIP SEX SMOKER DAY TIME SIZE #&gt; 1 R001 16.99 1.01 1 0 6 1 2 #&gt; 2 R002 10.34 1.66 0 0 6 1 3 #&gt; 3 R003 21.01 3.50 0 0 6 1 3 #&gt; 4 R004 23.68 3.31 0 0 6 1 2 #&gt; 5 R005 24.59 3.61 1 0 6 1 4 #&gt; 6 R006 25.29 4.71 0 0 6 1 4 9.2.2 Contenu du fichier Ce dossier contient les pourboires (tips en anglais, d’où le nom du fichier) d’un serveur dans un restaurant américain aux débuts des années 1990. Le restaurant était dans un centre commercial. Il y avait une zone fumeurs et une zone non fumeurs.Les données indiquent le prix du repas, le pourboire, le sexe de la personne qui a payé et donné le pourboire, si c’était dans la zone fumeurs ou non, le jour où le repas a été pris, si c’était en journée ou en soirée et enfin, le nombre de convives. Sources : Ces données sont disponibles dans le package R nommé rggobi et sont décrites dans l’ouvrage de Cook et Swayne intitulé Interactive and Dynamic Graphics for Data Analysis. Elles font partie des données d’exemple du livre de Bryant et Smith dont la première édition est parue en 1995 dont le titre est Practical Data Analysis: Case Studies in Business Statistics. 9.2.3 Dictionaire des variables IDEN : identifiant du repas TOTBILL : prix du repas (en dollars des années 1990) TIP : pourboire (en dollars des années 1990) SEX : sexe de la personne qui a payé (0 = Homme, 1 = Femme) SMOKER : la personne qui a payé est non-fumeur (O) ou fumeur (1) DAY : jour de la semaine (1 = dimanche, 2 = lundi, 3 = mardi, …) TIME : repas pris en journée (0) ou le soir (1) SIZE : nombre de convives 9.2.4 Recodage des variables Le type de plusieurs variables est incorrect. On transforme les codes numériques en facteur et on recode les niveaux en français : don$IDEN&lt;-as.character(don$IDEN) don$SEX&lt;-as.factor(don$SEX) levels(don$SEX)&lt;-c(&quot;Homme&quot;,&quot;Femme&quot;) don$SMOKER&lt;-as.factor(don$SMOKER) levels(don$SMOKER)&lt;-c(&quot;Non fumeur&quot;, &quot;Fumeur&quot;) don$DAY&lt;-as.factor(don$DAY) levels(don$DAY)&lt;-c(&quot;Mercredi&quot;,&quot;Jeudi&quot;,&quot;Vendredi&quot;,&quot;Samedi&quot;) don$TIME&lt;-as.factor(don$TIME) levels(don$TIME)&lt;-c(&quot;Journée&quot;,&quot;Soirée&quot;) don$PCT&lt;-100*don$TIP/don$TOTBILL 9.2.5 Résumé de l’ensemble du tableau summary(don) #&gt; IDEN TOTBILL TIP SEX #&gt; Length:244 Min. : 3.07 Min. : 1.000 Homme:157 #&gt; Class :character 1st Qu.:13.35 1st Qu.: 2.000 Femme: 87 #&gt; Mode :character Median :17.80 Median : 2.900 #&gt; Mean :19.79 Mean : 2.998 #&gt; 3rd Qu.:24.13 3rd Qu.: 3.562 #&gt; Max. :50.81 Max. :10.000 #&gt; SMOKER DAY TIME SIZE PCT #&gt; Non fumeur:151 Mercredi:62 Journée: 68 Min. :1.00 Min. : 3.564 #&gt; Fumeur : 93 Jeudi :19 Soirée :176 1st Qu.:2.00 1st Qu.:12.913 #&gt; Vendredi:87 Median :2.00 Median :15.477 #&gt; Samedi :76 Mean :2.57 Mean :16.080 #&gt; 3rd Qu.:3.00 3rd Qu.:19.148 #&gt; Max. :6.00 Max. :71.034 9.3 Principes généraux On commence par charger le package ggplot2 qui est une partie de l’univers tidyverse mais que l’on peut utiliser indépendamment du reste de l’empire d’Hadley Wickham… library(ggplot2) 9.3.1 Les différentes étapes la commande ggplot(data) initie la création du graphique. la commande aes() qui est l’abrévation de aesthetics définit les paramètres généraux de l’ensemble du graphique et comporte en général x = variable liée à l’axe horizontal y= variable liée à l’axe vertical colour= : variable définissant des groupes / couleur shape= : variable définissant des groupes / forme la commande geom_xxx crée un graphique de type xxx les commandes additionnelles scale_xxx précisent les axes la commande additionelle facet_xxx partitionne la figure en plusieurs la commande theme_xxx retouche l’ensemble des paramètres de couleur, police, épaisseur N.B. Toutes les étapes ci-dessus ne sont pas obligatoires. 9.3.2 La figure à réaliser Comment réaliser la figure ci-dessous ? 9.3.3 La construction pas à pas On définit le tableau de données avec ggplot() et les variables principales avec aes() ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) On ajoute le type principal du graphique avec la commande geom_point() ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) + geom_point() On retouche les axes horizontaux et verticaux en les passant en logarithme et en leur donnant un titre. ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) + geom_point() + scale_x_log10(name=&quot;Prix du repas en $&quot;)+ scale_y_log10(name=&quot;Montant du pourboire en $&quot;) On segmente le graphique en facettes selon une ou plusieurs variables avec facet_wrap(). Du coup, on retire ces variables de l’esthétique générale : ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) + geom_point() + scale_x_log10(name=&quot;Prix du repas en $&quot;)+ scale_y_log10(name=&quot;Montant du pourboire en $&quot;)+ facet_wrap(vars(SEX,SMOKER)) On ajoute dans chaque facette une droite de tendance et son intervalle de confiance avec geom_smooth(). On précise method=“lm” pour avoir une droite et non pas une courbe ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) + geom_point() + scale_x_log10(name=&quot;Prix du repas en $&quot;)+ scale_y_log10(name=&quot;Montant du pourboire en $&quot;)+ facet_wrap(vars(SEX,SMOKER))+ geom_smooth(method=&quot;lm&quot;) Onajoute un titre principal avec ggtitle() et on retouche l’ensemble de l’apparence avec theme_light(). ggplot(don) + aes(x = TOTBILL) + aes(y = TIP) + geom_point() + scale_x_log10(name=&quot;Prix du repas en $&quot;)+ scale_y_log10(name=&quot;Montant du pourboire en $&quot;)+ facet_wrap(vars(SEX,SMOKER))+ geom_smooth(method=&quot;lm&quot;) + ggtitle(label = &quot;Relation entre prix du repas et pourboire / sexe et tabagisme&quot;, subtitle = &quot;Source : Briant &amp; Smith 1995 &quot;) + theme_light() 9.3.4 Comparaison avec R-Base La principale différence réside dans la construction séquentielle de la figure avec l’opérateur +. A tout moment on peut sauvegarder la figure au cours d’une des étapes décrites dans l’exemple. On parle de pipeline pour ce type de programme que l’on retrouve dans la manipulation de données avec tidyverse et dplyr. La seconde différence réside dans la production rapide d’une figure de qualité graphique acceptable sans avoir besoin de spécifier les paramètres par() de R-Base. Au total, ggplot2 s’impose actuellement comme un standard mondial autour duquel se greffent d’autres applications. Par exemple, on peut rendre interactif un graphique ggplot() en le couplant avec plotly(). Mais … ggplot2 est beaucoup moins simple qu’il n’y paraît de prime abord. Et on peut facilement s’arracher les cheveux sur certaines commandes ! 9.3.5 Attention ! Paramètres aes() locaux et globaux Une des plus grandes difficultés que l’on rencontre dans ggplot() est la manipulation du paramètre aes() qui peut renvoyer : soit à des paramètres globaux s’ils apparaissent dans le ggplot initial ou dans des lignes de codes isolées soit à des paramètres locaux, s’ils apparaissent à l’intérieur d’une fonction geom(). Deux exemples rapides pour bien comprendre SEX est un paramètre global : dans ce cas il s’applique à toutes les commandes qui suivent. Il y aura donc deux droites de régression générées par geom_smooth ggplot(don, aes(x = TOTBILL, y = TIP, color = SEX)) + geom_point() + geom_smooth(method=&quot;lm&quot;) SEX est un paramètre local de geom_point() : dans ce cas il n’aura pas d’effet sur geom_smooth() qui va générer une seule droite de régression. ggplot(don, aes(x = TOTBILL, y = TIP)) + geom_point(aes(color=SEX)) + geom_smooth(method=&quot;lm&quot;) 9.4 X discrète 9.4.1 barplot (R-base) barplot(table(don$SMOKER), col = c(&quot;blue&quot;, &quot;red&quot;), xlab=&quot;Salle de repas&quot;, ylab = &quot;effectif&quot;) 9.4.2 geom_bar (ggplot2) # ggplot ggplot(don) + aes(x =SMOKER) + geom_bar(fill = c(&quot;blue&quot;,&quot;red&quot;))+ scale_x_discrete(name=&quot;Salle de repas&quot;)+ scale_y_continuous(name=&quot;effectif&quot;) 9.5 X quantitative continue 9.5.1 hist (R-base) don2&lt;-don[don$PCT&lt;30,] hist(don2$PCT,breaks = 15, col = &quot;lightyellow&quot;, border = &quot;blue&quot;, xlab=&quot;Pourboire (%)&quot;, ylab = &quot;Nombre de clients&quot;, main = &quot;Les clients sont-ils généreux ?&quot;) 9.5.2 geom_histogram (ggplot2) # On démarre par une ligne de tidyverse ... don %&gt;% filter(PCT&lt;30) %&gt;% # ... en on embraye sur ggplot2 ggplot() + aes(x =PCT) + # Appel de la fonction principale geom_histogram( bins = 15, fill=&quot;lightyellow&quot;, col=&quot;blue&quot; ) + # Retouche de l&#39;échelle scale_x_continuous( name = &quot;Pourboires en %&quot;) + scale_y_continuous(name = &quot;Nombre de clients&quot;)+ # Ajout du titre ggtitle(&quot;Les clients sont-ils généreux ?&quot;) 9.6 X et Y quantitatives continues 9.6.1 plot (R-base) don2&lt;-don[don$PCT&lt;30,] plot(x = don2$TOTBILL, y = don2$PCT, cex=0, xlab=&quot;Prix du repas&quot;, ylab=&quot;Pourboire (%)&quot;, main= &quot;Plus c&#39;est cher moins on est généreux !&quot;) points(x=don2$TOTBILL, y=don2$PCT, col=don2$SEX, cex=sqrt(don2$SIZE), pch=19) abline(lm(don2$PCT~don2$TOTBILL), col=&quot;blue&quot;, lwd=3) 9.6.2 geom_point (ggplot2) # On filtre avec tidyverse ... don %&gt;% filter(PCT&lt;30) %&gt;% # On définit les paramètres globaux ggplot(aes(x =TOTBILL, y=PCT)) + # On trace les points avec # des paramètres locaux geom_point(aes(color=SEX, size = SIZE)) + # On ajoute la droite de régression geom_smooth(method = &quot;lm&quot;) + # On ajoute les titres scale_x_continuous(name=&quot;Prix du repas&quot;) + scale_y_continuous(name=&quot;Pourboire en %&quot;) + ggtitle(&quot;Plus c&#39;est cher moins on est généreux !&quot;) 9.7 X quantitative continue et Y discrète 9.7.1 6.1 boxplot (R-base) don2&lt;-don[(don$PCT &lt; 30),] don2$SIZE&lt;-as.factor(don2$SIZE) #levels(don2$SIZE)&lt;-c(&quot;1 ou 2&quot;, &quot;1 ou 2&quot;, &quot;3 ou 4&quot;, &quot;3 ou 4&quot;, &quot;5 ou 6&quot;, &quot;5 ou 6&quot;) boxplot(don2$PCT~don2$SIZE, col=rainbow(n=12, alpha=0.5), xlab=&quot;Nombre de personnes&quot;, ylab=&quot;Pourboire (%)&quot;, main= &quot;Plus on est de fous, moins on est généreux !&quot;,) 9.7.2 geom_boxplot (ggplot2) # On filtre le tableau et on change SIZE en factor don %&gt;% filter(PCT &lt; 30) %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;% # On définit les paramètres principaux ggplot(aes(x= SIZE,y = PCT)) + # On ajoute la boxplot geom_boxplot(aes(fill= SIZE)) + # On ajoute les titres scale_x_discrete(name=&quot;Nombre de personnes&quot;) + scale_y_continuous(name=&quot;Pourboire en %&quot;) + ggtitle(&quot;Plus on est de fous, moins on est généreux !&quot;) 9.7.3 beanplot (R-base + package beanplot) par(bg=&quot;black&quot;,fg=&quot;white&quot;,col.lab =&quot;white&quot;, col.axis =&quot;white&quot;,col.main=&quot;white&quot; ) don2&lt;-don[(don$PCT &lt; 30),] don2$SIZE&lt;-as.factor(don2$SIZE) #levels(don2$SIZE)&lt;-c(&quot;1 ou 2&quot;, &quot;1 ou 2&quot;, &quot;3 ou 4&quot;, &quot;3 ou 4&quot;, &quot;5 ou 6&quot;, &quot;5 ou 6&quot;) library(beanplot) beanplot(don2$PCT~don2$SIZE, col=c(&quot;lightyellow&quot;,&quot;red&quot;), xlab=&quot;Nombre de personnes&quot;, ylab=&quot;Pourboire (%)&quot;, main= &quot;Plus on est de fous, moins on est généreux !&quot;) 9.7.4 geom_violin (ggplot2) # On filtre le tableau et on change SIZE en factor don %&gt;% filter(PCT &lt; 30) %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;% # On définit les paramètres principaux ggplot(aes(x= SIZE,y = PCT)) + # On ajoute la géométrie geom_violin(aes(fill= SIZE)) + # On ajoute les titres scale_x_discrete(name=&quot;Nombre de personnes&quot;) + scale_y_continuous(name=&quot;Pourboire en %&quot;) + ggtitle(&quot;Plus on est de fous, moins on est généreux !&quot;)+ # On passe en thème &quot;dark&quot; theme_dark() 9.8 Deux variables X et Y discrètes 9.8.1 mosaicplot (R-base) don$SIZE&lt;-as.factor(don$SIZE) mosaicplot(don$SEX~don$SIZE, col=terrain.colors(n=7, alpha=0.5), xlab=&quot;Genre de la personne qui a payé&quot;, ylab=&quot;Nombre de convives&quot;, main= &quot;Plus il y a de monde, plus ce sont les hommes qui payent&quot;) 9.8.2 geom_bar (ggplot2) Solution simple mais pas terrible ! # On filtre le tableau et on change SIZE en factor don %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;% # On définit les paramètres principaux ggplot(aes(x= SEX, fill = SIZE)) + # On ajoute geom_bar geom_bar() + # On ajoute les titres scale_x_discrete(name=&quot;Genre de la personne qui a payé&quot;) + ggtitle(&quot;Plus il y a de monde, plus ce sont les hommes qui payent&quot;) solution juste … mais très complexe # On crée un tableau de contingence # avec pourcentages en colonne avec # du code tidyverse don %&gt;% mutate(SIZE = as.factor(SIZE)) %&gt;% group_by(SEX, SIZE) %&gt;% summarise(count = n()) %&gt;% mutate(cut.count = sum(count), prop = count/sum(count)) %&gt;% ungroup() %&gt;% # On définit les paramètres principaux ggplot(aes(x = SEX, y = prop, width = cut.count, fill = SIZE)) + # On lance le geom_bar avec plein d&#39;options geom_bar(stat = &quot;identity&quot;, position = &quot;fill&quot;, colour = &quot;black&quot;) + facet_grid(~SEX, scales = &quot;free_x&quot;, space = &quot;free_x&quot;) + scale_fill_brewer(palette = &quot;RdYlGn&quot;, direction=-1) + theme_void() + # On ajoute les titres scale_x_discrete(name=&quot;Genre de la personne qui a payé&quot;) + ggtitle(&quot;Plus il y a de monde, plus ce sont les hommes qui payent&quot;) # OUF !!! (R-base est + simple !) 9.9 Conclusion 9.9.1 R-base simple d’utilisation peut être amélioré par des packages spécialisés permet de créer ses propres fonctions n’impose pas d’apprendre tidyverse 9.9.2 ggplot2 standard mondial du graphisme … actuellement compatible avec la religion du tidyverse rédaction séquentielle très efficace mais apprentissage difficile (plusieurs semaines …) 9.9.3 Le meilleur des deux mondes ? ne pas hésiter à combiner les deux exportation facile des résultats dans les deux cas (pdf, jpeg, png, …) 9.9.4 plotly, un challenger sérieux de ggplot pour le web plotly crée des graphiques interactifs au format .html plotly peut convertir des documents ggplot plotly a une syntaxe proche de ggplot mais avec des fonctionnalités en plus plotly est multilangage (R, Python, …) "],["10-Tidyverse.html", "Partie 10 Initiation à tidyverse 10.1 Introduction 10.2 Manipuler avec dplyr 10.3 Visualiser avec ggplot2 10.4 Comparaison R-Base / Ggplot2 10.5 Conclusion", " Partie 10 Initiation à tidyverse Mise en place : Télécharger le dossier exo_dvf et décompressez le sur votre ordinateur. Puis ouvrez le projet R exo.Rproj dans Rstudio. 10.1 Introduction 10.1.1 Un nouvel empire ? Le package tidyverse mis au point par les auteurs de R Studio est une collection de packages R qui se présente comme un nouveau langage permettant le traitement intégré des données selon une chaîne qui part de l’importation (readr) et de la mise en forme (tidyr) pour passer ensuite aux transformations(dplyr, broom), à la visualisation statistique (ggplot2) ou cartographique (ggmap), à la modélisation et enfin la restitution sous forme de documents (Rmarkdown). La liste de package présentée dans la figure ci-dessus n’est d’ailleurs pas exhaustive car il existe des packages plus spécialisés dans l’analyse et le recodage des variables catégorielles (forcats) ou temporelles (lubridate), l’analyse de données textuelles (stringr), l’étude de données d’enquête (haven). En dehors de tidyverse proprement dit, les auteurs de ce package ont mis au point des outils d’analye textuelle (tidytext), de création de site web (shiny) qui s’inscrivent dans la même philosophie. Bref, tidyverse se présente comme un nouvel empire qui remplacerait les vieux packages R destinés à tomber dans les poubelles de l’histoire et constituerait l’outil ultime de la science des données… 10.1.2 Pour une utilisation sélective Les adhérents de la philosophie tidyverse ont donc pour pratique de charger d’emblée le superpackage tidyverse et d’inclure de ce fait l’ensemble de ces composantes qu’elles soient utiles ou non à l’analyse, ce qui ne manque pas de créer des conflits avec d’autres packages disponibles dans R : # Ne pas executer ! library(tidyverse) L’auteur de ces lignes et beaucoup de chercheurs en sciences des données ne partagent cependant pas l’enthousiasme des auteurs de tidyverse et émettent plusieurs réserves. tidyverse n’est pas un très bon logiciel de statistique comparativement à d’autres packages tels que car (pour la régression), survey ou questionr (pour les analyses d’enquêtes). tidyverse n’est pas le meilleur package pour des représentation cartographiques et il existe d’autres packages plus effficaces tels que tmap, leaflet, mapsf, … tidyverse charge inutilement la mémoire de l’ordinateure packages pas toujours utiles aux objectifs que l’on s’est donné. tidyverse n’est pas le plus performant pour la gestion de très grandes masses de données comparativement au package data.table tidyverse ne fait souvent que dupliquer des packages existants … Bref, il semble préférable d’utiliser au cas par cas les composantes de tidverse et de ne charger que celles dont on a réellement l’utilité et pour lesquelles les auteurs ont réellement apporter une innovation majeure. Deux packages relèvent clairement de cette catégorie : dplyr et ggplot2. C’est donc uniquement ces deux packages que nous allons utiliser ici en insistant sur leurs qualités et leur complémentarité. library(dplyr) library(ggplot2) 10.1.3 Jeu de données On charge un fichier sauvegardé au format .RDS appelé DSTM1_2023_V2.RDS base&lt;-readRDS(&quot;resources/data/dvf/dm/DSTM1_2023_V2.RDS&quot;) base&lt;-as.data.frame(base) head(base) #&gt; com_code com_nom ann type prix sup nbp X Y #&gt; 1 93046 Livry-Gargan 2019 Maison 359980 105 5 665716.8 6868319 #&gt; 2 93046 Livry-Gargan 2019 Appartement 271000 58 3 666339.0 6869657 #&gt; 3 93005 Aulnay-sous-Bois 2019 Appartement 80000 72 4 664285.1 6872132 #&gt; 4 93046 Livry-Gargan 2019 Appartement 149000 38 2 664728.0 6867419 #&gt; 5 93005 Aulnay-sous-Bois 2019 Maison 230000 78 4 663570.8 6872907 #&gt; 6 93005 Aulnay-sous-Bois 2019 Maison 200000 94 4 662340.0 6870911 #&gt; dist_gare #&gt; 1 2522.1834 #&gt; 2 1222.6446 #&gt; 3 942.0401 #&gt; 4 1920.6869 #&gt; 5 1144.2156 #&gt; 6 836.4367 10.1.3.1 Contenu du fichier Ce dossier est une version simplifiée des Demandes de Valeurs Foncières et contient un échantillon des ventes de maisons ou d’appartements effectués dans un ensemble de communes d’Ile de France caractérisées par la présence d’un volume important de maisons et d’appartement. Sources : Ces données sont disponibles sur le site opendatasoft sous l’appellation “Demandes de valeurs foncières géoloalisées” La liste des variables est la suivante : com_code : code INSEE de la commune où a eu lieu la transaction com_nom : nom de la commune où a eu lieu la transaction ann : année de la transcation type : type de bien vendu (maison ou appartement) prix : prix de vente du bien surf : surface habitable du logement nbp : nombre de pièces du logement X : cordonnées projetées de longitude Y : coordonnées projetées de latitude dist_gare : distance à la gare la plus proche en mètres summary(base) #&gt; com_code com_nom ann type #&gt; Min. :77373 Length:94530 Min. :2017 Appartement:58415 #&gt; 1st Qu.:92002 Class :character 1st Qu.:2018 Maison :36115 #&gt; Median :93029 Mode :character Median :2019 #&gt; Mean :91281 Mean :2019 #&gt; 3rd Qu.:94068 3rd Qu.:2020 #&gt; Max. :95607 Max. :2021 #&gt; prix sup nbp X #&gt; Min. : 13500 Min. : 9.00 Min. : 1.000 Min. :627324 #&gt; 1st Qu.: 164000 1st Qu.: 48.00 1st Qu.: 2.000 1st Qu.:643478 #&gt; Median : 243000 Median : 65.00 Median : 3.000 Median :658934 #&gt; Mean : 296945 Mean : 70.23 Mean : 3.288 Mean :653699 #&gt; 3rd Qu.: 360000 3rd Qu.: 85.00 3rd Qu.: 4.000 3rd Qu.:663441 #&gt; Max. :3131000 Max. :299.00 Max. :15.000 Max. :673401 #&gt; Y dist_gare #&gt; Min. :6830664 Min. : 27.84 #&gt; 1st Qu.:6855834 1st Qu.: 548.93 #&gt; Median :6864402 Median : 901.37 #&gt; Mean :6862812 Mean : 999.69 #&gt; 3rd Qu.:6870676 3rd Qu.:1326.11 #&gt; Max. :6884258 Max. :3768.92 10.2 Manipuler avec dplyr Nous allons passer rapidement en revue quelques commandes de base de dplyr à travers des exemples précis d’application.On commence par charger le package dlyr qui est une partie de l’univers tidyverse mais que l’on peut utiliser indépendamment du reste de l’empire d’Hadley Wickham… library(dplyr) knitr::include_graphics(&quot;resources/figures/dplyr.jpg&quot;) 10.2.1 filter() La commande filter() permet de sélectionner des lignes. Deux syntaxes sont possibles : filter(tableau, condition1, condition2, …) tableau %&gt;% filter(}condition1, condition2, ...) On préfrera la seconde syntaxe qui évite de mélanger dans la parenthèse le nom du tableau et les conditions de sélection. La fonction %&gt;% est un pipeline (en abrégé ‘pipe’) qui peut se traduire par ‘et ensuite’ lorsque l’on enchaîne une série d’instruction. Par exemple, si on veut sélectionner la commune de St-Maur-des-Fossés dont le code est 94068 on pourra écrire le programme suivant # Solution R-Base don&lt;-base[base$com_code==&quot;94068&quot;,] head(don,3) #&gt; com_code com_nom ann type prix sup nbp X #&gt; 60 94068 Saint-Maur-des-Fossés 2019 Appartement 170000 35 3 661127.9 #&gt; 61 94068 Saint-Maur-des-Fossés 2019 Appartement 362000 59 3 663139.1 #&gt; 62 94068 Saint-Maur-des-Fossés 2019 Appartement 315000 52 3 661660.3 #&gt; Y dist_gare #&gt; 60 6856876 522.3698 #&gt; 61 6856243 868.9349 #&gt; 62 6855562 896.2634 #Solution dplyr don&lt;-base %&gt;% filter(com_code==&quot;94068&quot;) head(don,3) #&gt; com_code com_nom ann type prix sup nbp X #&gt; 1 94068 Saint-Maur-des-Fossés 2019 Appartement 170000 35 3 661127.9 #&gt; 2 94068 Saint-Maur-des-Fossés 2019 Appartement 362000 59 3 663139.1 #&gt; 3 94068 Saint-Maur-des-Fossés 2019 Appartement 315000 52 3 661660.3 #&gt; Y dist_gare #&gt; 1 6856876 522.3698 #&gt; 2 6856243 868.9349 #&gt; 3 6855562 896.2634 A première vue il n’y a pas beaucoup de différence entre R-Base et dplyr. Mais l’avantage de ce dernier apparaît mieux lorsque l’on veut effectuer une solution selon plusieurs critères. Par exemple, supposons qu’on veuille sélectionner les ventes de maison de 80 à 120 m2 à Saint-Maur des fossés en 2020 : # Solution R-Base don&lt;-base[base$com_code==&quot;94068&quot; &amp; base$type==&quot;Maison&quot; &amp; base$ann == 2020 &amp; base$sup &gt;= 80 &amp; base$sup &lt;= 120,] head(don,3) #&gt; com_code com_nom ann type prix sup nbp X #&gt; 2817 94068 Saint-Maur-des-Fossés 2020 Maison 1500000 120 5 663646.8 #&gt; 3340 94068 Saint-Maur-des-Fossés 2020 Maison 773313 80 4 661871.6 #&gt; 3342 94068 Saint-Maur-des-Fossés 2020 Maison 610000 93 4 661389.3 #&gt; Y dist_gare #&gt; 2817 6855738 778.2111 #&gt; 3340 6855967 457.8792 #&gt; 3342 6854505 1867.5387 #Solution dplyr don&lt;-base %&gt;% filter(com_code==&quot;94068&quot;, type==&quot;Maison&quot;, ann == 2020, sup &gt;= 80, sup &lt;= 120) head(don,3) #&gt; com_code com_nom ann type prix sup nbp X Y #&gt; 1 94068 Saint-Maur-des-Fossés 2020 Maison 1500000 120 5 663646.8 6855738 #&gt; 2 94068 Saint-Maur-des-Fossés 2020 Maison 773313 80 4 661871.6 6855967 #&gt; 3 94068 Saint-Maur-des-Fossés 2020 Maison 610000 93 4 661389.3 6854505 #&gt; dist_gare #&gt; 1 778.2111 #&gt; 2 457.8792 #&gt; 3 1867.5387 Le code est désormais beaucoup plus léger et beaucoup plus clair dans le cas de dplyr, surtout si l’on procède à une indentation des conditions. 10.2.2 select() La commande select() permet de choisir des variables c’est-à-dire des colonnes dans un tableau. Supposons à titre d’exemple que l’on veuille créer un tableau ne contenant que les variables com_nom, type, prix et surface. # Solution R-Base don&lt;-base[,c(&quot;com_nom&quot;, &quot;type&quot;,&quot;prix&quot;,&quot;sup&quot;)] head(don,3) #&gt; com_nom type prix sup #&gt; 1 Livry-Gargan Maison 359980 105 #&gt; 2 Livry-Gargan Appartement 271000 58 #&gt; 3 Aulnay-sous-Bois Appartement 80000 72 #Solution dplyr don&lt;-base %&gt;% select(com_nom, type, prix, sup) head(don,3) #&gt; com_nom type prix sup #&gt; 1 Livry-Gargan Maison 359980 105 #&gt; 2 Livry-Gargan Appartement 271000 58 #&gt; 3 Aulnay-sous-Bois Appartement 80000 72 La principale différence entre les deux écritures est l’absence d’apostrophe “” dans la liste du nom des variables utilisées par select() ce qui est tout de même un gain de temps précieux. On peut procéder à des sélections par numéro de colonnes et on peut supprimer des variables avec l’opérateur “-”. Par exemple, pour retirer les variables X et Y on a deux écritures possibles en dplyr # Solution R-Base don&lt;-base[,c(1:7,10)] head(don,3) #&gt; com_code com_nom ann type prix sup nbp dist_gare #&gt; 1 93046 Livry-Gargan 2019 Maison 359980 105 5 2522.1834 #&gt; 2 93046 Livry-Gargan 2019 Appartement 271000 58 3 1222.6446 #&gt; 3 93005 Aulnay-sous-Bois 2019 Appartement 80000 72 4 942.0401 #Solution dplyr n°1 don&lt;-base %&gt;% select(1:7,10) head(don,3) #&gt; com_code com_nom ann type prix sup nbp dist_gare #&gt; 1 93046 Livry-Gargan 2019 Maison 359980 105 5 2522.1834 #&gt; 2 93046 Livry-Gargan 2019 Appartement 271000 58 3 1222.6446 #&gt; 3 93005 Aulnay-sous-Bois 2019 Appartement 80000 72 4 942.0401 #Solution dplyr n°2 don&lt;-base %&gt;% select(-X,-Y) head(don,3) #&gt; com_code com_nom ann type prix sup nbp dist_gare #&gt; 1 93046 Livry-Gargan 2019 Maison 359980 105 5 2522.1834 #&gt; 2 93046 Livry-Gargan 2019 Appartement 271000 58 3 1222.6446 #&gt; 3 93005 Aulnay-sous-Bois 2019 Appartement 80000 72 4 942.0401 10.2.3 mutate() La commande mutate() permet de créer de nouvelles variables ou de modifier des variables existantes. Supposons par exemple qu’on veuille créer un tableau contenant pour la commune de Saint-Maur une variable prix au m2 et une variable distance à la gare en km. # Solution R-Base don&lt;-base[base$com_code==94068,] don$prixm2&lt;-don$prix/don$sup don$dist_gare&lt;-don$dist_gare/1000 don&lt;-don[,c(&quot;prixm2&quot;, &quot;dist_gare&quot;)] head(don,3) #&gt; prixm2 dist_gare #&gt; 60 4857.143 0.5223698 #&gt; 61 6135.593 0.8689349 #&gt; 62 6057.692 0.8962634 #Solution dplyr n°1 don&lt;-base %&gt;% filter(com_code==94068) %&gt;% # sélection de Saint-Maur mutate(prixm2 = prix/sup, # création du prix au m2 dist_gare = dist_gare/1000)%&gt;% # conversion de la distance en km select(prixm2,dist_gare) # sélection des variables utiles head(don,3) #&gt; prixm2 dist_gare #&gt; 1 4857.143 0.5223698 #&gt; 2 6135.593 0.8689349 #&gt; 3 6057.692 0.8962634 Nous voyons ici l’intérêt du pipeline %&gt;% qui permet d’enchaîner de façon simple les différentes opérations effectuées respectivement par chacune des fonctions. La lecture du programme est beaucoup plus naturelle que dans le cas de R-Base 10.2.4 arrange() La commande mutate() permet enfin de trier le tableau selon une ou plusieurs clés de tri. Reprenons par exemple le programme précédent et essayons de trier les résultats en fonction de la distance à la gare. # Solution R-Base don &lt;- base[base$com_code==94068,] don$prixm2 &lt;- don$prix/don$sup don$dist_gare &lt;- don$dist_gare/1000 don &lt;- don[,c(&quot;prixm2&quot;, &quot;dist_gare&quot;)] don &lt;- don[order(don$dist_gare),] head(don,3) #&gt; prixm2 dist_gare #&gt; 9335 4642.000 0.03447172 #&gt; 82459 5053.571 0.03447172 #&gt; 6124 8295.455 0.03622251 tail(don,3) #&gt; prixm2 dist_gare #&gt; 5987 5343.750 2.164269 #&gt; 56051 3437.466 2.170164 #&gt; 83391 3750.000 2.170164 #Solution dplyr n°1 don&lt;-base %&gt;% filter(com_code==94068) %&gt;% # sélection de Saint-Maur mutate(prixm2 = prix/sup, # création du prix au m2 dist_gare = dist_gare/1000)%&gt;% # conversion de la distance en km select(prixm2,dist_gare) %&gt;% # sélection des variables utiles arrange(dist_gare) head(don,3) #&gt; prixm2 dist_gare #&gt; 1 4642.000 0.03447172 #&gt; 2 5053.571 0.03447172 #&gt; 3 8295.455 0.03622251 tail(don,3) #&gt; prixm2 dist_gare #&gt; 6628 5343.750 2.164269 #&gt; 6629 3437.466 2.170164 #&gt; 6630 3750.000 2.170164 10.3 Visualiser avec ggplot2 On commence par charger le package ggplot2 qui est une partie de l’univers tidyverse mais que l’on peut utiliser indépendamment du reste de l’empire d’Hadley Wickham… library(ggplot2) knitr::include_graphics(&quot;resources/figures/ggplot2.jpeg&quot;) 10.3.1 Les différentes étapes la commande ggplot(data) initie la création du graphique. la commande aes() qui est l’abrévation de aesthetics définit les paramètres généraux de l’ensemble du graphique et comporte en général x = variable liée à l’axe horizontal y= variable liée à l’axe vertical colour= : variable définissant des groupes / couleur shape= : variable définissant des groupes / forme la commande geom_xxx crée un graphique de type xxx les commandes additionnelles scale_xxx précisent les axes la commande additionelle facet_xxx partitionne la figure en plusieurs la commande theme_xxx retouche l’ensemble des paramètres de couleur, police, épaisseur N.B. Toutes les étapes ci-dessus ne sont pas obligatoires. 10.3.2 La figure à réaliser Comment réaliser la figure ci-dessous ? 10.3.3 La construction pas à pas On commence par préparer le tableau de données avec dplyr : sel&lt;-base %&gt;% filter(com_code==94068) %&gt;% mutate(periode = as.factor(ann&gt;2019))%&gt;% select(periode, type, prix, sup, nbp) levels(sel$periode)&lt;-c(&quot;Pre-covid (2017-19)&quot;,&quot;Covid (2020-21)&quot;) head(sel) #&gt; periode type prix sup nbp #&gt; 1 Pre-covid (2017-19) Appartement 170000 35 3 #&gt; 2 Pre-covid (2017-19) Appartement 362000 59 3 #&gt; 3 Pre-covid (2017-19) Appartement 315000 52 3 #&gt; 4 Pre-covid (2017-19) Appartement 405000 62 2 #&gt; 5 Pre-covid (2017-19) Maison 174500 36 2 #&gt; 6 Pre-covid (2017-19) Appartement 344700 63 3 On définit le tableau de données avec ggplot() et les variables principales avec aes() ggplot(sel) + aes(x = sup) + aes(y = prix) + aes(col = type) On ajoute le type principal du graphique avec la commande geom_point() ggplot(sel) + aes(x = sup) + aes(y = prix) + geom_point() On retouche les axes horizontaux et verticaux en les passant en logarithme et en leur donnant un titre. ggplot(sel) + aes(x = sup) + aes(y = prix) + geom_point() + scale_x_continuous(name=&quot;Surface du logement&quot;)+ scale_y_continuous(name=&quot;Prix de vente&quot;) On segmente le graphique en facettes selon une ou plusieurs variables avec facet_wrap(). Du coup, on retire ces variables de l’esthétique générale : ggplot(sel) + aes(x = sup) + aes(y = prix) + geom_point() + scale_x_continuous(name=&quot;Surface du logement&quot;)+ scale_y_continuous(name=&quot;Prix de vente&quot;)+ facet_wrap(vars(type, periode),ncol= 2) On ajoute dans chaque facette une droite de tendance et son intervalle de confiance avec geom_smooth(). On précise method=“lm” pour avoir une droite et non pas une courbe ggplot(sel) + aes(x = sup) + aes(y = prix) + geom_point() + scale_x_continuous(name=&quot;Surface du logement&quot;)+ scale_y_continuous(name=&quot;Prix de vente&quot;)+ facet_wrap(vars(type, periode),ncol= 2) geom_smooth(method=&quot;lm&quot;) #&gt; geom_smooth: na.rm = FALSE, orientation = NA, se = TRUE #&gt; stat_smooth: na.rm = FALSE, orientation = NA, se = TRUE, method = lm #&gt; position_identity Onajoute un titre principal avec ggtitle() et on retouche l’ensemble de l’apparence avec theme_light(). ggplot(sel) + aes(x = sup) + aes(y = prix) + geom_point() + scale_x_continuous(name=&quot;Surface du logement&quot;)+ scale_y_continuous(name=&quot;Prix de vente&quot;)+ facet_wrap(vars(type, periode),ncol= 2)+ geom_smooth(method=&quot;lm&quot;) + ggtitle(label = &quot;Ventes de logements à Saint-Maur (2017-2021)&quot;, subtitle = &quot;Source : DVF &quot;) + theme_light() 10.3.4 Comparaison avec R-Base La principale différence réside dans la construction séquentielle de la figure avec l’opérateur +. A tout moment on peut sauvegarder la figure au cours d’une des étapes décrites dans l’exemple. On parle de pipeline pour ce type de programme que l’on retrouve dans la manipulation de données avec tidyverse et dplyr. La seconde différence réside dans la production rapide d’une figure de qualité graphique acceptable sans avoir besoin de spécifier les paramètres par() de R-Base. Au total, ggplot2 s’impose actuellement comme un standard mondial autour duquel se greffent d’autres applications. Par exemple, on peut rendre interactif un graphique ggplot() en le couplant avec plotly(). Mais … ggplot2 est beaucoup moins simple qu’il n’y paraît de prime abord. Et on peut facilement s’arracher les cheveux sur certaines commandes ! 10.3.5 Attention ! Paramètres aes() locaux et globaux Une des plus grandes difficultés que l’on rencontre dans ggplot() est la manipulation du paramètre aes() qui peut renvoyer : soit à des paramètres globaux s’ils apparaissent dans le ggplot initial ou dans des lignes de codes isolées soit à des paramètres locaux, s’ils apparaissent à l’intérieur d’une fonction geom(). Deux exemples rapides pour bien comprendre type est un paramètre global : dans ce cas il s’applique à toutes les commandes qui suivent. Il y aura donc deux droites de régression générées par geom_smooth ggplot(sel, aes(x = sup, y = prix, color = type)) + geom_point() + geom_smooth(method=&quot;lm&quot;) type est un paramètre local de geom_point() : dans ce cas il n’aura pas d’effet sur geom_smooth() qui va générer une seule droite de régression. ggplot(sel, aes(x = sup, y = prix)) + geom_point(aes(color=type)) + geom_smooth(method=&quot;lm&quot;) 10.4 Comparaison R-Base / Ggplot2 10.4.1 X discrète 10.4.1.1 barplot (R-base) barplot(table(sel$type), col = c(&quot;blue&quot;, &quot;red&quot;), xlab=&quot;Type de logement&quot;, ylab = &quot;effectif&quot;) 10.4.1.2 geom_bar (ggplot2) # ggplot ggplot(sel) + aes(x =type) + geom_bar(fill = c(&quot;blue&quot;,&quot;red&quot;))+ scale_x_discrete(name=&quot;Type de logement&quot;)+ scale_y_continuous(name=&quot;effectif&quot;) 10.4.2 X quantitative continue 10.4.2.1 hist (R-base) sel2&lt;-sel[sel$type==&quot;Maison&quot;,] hist(sel2$prix,breaks = 15, col = &quot;lightyellow&quot;, border = &quot;blue&quot;, xlab=&quot;Prix de vente&quot;, ylab = &quot;Nombre de ventes&quot;, main = &quot;Ventes de maison&quot;) 10.4.2.2 geom_histogram (ggplot2) # On démarre par une ligne de tidyverse ... sel %&gt;% filter(type==&quot;Maison&quot;) %&gt;% # ... en on embraye sur ggplot2 ggplot() + aes(x =prix) + # Appel de la fonction principale geom_histogram( bins = 15, fill=&quot;lightyellow&quot;, col=&quot;blue&quot; ) + # Retouche de l&#39;échelle scale_x_continuous( name = &quot;Prix de vente&quot;) + scale_y_continuous(name = &quot;Nombre de ventes&quot;)+ # Ajout du titre ggtitle(&quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.3 X et Y quantitatives continues 10.4.3.1 plot (R-base) plot(x = sel$sup, y = sel$prix, cex=0, xlab=&quot;Surface&quot;, ylab=&quot;Prix de vente&quot;, main= &quot;Ventes de maison&quot;) points(x = sel$sup, y = sel$prix, col=sel$type, cex=sqrt(sel$nbp), pch=19) abline(lm(sel$prix~sel$sup), col=&quot;blue&quot;, lwd=3) 10.4.3.2 geom_point (ggplot2) # On définit les paramètres globaux ggplot(sel, aes(x =sup, y=prix)) + # On trace les points avec # des paramètres locaux geom_point(aes(color=type, size = nbp)) + # On ajoute la droite de régression geom_smooth(method = &quot;lm&quot;) + # On ajoute les titres scale_x_continuous(name=&quot;surface&quot;) + scale_y_continuous(name=&quot;prix de vente&quot;) + ggtitle(&quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.4 X quantitative continue et Y discrète 10.4.4.1 boxplot (R-base) sel2&lt;-sel[(sel$type==&quot;Maison&quot;),] sel2$SIZE&lt;-as.factor(sel2$nbp) #levels(don2$SIZE)&lt;-c(&quot;1 ou 2&quot;, &quot;1 ou 2&quot;, &quot;3 ou 4&quot;, &quot;3 ou 4&quot;, &quot;5 ou 6&quot;, &quot;5 ou 6&quot;) boxplot(sel2$prix~sel2$SIZE, col=rainbow(n=12, alpha=0.5), xlab=&quot;Nombre de pièces&quot;, ylab=&quot;Prix&quot;, main= &quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.4.2 geom_boxplot (ggplot2) # On filtre le tableau et on change SIZE en factor sel %&gt;% filter(type==&quot;Maison&quot;) %&gt;% mutate(SIZE = as.factor(nbp)) %&gt;% # On définit les paramètres principaux ggplot(aes(x= SIZE,y = prix)) + # On ajoute la boxplot geom_boxplot(aes(fill= SIZE)) + # On ajoute les titres scale_x_discrete(name=&quot;Nombre de pièces&quot;) + scale_y_continuous(name=&quot;Prix de vente&quot;) + ggtitle(&quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.4.3 beanplot (R-base + package beanplot) par(bg=&quot;black&quot;,fg=&quot;white&quot;,col.lab =&quot;white&quot;, col.axis =&quot;white&quot;,col.main=&quot;white&quot; ) sel2&lt;-sel[(sel$type==&quot;Maison&quot;),] sel2$SIZE&lt;-as.factor(sel2$nbp) #levels(don2$SIZE)&lt;-c(&quot;1 ou 2&quot;, &quot;1 ou 2&quot;, &quot;3 ou 4&quot;, &quot;3 ou 4&quot;, &quot;5 ou 6&quot;, &quot;5 ou 6&quot;) library(beanplot) beanplot(sel2$prix~sel2$SIZE, col=c(&quot;lightyellow&quot;,&quot;red&quot;), xlab=&quot;Nombre de pièces&quot;, ylab=&quot;Prix&quot;, main= &quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.4.4 geom_violin (ggplot2) # On filtre le tableau et on change SIZE en factor sel %&gt;% filter(type==&quot;Maison&quot;) %&gt;% mutate(SIZE = as.factor(nbp)) %&gt;% # On définit les paramètres principaux ggplot(aes(x= SIZE,y = prix)) + # On ajoute la géométrie geom_violin(aes(fill= SIZE)) + # On ajoute les titres scale_x_discrete(name=&quot;Nombre de pièces&quot;) + scale_y_continuous(name=&quot;Prix de vente&quot;) + ggtitle(&quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) + # On passe en thème &quot;dark&quot; theme_dark() 10.4.5 Deux variables X et Y discrètes 10.4.5.1 mosaicplot (R-base) mosaicplot(sel$periode~sel$type, col=c(&quot;yellow&quot;,&quot;orange&quot;), xlab=&quot;Année&quot;, ylab=&quot;Type de logement&quot;, main= &quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.4.5.2 geom_bar (ggplot2) # On définit les paramètres principaux ggplot(sel,aes(x= periode, fill = type)) + # On ajoute geom_bar geom_bar() + # On ajoute les titres scale_x_discrete(name=&quot;Année&quot;) + ggtitle(&quot;Ventes de logements à Saint-Maur (2017-2021)&quot;) 10.5 Conclusion 10.5.1 R-base simple d’utilisation peut être amélioré par des packages spécialisés permet de créer ses propres fonctions n’impose pas d’apprendre tidyverse 10.5.2 ggplot2 standard mondial du graphisme … actuellement compatible avec la religion du tidyverse rédaction séquentielle très efficace mais apprentissage difficile (plusieurs semaines …) 10.5.3 Le meilleur des deux mondes ? ne pas hésiter à combiner les deux exportation facile des résultats dans les deux cas (pdf, jpeg, png, …) 10.5.4 plotly, un challenger sérieux de ggplot pour le web plotly crée des graphiques interactifs au format .html plotly peut convertir des documents ggplot plotly a une syntaxe proche de ggplot mais avec des fonctionnalités en plus plotly est multilangage (R, Python, …) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
